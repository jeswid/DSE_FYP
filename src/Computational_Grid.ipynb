{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Computational grid"
      ],
      "metadata": {
        "id": "QEApmPYMCKpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Tuple, List\n",
        "import argparse\n",
        "import math\n",
        "import yaml"
      ],
      "metadata": {
        "id": "Gqjw6R3cCMZb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_grid(num_grid_x:Tuple[int],extents:Tuple[float]):\n",
        "    \"\"\"\n",
        "    Computes Grid Points\n",
        "    num_grid_x : number of grid points in x direction\n",
        "    extents : Map Extents\n",
        "    \"\"\"\n",
        "    x_min, x_max, y_min, y_max = extents\n",
        "\n",
        "    dy = y_max - y_min\n",
        "    dx = x_max - x_min\n",
        "    factor = dy / dx\n",
        "\n",
        "    n_x = num_grid_x\n",
        "    n_y = math.ceil(factor * num_grid_x)\n",
        "\n",
        "    x_grid = np.linspace(x_min, x_max, n_x, endpoint=True) #(n_x,)\n",
        "    y_grid = np.linspace(y_min, y_max, n_y, endpoint=True) #(n_y,)\n",
        "\n",
        "    # full coordinate arrays\n",
        "    x_coords, y_coords = np.meshgrid(x_grid, y_grid) #(n_x,n_y),(n_x,n_y) <- Values in these arrays arnt the same\n",
        "    x_coords = x_coords.reshape(-1) #(n_x * n_y,)\n",
        "    y_coords = y_coords.reshape(-1) #(n_x * n_y,)\n",
        "\n",
        "    df = pd.DataFrame({\"Latitude\" : y_coords, \"Longitude\" : x_coords})\n",
        "    grid_pts = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Longitude, df.Latitude))\n",
        "\n",
        "    x = np.array([x_coords, y_coords]).transpose((1,0)) #(n_x * n_y , 2)\n",
        "\n",
        "    return x, grid_pts"
      ],
      "metadata": {
        "id": "naRUmC2ACZAN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pol_pts(df_shp:gpd.GeoDataFrame, grid_pts:gpd.GeoDataFrame):\n",
        "    \"\"\"\n",
        "    Counts the grid points that fall on the regions\n",
        "     - df_shp : takes the dataframe containing regions\n",
        "     - grid_pts : takes the dataframe containing grid_points\n",
        "\n",
        "    \"\"\"\n",
        "    grid_pts.set_crs(epsg=4326, inplace = True) #geometry column remains the same, but originally it doesnt have crs until you set it\n",
        "    grid_pts.crs == df_shp.crs # ensures both are epsh 4326\n",
        "    n_pol = len(df_shp.geometry) #46 for s_new\n",
        "    n_pts = len(grid_pts.geometry) #1919 - num grid points\n",
        "\n",
        "    pl_pt = np.zeros((n_pol, n_pts), dtype = int) #zeros(46, 1919) for new_regions\n",
        "    pt_which_pol = np.zeros(n_pts, dtype = int) #(1919,) for s_new possibly the same for s_old\n",
        "\n",
        "    for i_pol in range(n_pol): #1..46\n",
        "        pol = df_shp.geometry[i_pol] #i.e POLYGON((...))\n",
        "        for j_pts in range(n_pts): # 0 ...1919\n",
        "            pt = grid_pts.geometry[j_pts] #i.e point((...))\n",
        "            # Check if point falls on polygon\n",
        "            if pol.contains(pt):\n",
        "                pl_pt[i_pol, j_pts] = 1 # matrix just says if there is point\n",
        "                # in the code cell below we use this to make a new column that will helps us\n",
        "                # figure out which region each point corresponds to\n",
        "                pt_which_pol[j_pts] = i_pol + 1\n",
        "\n",
        "    return([pl_pt, pt_which_pol])"
      ],
      "metadata": {
        "id": "jFpBJjZKCbAD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grid(df:gpd.GeoDataFrame, grid_pts:gpd.GeoDataFrame, file_name:str)->None:\n",
        "    \"\"\"\n",
        "    Plots grid points\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1,1, figsize = (10,10))\n",
        "    df.plot(ax = ax, color = \"white\", edgecolor = \"black\")\n",
        "    grid_pts.plot(ax = ax , marker = \"o\", color = \"red\", markersize = 2)\n",
        "\n",
        "    if not os.path.exists(\"tmp\"):\n",
        "        os.mkdir(\"tmp\")\n",
        "\n",
        "    fig.savefig(os.path.join(\"tmp\", file_name))\n",
        "    print(\"Saving plot in 'tmp'...\")"
      ],
      "metadata": {
        "id": "Jb9Ox1_zCdaB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_points_in_region(df:gpd.GeoDataFrame, grid_pts:gpd.GeoDataFrame):\n",
        "    \"\"\"Returns an array with points that fall regions as well as which point that falls\n",
        "    on region.\n",
        "    \"\"\"\n",
        "    pol_pt, pt_which_pol = pol_pts(df, grid_pts) #(9, num_points), (num_points,)\n",
        "    pol_sums = np.sum(pol_pt, axis = 1)\n",
        "    assert all(item > 0 for item in pol_sums), \"Region(s) with no pints exists !\"\n",
        "    print(\"Atleast one point falls on every region !\")\n",
        "    return pol_pt, pt_which_pol"
      ],
      "metadata": {
        "id": "TjVaFlwlCgve"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#todo : We need to replace this with a linear programming optimization code to figure the best grid size\n",
        "def check_for_min_points(start_value, end_value, df, extents):\n",
        "    \"\"\"Helper to look for a given configuration where atleast one point falls\n",
        "    on every region.\"\"\"\n",
        "    num_grid_x = start_value\n",
        "    for i in range(0,end_value):\n",
        "        x, grid_pts = compute_grid(num_grid_x, extents)\n",
        "        pol_pt_hi, pt_which_pol_hi = pol_pts(df, grid_pts) #(9, num_points), (num_points,)\n",
        "        pol_sums_hi = np.sum(pol_pt_hi, axis = 1)\n",
        "        if all(item > 0 for item in pol_sums_hi):\n",
        "            print(f\"Min point fall for these extents : {num_grid_x}\")\n",
        "            return x\n",
        "            break\n",
        "        else:\n",
        "            print(num_grid_x)\n",
        "            num_grid_x += 1\n"
      ],
      "metadata": {
        "id": "bH9vk_LdCiPi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Argument Parser : Read jkt/java shape files\n",
        "    parser = argparse.ArgumentParser(description = \"Computational Grid\")\n",
        "    parser.add_argument(\"-jkt_shp_file_p\", type = str, default = \"data/processed/jkt/jkt_district_divisions/jkt_district_divisions.shp\", help = \"path to jkt region shape file\")\n",
        "    parser.add_argument(\"-java_shp_file_p\", type = str, default = \"data/processed/java/westjava_district_divisions/westjava_district_divisions.shp\", help = \"path to west java region shape file\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Read YAML file to get compute grid\n",
        "    with open(\"comp_grid_params.yaml\") as f:\n",
        "        comp_grid_params = yaml.safe_load(f)\n",
        "\n",
        "    # Load Data\n",
        "    df_jkt = gpd.read_file(args.jkt_shp_file_p)\n",
        "    df_java = gpd.read_file(args.java_shp_file_p)\n",
        "\n",
        "    # Number of grid points\n",
        "    num_grid_x = comp_grid_params[\"num_grids_x\"]\n",
        "\n",
        "    # Manually look at map and decide on a grid\n",
        "    extents = tuple(comp_grid_params[\"extents\"])\n",
        "    x, grid_pts = compute_grid(num_grid_x, extents)\n",
        "    print(f\"Num Grid Points : {grid_pts.shape}\")\n",
        "\n",
        "    pol_pts_jkt, pt_which_pol_jkt = get_points_in_region(df_jkt, grid_pts)\n",
        "    pol_pts_java, pt_which_pol_java = get_points_in_region(df_java, grid_pts)\n",
        "\n",
        "    # Plot grid to check if grid is accurate\n",
        "    plot_grid(df_jkt, grid_pts, file_name = \"comp_grid_jkt.png\")\n",
        "    plot_grid(df_java, grid_pts, file_name = \"comp_grid_java.png\")\n",
        "\n",
        "    print(\"saving files in 'data/processed'...\")\n",
        "\n",
        "    np.save(\"data/processed/lat_lon_x\", x)\n",
        "    np.save(\"data/processed/jkt/pol_pts_jkt\",pol_pts_jkt)\n",
        "    np.save(\"data/processed/jkt/pt_which_pol_jkt\",pt_which_pol_jkt)\n",
        "    np.save(\"data/processed/java/pol_pts_java\",pol_pts_java)\n",
        "    np.save(\"data/processed/java/pt_which_pol_java\",pt_which_pol_java)"
      ],
      "metadata": {
        "id": "8-JmpgF-Cmnh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}