{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14744,
     "status": "ok",
     "timestamp": 1741359684153,
     "user": {
      "displayName": "Jessica Widyawati",
      "userId": "04280305213402302223"
     },
     "user_tz": -480
    },
    "id": "oc6vDXCXH7y5",
    "outputId": "c626481d-bfea-4c46-d5ae-510bf9c4a9ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpyro\n",
      "  Downloading numpyro-0.17.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: jax>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from numpyro) (0.4.33)\n",
      "Requirement already satisfied: jaxlib>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from numpyro) (0.4.33)\n",
      "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from numpyro) (1.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from numpyro) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from numpyro) (4.67.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.25->numpyro) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.25->numpyro) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.25->numpyro) (1.13.1)\n",
      "Downloading numpyro-0.17.0-py3-none-any.whl (360 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.8/360.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpyro\n",
      "Successfully installed numpyro-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "error",
     "timestamp": 1741359868877,
     "user": {
      "displayName": "Jessica Widyawati",
      "userId": "04280305213402302223"
     },
     "user_tz": -480
    },
    "id": "nDjUgPoZOs5y",
    "outputId": "53e2b201-64d6-4eaf-e712-6afb44bda738"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aggGP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4589f8b940f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtermcolor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maggGP\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdist_euclid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_sq_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aggGP'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, lax, jit, ops\n",
    "from jax.example_libraries import stax\n",
    "\n",
    "import numpyro\n",
    "from numpyro.infer import SVI, MCMC, NUTS, init_to_median, Predictive, RenyiELBO\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import pickle\n",
    "\n",
    "jax.config.update(\"jax_default_device\", jax.devices()[1])\n",
    "print(f\"Jax using device : {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the functions necessary\n",
    "def dist_euclid(x, z):\n",
    "    \"\"\"\n",
    "    Computes Eucledian Distance Between Regions. This function is used by\n",
    "    exp_sq_kernel function (kernel function for gaussian processes)\n",
    "    \"\"\"\n",
    "    x = jnp.array(x) # (ngrid_pts, lat/lon) <- i.e (7304,2)\n",
    "    z = jnp.array(z) # (ngrid_pts, lat/lon) <- i.e (7304,2)\n",
    "    if len(x.shape)==1:\n",
    "        x = x.reshape(x.shape[0], 1) #(2618,) -> (7304,1)\n",
    "    if len(z.shape)==1:\n",
    "        z = x.reshape(x.shape[0], 1) #(2618,) -> (7304,1)\n",
    "    n_x, m = x.shape # 7304 , 2\n",
    "    n_z, m_z = z.shape # 7304 , 2\n",
    "    assert m == m_z\n",
    "    delta = jnp.zeros((n_x,n_z)) #(ngrid_pts,ngrid_pts) <- i.e (7304,7304)\n",
    "    for d in jnp.arange(m):\n",
    "        x_d = x[:,d] #(ngrid_pts-lat/lon,) <- (7304,)\n",
    "        z_d = z[:,d] #(ngrid_pts-lat/lon,) <- (7304,)\n",
    "        delta += (x_d[:,jnp.newaxis] - z_d)**2 # (7304,7304)\n",
    "\n",
    "    return jnp.sqrt(delta) #(7304,7304)\n",
    "\n",
    "def exp_sq_kernel(x, z, var, length, noise, jitter=1.0e-4):\n",
    "    dist = dist_euclid(x, z) #(7304, 7304)\n",
    "    deltaXsq = jnp.power(dist/ length, 2.0)\n",
    "    k = var * jnp.exp(-0.5 * deltaXsq)\n",
    "    k += (noise + jitter) * jnp.eye(x.shape[0])\n",
    "    return k # (ngrid_pts, ngrid_pts) <- (7304,7304)\n",
    "\n",
    "def M_g(M, g):\n",
    "    '''\n",
    "    - $M$ is a matrix with binary entries $m_{ij},$ showing whether point $j$ is in polygon $i$\n",
    "    - $g$ is a vector of GP draws over grid\n",
    "    - $maltmul(M, g)$ gives a vector of sums over each polygon\n",
    "    '''\n",
    "    M = jnp.array(M)\n",
    "    g = jnp.array(g).T\n",
    "    return(jnp.matmul(M, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpyAuFOQxOI"
   },
   "source": [
    "#AggVAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W35Bwle9YtgB"
   },
   "source": [
    "##Function for Predictive Simulation (Prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqpibNNMYxp5"
   },
   "outputs": [],
   "source": [
    "def gp_aggr(args):\n",
    "    x = args[\"x\"] # (num_grid_pts, lat+lon)\n",
    "    gp_kernel = args[\"gp_kernel\"]\n",
    "    noise = args[\"noise\"]\n",
    "\n",
    "    M= args[\"M\"]\n",
    "\n",
    "    #kernal hyperparams\n",
    "    kernal_length = args[\"kernel_length\"]\n",
    "    kernel_var = args[\"kernel_var\"]\n",
    "\n",
    "    # Random effect - aggregated GP\n",
    "    length = numpyro.sample(\"kernel_length\", kernal_length) #(,)\n",
    "    var = numpyro.sample(\"kernel_var\",kernel_var) #(,)\n",
    "    # Kernel for allgrid points\n",
    "    k = gp_kernel(x,x,var, length, noise) #(num_grig_pts,num_grid_pts)\n",
    "    # GP draw evaluated at all ... grid pints\n",
    "    f = numpyro.sample(\n",
    "        \"f\",\n",
    "        dist.MultivariateNormal(loc = jnp.zeros(x.shape[0]), covariance_matrix = k)\n",
    "        ) #(num_grid_pts,)\n",
    "\n",
    "    #aggregate f into gp_aggr according to indexing of (point in polygon)\n",
    "    gp_aggr = numpyro.deterministic(\"gp_aggr\", M_g(M, f)) #(num_regions,)\n",
    "\n",
    "    return gp_aggr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjA0_Y9YTBYf"
   },
   "source": [
    "##Define the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-qYl8VcTDzq"
   },
   "outputs": [],
   "source": [
    "def vae_encoder(hidden_dim = 50, z_dim = 40):\n",
    "    return stax.serial(\n",
    "        #(num_samples, num_regions) -> (num_samples, hidden_dims)\n",
    "        stax.Dense(hidden_dim, W_init = stax.randn()), #i.e(5,58) -> (5,50)\n",
    "        stax.Elu,\n",
    "        stax.FanOut(2),\n",
    "        stax.parallel(\n",
    "            # mean : (num_samples, hidden_dim) -> (num_samples, z_dim)\n",
    "            stax.Dense(z_dim, W_init = stax.randn()), #(5,50) -> (5,40)\n",
    "            #std : (num_samples, hidden_dim) -> (num_samples, z_dim)\n",
    "            stax.serial(stax.Dense(z_dim, W_init = stax.randn()), stax.Exp) #(5,50) -> (5,40)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def vae_decoder(hidden_dim, out_dim):\n",
    "    return stax.serial(\n",
    "        # (num_samples, z_dim) -> (num_samples, hidden_dim): (5,40) -> (5,50)\n",
    "        stax.Dense(hidden_dim, W_init = stax.randn()),\n",
    "        stax.Elu,\n",
    "        # (num_samples, hidden_dim) -> (num_samples, num_regions) : (5,50) -> (5, 58)\n",
    "        stax.Dense(out_dim, W_init = stax.randn())\n",
    "    )\n",
    "\n",
    "\n",
    "def vae_model(batch, hidden_dim, z_dim):\n",
    "    \"\"\"This computes the decoder portion\"\"\"\n",
    "    batch = jnp.reshape(batch, (batch.shape[0], -1)) # (num_samples, num_regions) <- i.e (5,58)\n",
    "    batch_dim, out_dim = jnp.shape(batch) # 5 , 58\n",
    "\n",
    "    # vae-decoder in numpyro module\n",
    "    decode = numpyro.module(\n",
    "        name = \"decoder\",\n",
    "        nn = vae_decoder(hidden_dim = hidden_dim, out_dim = out_dim),\n",
    "        input_shape = (batch_dim, z_dim) #(5,40)\n",
    "    )\n",
    "\n",
    "    # Sample a univariate normal\n",
    "    #! ISSUE HERE : lax.sub cannot broadcast shapes (5,40) & (40,) here\n",
    "    #! SO HAD TO CHANGE dist.Normal(jnp.zeros((z_dim,)), jnp.ones((z_dim,))) TO THIS dist.Normal(jnp.zeros((5,z_dim)), jnp.ones((5,z_dim)))\n",
    "    z = numpyro.sample(\n",
    "        \"z\",\n",
    "        dist.Normal(\n",
    "            jnp.zeros((batch_dim,z_dim)),\n",
    "            jnp.ones((batch_dim,z_dim))\n",
    "            )\n",
    "    ) # (z_dim,) : i.e (40,)\n",
    "    # Forward pass from decoder\n",
    "    gen_loc = decode(z) #(num_regions,) : (58,)\n",
    "    obs = numpyro.sample(\n",
    "        \"obs\",\n",
    "        dist.Normal(gen_loc, args[\"vae_var\"]),\n",
    "        obs = batch\n",
    "    ) #(num_samples, num_regions) : (5,58)\n",
    "    return obs\n",
    "\n",
    "\n",
    "def vae_guide(batch, hidden_dim, z_dim):\n",
    "    \"\"\"This computes the encoder portion\"\"\"\n",
    "    batch = jnp.reshape(batch, (batch.shape[0], -1)) #(num_samples, num_regions) : (5,58)\n",
    "    batch_dim, input_dim = jnp.shape(batch)# num_samples , num_regions : 5 , 58\n",
    "\n",
    "    # vae-encoder in numpyro module\n",
    "    encode = numpyro.module(\n",
    "        name = \"encoder\",\n",
    "        nn = vae_encoder(hidden_dim=hidden_dim,z_dim = z_dim),\n",
    "        input_shape = (batch_dim, input_dim) #(5,58)\n",
    "    ) #(num_samples, num_regions) -> (num_samples, hidden_dims) : i.e (5,58) -> (5,40)\n",
    "\n",
    "    # Samapling mu, sigma - Pretty much the forward pass\n",
    "    z_loc, z_std = encode(batch) #mu : (num_samples, z_dim), sigma2 : (num_samples, z_dim) <- (5,40),(5,40)\n",
    "    # Sample a value z based on mu and sigma\n",
    "    z = numpyro.sample(\"z\", dist.Normal(z_loc, z_std)) #(num_sample, z_dim) : (5,40)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA7tPNDnWgpG"
   },
   "source": [
    "##Train the VAE encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8_MUf7FWlAX"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def epoch_train(rng_key, svi_state, num_train):\n",
    "    def body_fn(i, val):\n",
    "        rng_key_i = jax.random.fold_in(rng_key, i) #Array(2,)\n",
    "        rng_key_i, rng_key_ls, rng_key_var, rng_key_noise = jax.random.split(rng_key_i, 4) #Tuple(Array(2,) x 4)\n",
    "        loss_sum, svi_state = val #val --svi_state\n",
    "\n",
    "        batch = agg_gp_predictive(rng_key_i, args)[\"gp_aggr\"] #(5,116) <- num_samples : 5, total_districts : 116\n",
    "        #* svi is where the vae_model & vae_guide gets applied\n",
    "        svi_state, loss = svi.update(svi_state, batch)\n",
    "        loss_sum += loss / args[\"batch_size\"]\n",
    "        return loss_sum, svi_state\n",
    "\n",
    "    return lax.fori_loop(lower = 0, upper = num_train, body_fun=body_fn, init_val=(0.0, svi_state))\n",
    "\n",
    "@jax.jit\n",
    "def eval_test(rng_key, svi_state, num_test):\n",
    "    def body_fn(i, loss_sum):\n",
    "        rng_key_i = jax.random.fold_in(rng_key, i)\n",
    "        rng_key_i, rng_key_ls, rng_key_varm, rng_key_noise = jax.random.split(rng_key_i, 4)\n",
    "        batch = agg_gp_predictive(rng_key_i, args)[\"gp_aggr\"]\n",
    "        #* svi is where the vae_model & vae_guide gets applied\n",
    "        loss = svi.evaluate(svi_state, batch) / args[\"batch_size\"]\n",
    "        loss_sum += loss\n",
    "        return loss_sum\n",
    "\n",
    "    loss = lax.fori_loop(lower = 0, upper = num_test,body_fun =  body_fn, init_val = 0.0)\n",
    "    loss = loss / num_test\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHkZ6dqhTEKl"
   },
   "source": [
    "##Function to plot the GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rke7xN5TJts"
   },
   "outputs": [],
   "source": [
    "def plot_process(gp_draws):\n",
    "    p = px.line()\n",
    "    for i in range(len(gp_draws)):\n",
    "        p.add_scatter(x = np.arange(gp_draws.shape[1]), y = gp_draws[i, :])\n",
    "\n",
    "    p.update_traces(line_color = \"black\")\n",
    "    p.update_layout(\n",
    "        template = \"plotly_white\",\n",
    "        xaxis_title = \"region\", yaxis_title = \"num cases\",\n",
    "        showlegend = False)\n",
    "    p.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Egml-fn9TKMJ"
   },
   "source": [
    "##Load the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veD2sogTTMIc"
   },
   "outputs": [],
   "source": [
    "# Lat/Lon Values of artificial grid\n",
    "x = np.load(\"lat_lon_x.npy\")\n",
    "pol_pts_all = np.load(\"pol_pts_all.npy\")\n",
    "pt_which_pol_all = np.load(\"pt_which_pol_all.npy\")\n",
    "\n",
    "df_combined = gpd.read_file(\"final_district_divisions.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgiCqcl7TDwR"
   },
   "source": [
    "##Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D79oQ7R-THBC"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"x\": x,\n",
    "        \"gp_kernel\": exp_sq_kernel,\n",
    "        \"noise\": 1e-4,\n",
    "        \"M\": pol_pts_all,\n",
    "\n",
    "        # VAE training\n",
    "        \"rng_key\": random.PRNGKey(5),\n",
    "        \"num_epochs\": 20,\n",
    "        #\"learning_rate\": 1.0e-3,\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"batch_size\": 100,\n",
    "        \"hidden_dim\": 50,\n",
    "        \"z_dim\": 40,\n",
    "        \"num_train\": 100,\n",
    "        \"num_test\":100,\n",
    "        \"vae_var\": 1,\n",
    "        # kernel hyperparams\n",
    "        \"kernel_length\" : dist.InverseGamma(3,3), #!hyperparam\n",
    "        \"kernel_var\" : dist.HalfNormal(0.05) #!hyperparam\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dp6EFT7RTLKZ"
   },
   "source": [
    "##Prior predictive simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72dE-HgATNBA"
   },
   "outputs": [],
   "source": [
    "rng_key, rng_key_ = random.split(random.PRNGKey(4))\n",
    "agg_gp_predictive = Predictive(gp_aggr,num_samples = 5)\n",
    "\n",
    "agg_gp_draws = agg_gp_predictive(rng_key_, args)[\"gp_aggr\"] #(num_samples, num_regions) <- (5,58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMnPLKZwJrO5"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_process(agg_gp_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb1HhnafTooi"
   },
   "source": [
    "##Initiate Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NR2_Or-Tq_E"
   },
   "outputs": [],
   "source": [
    "adam = numpyro.optim.Adam(step_size = args[\"learning_rate\"])\n",
    "svi = SVI(\n",
    "        vae_model,\n",
    "        vae_guide,\n",
    "        adam,\n",
    "        RenyiELBO(),\n",
    "        hidden_dim = args[\"hidden_dim\"],\n",
    "        z_dim = args[\"z_dim\"]\n",
    "    )\n",
    "\n",
    "rng_key, rng_key_samp, rng_key_init = random.split(args[\"rng_key\"],3)\n",
    "#(num_samples, num_regions)\n",
    "init_batch = agg_gp_predictive(rng_key_, args)[\"gp_aggr\"] #(num_samples, num_regions) <- i.e (5,58)\n",
    "svi_state = svi.init(rng_key_init, init_batch)\n",
    "\n",
    "test_loss_list = []\n",
    "for i in range(args[\"num_epochs\"]):\n",
    "    rng_key, rng_key_train, rng_key_test, rng_key_infer = random.split(rng_key, 4)\n",
    "    t_start = time.time()\n",
    "\n",
    "    num_train = 1000\n",
    "    # Where forward/backward pass gets called for train\n",
    "    train_loss , svi_state = epoch_train(rng_key_train, svi_state, num_train)\n",
    "\n",
    "    num_test = 1000\n",
    "    # Where forward/backward pass gets called for test\n",
    "    test_loss = eval_test(rng_key_test, svi_state, num_test)\n",
    "    test_loss_list += [test_loss]\n",
    "\n",
    "    print(\"Epoch : {}, train loss : {:.2f}, test loss : {:.2f} ({:.2f} s.)\".format(i, train_loss, test_loss, time.time() - t_start))\n",
    "\n",
    "    if math.isnan(test_loss):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check initial SVI state\n",
    "print(\"svi_state:\", svi_state.optim_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fldbVSkT0RR"
   },
   "source": [
    "##Save the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9zDJExcT1OB"
   },
   "outputs": [],
   "source": [
    "# save decoder\n",
    "decoder_params = svi.get_params(svi_state)\n",
    "save_path = f\"model_weights/aggVAE_e{args['num_epochs']}_h{args['hidden_dim']}_z{args['z_dim']}\"\n",
    "\n",
    "with open(save_path, \"wb\") as file:\n",
    "    pickle.dump(decoder_params, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNShaHgowPI8Lg77TRpeLq/",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
