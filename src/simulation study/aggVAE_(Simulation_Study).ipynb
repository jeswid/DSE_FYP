{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpyro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc6vDXCXH7y5",
        "outputId": "21ceaa12-427c-4331-c552-2091a031d667"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpyro\n",
            "  Downloading numpyro-0.18.0-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: jax>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from numpyro) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from numpyro) (0.5.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from numpyro) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from numpyro) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from numpyro) (4.67.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.25->numpyro) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.25->numpyro) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.25->numpyro) (1.14.1)\n",
            "Downloading numpyro-0.18.0-py3-none-any.whl (365 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/365.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m358.4/365.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpyro\n",
            "Successfully installed numpyro-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nDjUgPoZOs5y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import time\n",
        "\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random, lax, jit, ops\n",
        "from jax.example_libraries import stax\n",
        "\n",
        "import numpyro\n",
        "from numpyro.infer import SVI, MCMC, NUTS, init_to_median, Predictive, RenyiELBO\n",
        "import numpyro.distributions as dist\n",
        "\n",
        "import geopandas as gpd\n",
        "import plotly.express as px\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensure this script runs on GPU 1\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Use GPU 1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Script B running on {device}\")"
      ],
      "metadata": {
        "id": "1SeHa4ZBTSsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the functions necessary\n",
        "def dist_euclid(x, z):\n",
        "    \"\"\"\n",
        "    Computes Eucledian Distance Between Regions. This function is used by\n",
        "    exp_sq_kernel function (kernel function for gaussian processes)\n",
        "    \"\"\"\n",
        "    x = jnp.array(x) # (ngrid_pts, lat/lon) <- i.e (7304,2)\n",
        "    z = jnp.array(z) # (ngrid_pts, lat/lon) <- i.e (7304,2)\n",
        "    if len(x.shape)==1:\n",
        "        x = x.reshape(x.shape[0], 1) #(2618,) -> (7304,1)\n",
        "    if len(z.shape)==1:\n",
        "        z = x.reshape(x.shape[0], 1) #(2618,) -> (7304,1)\n",
        "    n_x, m = x.shape # 7304 , 2\n",
        "    n_z, m_z = z.shape # 7304 , 2\n",
        "    assert m == m_z\n",
        "    delta = jnp.zeros((n_x,n_z)) #(ngrid_pts,ngrid_pts) <- i.e (7304,7304)\n",
        "    for d in jnp.arange(m):\n",
        "        x_d = x[:,d] #(ngrid_pts-lat/lon,) <- (7304,)\n",
        "        z_d = z[:,d] #(ngrid_pts-lat/lon,) <- (7304,)\n",
        "        delta += (x_d[:,jnp.newaxis] - z_d)**2 # (7304,7304)\n",
        "\n",
        "    return jnp.sqrt(delta) #(7304,7304)\n",
        "\n",
        "def exp_sq_kernel(x, z, var, length, noise, jitter=1.0e-4):\n",
        "    dist = dist_euclid(x, z) #(7304, 7304)\n",
        "    deltaXsq = jnp.power(dist/ length, 2.0)\n",
        "    k = var * jnp.exp(-0.5 * deltaXsq)\n",
        "    k += (noise + jitter) * jnp.eye(x.shape[0])\n",
        "    return k # (ngrid_pts, ngrid_pts) <- (7304,7304)\n",
        "\n",
        "def M_g(M, g):\n",
        "    '''\n",
        "    - $M$ is a matrix with binary entries $m_{ij},$ showing whether point $j$ is in polygon $i$\n",
        "    - $g$ is a vector of GP draws over grid\n",
        "    - $maltmul(M, g)$ gives a vector of sums over each polygon\n",
        "    '''\n",
        "    M = jnp.array(M)\n",
        "    g = jnp.array(g).T\n",
        "    return(jnp.matmul(M, g))"
      ],
      "metadata": {
        "id": "RWApQLwlTWKD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AggVAE Model"
      ],
      "metadata": {
        "id": "AOpyAuFOQxOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function for Predictive Simulation (Prior)"
      ],
      "metadata": {
        "id": "W35Bwle9YtgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gp_aggr(args):\n",
        "    x = args[\"x\"]  # Spatial grid points: (num_grid_points, 2)\n",
        "    gp_kernel = args[\"gp_kernel\"]  # Gaussian Process kernel\n",
        "    noise = args[\"noise\"]\n",
        "    jitter = args[\"jitter\"]\n",
        "    M = args[\"M\"]  # (num_districts, num_grid_points) aggregation matrix\n",
        "\n",
        "    # GP hyperparameters\n",
        "    kernel_length = numpyro.sample(\"kernel_length\", args[\"kernel_length\"])\n",
        "    kernel_var = numpyro.sample(\"kernel_var\", args[\"kernel_var\"])\n",
        "\n",
        "    # GP Kernel and Sample\n",
        "    k = gp_kernel(x, x, kernel_var, kernel_length, noise, jitter)\n",
        "    f = numpyro.sample(\"f\", dist.MultivariateNormal(loc=jnp.zeros(x.shape[0]), covariance_matrix=k))  # (num_grid_points,)\n",
        "\n",
        "    # Aggregate GP values to district level\n",
        "    gp_aggr = numpyro.deterministic(\"gp_aggr\", M @ f)  # (num_districts,)\n",
        "\n",
        "    return gp_aggr"
      ],
      "metadata": {
        "id": "pqpibNNMYxp5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the VAE"
      ],
      "metadata": {
        "id": "yjA0_Y9YTBYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_encoder(hidden_dim = 50, z_dim = 40):\n",
        "    return stax.serial(\n",
        "        #(num_samples, num_regions) -> (num_samples, hidden_dims)\n",
        "        stax.Dense(hidden_dim, W_init = stax.randn()),\n",
        "        stax.Elu,\n",
        "        stax.FanOut(2),\n",
        "        stax.parallel(\n",
        "            # mean : (num_samples, hidden_dim) -> (num_samples, z_dim)\n",
        "            stax.Dense(z_dim, W_init = stax.randn()), #(5,50)\n",
        "            #std : (num_samples, hidden_dim) -> (num_samples, z_dim)\n",
        "            stax.serial(stax.Dense(z_dim, W_init = stax.randn()), stax.Exp)\n",
        "        )\n",
        "    )\n",
        "\n",
        "def vae_decoder(hidden_dim, out_dim):\n",
        "    return stax.serial(\n",
        "        # (num_samples, z_dim) -> (num_samples, hidden_dim)\n",
        "        stax.Dense(hidden_dim, W_init = stax.randn()),\n",
        "        stax.Elu,\n",
        "        # (num_samples, hidden_dim) -> (num_samples, num_regions)\n",
        "        stax.Dense(out_dim, W_init = stax.randn())\n",
        "    )\n",
        "\n",
        "\n",
        "def vae_model(batch, hidden_dim, z_dim):\n",
        "    \"\"\"This computes the decoder portion\"\"\"\n",
        "    batch = jnp.reshape(batch, (batch.shape[0], -1)) # (num_samples, num_regions)\n",
        "    batch_dim, out_dim = jnp.shape(batch)\n",
        "\n",
        "    # vae-decoder in numpyro module\n",
        "    decode = numpyro.module(\n",
        "        name = \"decoder\",\n",
        "        nn = vae_decoder(hidden_dim = hidden_dim, out_dim = out_dim),\n",
        "        input_shape = (batch_dim, z_dim) #(5,40)\n",
        "    )\n",
        "\n",
        "    # Sample a univariate normal\n",
        "    z = numpyro.sample(\n",
        "        \"z\",\n",
        "        dist.Normal(\n",
        "            jnp.zeros((batch_dim,z_dim)),\n",
        "            jnp.ones((batch_dim,z_dim))\n",
        "            )\n",
        "    )\n",
        "    # Forward pass from decoder\n",
        "    gen_loc = decode(z) #(num_regions,)\n",
        "    obs = numpyro.sample(\n",
        "        \"obs\",\n",
        "        dist.Normal(gen_loc, args[\"vae_var\"]),\n",
        "        obs = batch\n",
        "    ) #(num_samples, num_regions)\n",
        "    return obs\n",
        "\n",
        "\n",
        "def vae_guide(batch, hidden_dim, z_dim):\n",
        "    \"\"\"This computes the encoder portion\"\"\"\n",
        "    batch = jnp.reshape(batch, (batch.shape[0], -1)) #(num_samples, num_regions)\n",
        "    batch_dim, input_dim = jnp.shape(batch)# num_samples , num_regions\n",
        "\n",
        "    # vae-encoder in numpyro module\n",
        "    encode = numpyro.module(\n",
        "        name = \"encoder\",\n",
        "        nn = vae_encoder(hidden_dim=hidden_dim,z_dim = z_dim),\n",
        "        input_shape = (batch_dim, input_dim) #(5,58)\n",
        "    ) #(num_samples, num_regions) -> (num_samples, hidden_dims)\n",
        "\n",
        "    # Samapling mu, sigma - Pretty much the forward pass\n",
        "    z_loc, z_std = encode(batch) #mu : (num_samples, z_dim), sigma2 : (num_samples, z_dim)\n",
        "    # Sample a value z based on mu and sigma\n",
        "    z = numpyro.sample(\"z\", dist.Normal(z_loc, z_std)) #(num_sample, z_dim)\n",
        "    return z"
      ],
      "metadata": {
        "id": "8-qYl8VcTDzq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the VAE encoder"
      ],
      "metadata": {
        "id": "EA7tPNDnWgpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def epoch_train(rng_key, svi_state, num_train):\n",
        "    def body_fn(i, val):\n",
        "        rng_key_i = jax.random.fold_in(rng_key, i) #Array(2,)\n",
        "        rng_key_i, rng_key_ls, rng_key_var, rng_key_noise = jax.random.split(rng_key_i, 4) #Tuple(Array(2,) x 4)\n",
        "        loss_sum, svi_state = val #val --svi_state\n",
        "\n",
        "        batch = agg_gp_predictive(rng_key_i, args)[\"gp_aggr\"] #(5,116) <- num_samples : 5, total_districts : 116\n",
        "        #* svi is where the vae_model & vae_guide gets applied\n",
        "        svi_state, loss = svi.update(svi_state, batch)\n",
        "        loss_sum += loss / args[\"batch_size\"]\n",
        "        return loss_sum, svi_state\n",
        "\n",
        "    return lax.fori_loop(lower = 0, upper = num_train, body_fun=body_fn, init_val=(0.0, svi_state))\n",
        "\n",
        "@jax.jit\n",
        "def eval_test(rng_key, svi_state, num_test):\n",
        "    def body_fn(i, loss_sum):\n",
        "        rng_key_i = jax.random.fold_in(rng_key, i)\n",
        "        rng_key_i, rng_key_ls, rng_key_varm, rng_key_noise = jax.random.split(rng_key_i, 4)\n",
        "        batch = agg_gp_predictive(rng_key_i, args)[\"gp_aggr\"]\n",
        "        #* svi is where the vae_model & vae_guide gets applied\n",
        "        loss = svi.evaluate(svi_state, batch) / args[\"batch_size\"]\n",
        "        loss_sum += loss\n",
        "        return loss_sum\n",
        "\n",
        "    loss = lax.fori_loop(lower = 0, upper = num_test,body_fun =  body_fn, init_val = 0.0)\n",
        "    loss = loss / num_test\n",
        "    return loss"
      ],
      "metadata": {
        "id": "D8_MUf7FWlAX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function to plot the GP"
      ],
      "metadata": {
        "id": "HHkZ6dqhTEKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_process(gp_draws):\n",
        "    p = px.line()\n",
        "    for i in range(len(gp_draws)):\n",
        "        p.add_scatter(x = np.arange(gp_draws.shape[1]), y = gp_draws[i, :])\n",
        "\n",
        "    p.update_traces(line_color = \"black\")\n",
        "    p.update_layout(\n",
        "        template = \"plotly_white\",\n",
        "        xaxis_title = \"region\", yaxis_title = \"num cases\",\n",
        "        showlegend = False)\n",
        "    p.show()"
      ],
      "metadata": {
        "id": "7rke7xN5TJts"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the variables"
      ],
      "metadata": {
        "id": "Egml-fn9TKMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lat/Lon Values of artificial grid\n",
        "x = np.load(\"lat_lon_x_jkt.npy\")\n",
        "pol_pts_jkt = np.load(\"pol_pts_jkt.npy\")\n",
        "pt_which_pol_jkt = np.load(\"pt_which_pol_jkt.npy\")\n",
        "\n",
        "df_combined = gpd.read_file(\"jkt_combined_divisions.shp\")"
      ],
      "metadata": {
        "id": "veD2sogTTMIc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Arguments"
      ],
      "metadata": {
        "id": "DgiCqcl7TDwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "        \"x\": x,\n",
        "        \"gp_kernel\": exp_sq_kernel,\n",
        "        \"noise\": 1e-4,\n",
        "        \"M\": jnp.array(pol_pts_jkt),\n",
        "        \"jitter\" : 1e-4,\n",
        "        # VAE training\n",
        "        \"rng_key\": random.PRNGKey(5),\n",
        "        #common num_epochs 20-50\n",
        "        \"num_epochs\": 20,\n",
        "        #learning rate 0.0005 common choice, ADAM optimiser adapts the learning rate accordingly\n",
        "        \"learning_rate\": 0.0005,\n",
        "        #chosen to be 100 (no tune)\n",
        "        \"batch_size\": 100,\n",
        "        #change this to the optimal values after hyperparameter tuning\n",
        "        \"hidden_dim\": 30,\n",
        "        \"z_dim\": 40,\n",
        "        #chosen to be 100 (no tune)\n",
        "        \"num_train\": 100,\n",
        "        \"num_test\":100,\n",
        "        #variance set to 1 bc the latent variable prior distribution is assumed to be normal\n",
        "        \"vae_var\": 1,\n",
        "        \"kernel_length\": dist.InverseGamma(3,3),\n",
        "        \"kernel_var\": dist.HalfNormal(1e-5)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "D79oQ7R-THBC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prior predictive simulation"
      ],
      "metadata": {
        "id": "dp6EFT7RTLKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng_key, rng_key_ = random.split(random.PRNGKey(4))\n",
        "agg_gp_predictive = Predictive(gp_aggr,num_samples = 5)\n",
        "agg_gp_draws = agg_gp_predictive(rng_key_, args)[\"gp_aggr\"] #(num_samples, num_regions)"
      ],
      "metadata": {
        "id": "72dE-HgATNBA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "plot_process(agg_gp_draws)"
      ],
      "metadata": {
        "id": "KMnPLKZwJrO5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c22725f1-6f23-4b3a-9f7c-a65b56a7bc7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"641e0af8-4296-4eea-b9a5-bae4d50fa4a2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"641e0af8-4296-4eea-b9a5-bae4d50fa4a2\")) {                    Plotly.newPlot(                        \"641e0af8-4296-4eea-b9a5-bae4d50fa4a2\",                        [{\"hovertemplate\":\"\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"black\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[-0.0008642459,-0.0008642459,-0.0008642459,-0.0008642459,0.047228213,0.047228213,0.047228213,0.047228213,0.042516686,0.042516686,0.042516686,0.042516686,0.043449983,0.043449983,0.043449983,0.043449983,-0.029601205,-0.029601205,-0.029601205,-0.029601205],\"type\":\"scatter\",\"line\":{\"color\":\"black\"}},{\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.055798307,0.055798307,0.055798307,0.055798307,-0.0045364825,-0.0045364825,-0.0045364825,-0.0045364825,0.08187002,0.08187002,0.08187002,0.08187002,-0.01654052,-0.01654052,-0.01654052,-0.01654052,-0.0063288976,-0.0063288976,-0.0063288976,-0.0063288976],\"type\":\"scatter\",\"line\":{\"color\":\"black\"}},{\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.010631271,0.010631271,0.010631271,0.010631271,0.03557033,0.03557033,0.03557033,0.03557033,-0.06984117,-0.06984117,-0.06984117,-0.06984117,0.07848169,0.07848169,0.07848169,0.07848169,-0.03564187,-0.03564187,-0.03564187,-0.03564187],\"type\":\"scatter\",\"line\":{\"color\":\"black\"}},{\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[-0.11175458,-0.11175458,-0.11175458,-0.11175458,-0.04267596,-0.04267596,-0.04267596,-0.04267596,-0.05681751,-0.05681751,-0.05681751,-0.05681751,-0.065383606,-0.065383606,-0.065383606,-0.065383606,-0.10577324,-0.10577324,-0.10577324,-0.10577324],\"type\":\"scatter\",\"line\":{\"color\":\"black\"}},{\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.062131017,0.062131017,0.062131017,0.062131017,0.011629441,0.011629441,0.011629441,0.011629441,-0.08470759,-0.08470759,-0.08470759,-0.08470759,-0.010599414,-0.010599414,-0.010599414,-0.010599414,0.07805176,0.07805176,0.07805176,0.07805176],\"type\":\"scatter\",\"line\":{\"color\":\"black\"}}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"region\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"num cases\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('641e0af8-4296-4eea-b9a5-bae4d50fa4a2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "24YH-_biUJG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter grid\n",
        "hidden_dims = [20, 30, 40, 50]\n",
        "z_dims = [20, 30, 40, 50]\n",
        "\n",
        "# Store results\n",
        "test_loss_results_final = {}\n",
        "test_loss_results_mean = {}\n",
        "\n",
        "num_train = args[\"num_train\"]\n",
        "num_test = args[\"num_test\"]\n",
        "num_epochs = args[\"num_epochs\"]\n",
        "\n",
        "for hidden_dim, z_dim in itertools.product(hidden_dims, z_dims):\n",
        "    print(f\"Training with hidden_dim={hidden_dim}, z_dim={z_dim}\")\n",
        "\n",
        "    args[\"hidden_dim\"] = hidden_dim\n",
        "    args[\"z_dim\"] = z_dim\n",
        "\n",
        "    # Initialize optimizer and SVI\n",
        "    adam = numpyro.optim.Adam(step_size=args[\"learning_rate\"])\n",
        "    svi = SVI(\n",
        "        vae_model,\n",
        "        vae_guide,\n",
        "        adam,\n",
        "        RenyiELBO(),\n",
        "        hidden_dim=hidden_dim,\n",
        "        z_dim=z_dim\n",
        "    )\n",
        "\n",
        "    # Split RNG keys\n",
        "    rng_key, rng_key_samp, rng_key_init = random.split(args[\"rng_key\"], 3)\n",
        "    init_batch = agg_gp_predictive(rng_key_samp, args)[\"gp_aggr\"]\n",
        "\n",
        "    # Initialize SVI state\n",
        "    svi_state = svi.init(rng_key_init, init_batch)\n",
        "\n",
        "    # Pre-allocate test loss array\n",
        "    test_loss_list = jnp.zeros(num_epochs)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        rng_key, rng_key_train, rng_key_test = random.split(rng_key, 3)\n",
        "        t_start = time.time()\n",
        "\n",
        "        train_loss, svi_state = epoch_train(rng_key_train, svi_state, num_train)\n",
        "        test_loss = eval_test(rng_key_test, svi_state, num_test)\n",
        "        test_loss_list = test_loss_list.at[epoch].set(test_loss)\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f} ({time.time() - t_start:.2f} s)\")\n",
        "\n",
        "        if math.isnan(test_loss):  # Stop early if NaN\n",
        "            print(f\"NaN encountered at hidden_dim={hidden_dim}, z_dim={z_dim}. Skipping...\")\n",
        "            break  # Stop training if NaN occurs\n",
        "\n",
        "    # Store results only if valid\n",
        "    if not math.isnan(test_loss_list[-1]):\n",
        "        test_loss_results_final[(hidden_dim, z_dim)] = test_loss_list[-1]\n",
        "        test_loss_results_mean[(hidden_dim, z_dim)] = jnp.nanmean(test_loss_list)\n",
        "        print(f\"Final Test loss for hidden_dim={hidden_dim}, z_dim={z_dim}: {test_loss_list[-1]}\")\n",
        "        print(f\"Mean Test loss for hidden_dim={hidden_dim}, z_dim={z_dim}: {jnp.nanmean(test_loss_list)}\")\n",
        "\n",
        "print(\"Grid search complete.\")\n",
        "print(\"Results:\", test_loss_results_final)\n",
        "print(\"Mean Test Loss Results:\", test_loss_results_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldon-7FAUM1i",
        "outputId": "5733b51e-1e3a-4ddd-8166-d21ba68e06fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with hidden_dim=20, z_dim=20\n",
            "Epoch: 0, Train Loss: 92.06, Test Loss: 0.92 (9.48 s)\n",
            "Epoch: 1, Train Loss: 92.07, Test Loss: 0.92 (0.28 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 3, Train Loss: 92.08, Test Loss: 0.92 (0.49 s)\n",
            "Epoch: 4, Train Loss: 92.09, Test Loss: 0.92 (0.42 s)\n",
            "Epoch: 5, Train Loss: 92.09, Test Loss: 0.92 (0.50 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.74 s)\n",
            "Epoch: 7, Train Loss: 92.09, Test Loss: 0.92 (0.67 s)\n",
            "Epoch: 8, Train Loss: 92.08, Test Loss: 0.92 (0.65 s)\n",
            "Epoch: 9, Train Loss: 92.05, Test Loss: 0.92 (0.52 s)\n",
            "Epoch: 10, Train Loss: 92.05, Test Loss: 0.92 (0.46 s)\n",
            "Epoch: 11, Train Loss: 92.11, Test Loss: 0.92 (0.38 s)\n",
            "Epoch: 12, Train Loss: 92.13, Test Loss: 0.92 (0.29 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 14, Train Loss: 92.10, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 15, Train Loss: 92.06, Test Loss: 0.92 (0.30 s)\n",
            "Epoch: 16, Train Loss: 92.05, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 18, Train Loss: 92.06, Test Loss: 0.92 (0.39 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.40 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=20: 0.9231060147285461\n",
            "Mean Test loss for hidden_dim=20, z_dim=20: 0.9207326769828796\n",
            "Training with hidden_dim=20, z_dim=30\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (9.83 s)\n",
            "Epoch: 1, Train Loss: 92.06, Test Loss: 0.92 (0.25 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 3, Train Loss: 92.07, Test Loss: 0.92 (0.28 s)\n",
            "Epoch: 4, Train Loss: 92.07, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.24 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 7, Train Loss: 92.10, Test Loss: 0.92 (0.29 s)\n",
            "Epoch: 8, Train Loss: 92.07, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 10, Train Loss: 92.07, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 11, Train Loss: 92.09, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 12, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.05, Test Loss: 0.93 (0.17 s)\n",
            "Epoch: 18, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 19, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=30: 0.9201498627662659\n",
            "Mean Test loss for hidden_dim=20, z_dim=30: 0.9213196039199829\n",
            "Training with hidden_dim=20, z_dim=40\n",
            "Epoch: 0, Train Loss: 92.05, Test Loss: 0.92 (8.57 s)\n",
            "Epoch: 1, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 6, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 7, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 8, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 12, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 13, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.05, Test Loss: 0.92 (0.14 s)\n",
            "Epoch: 16, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 19, Train Loss: 92.05, Test Loss: 0.92 (0.14 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=40: 0.9173188209533691\n",
            "Mean Test loss for hidden_dim=20, z_dim=40: 0.9207714200019836\n",
            "Training with hidden_dim=20, z_dim=50\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (9.19 s)\n",
            "Epoch: 1, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 5, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 6, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 7, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 8, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 9, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 13, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 14, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.06, Test Loss: 0.93 (0.15 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 19, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=50: 0.9182264804840088\n",
            "Mean Test loss for hidden_dim=20, z_dim=50: 0.9211856126785278\n",
            "Training with hidden_dim=30, z_dim=20\n",
            "Epoch: 0, Train Loss: 92.06, Test Loss: 0.92 (11.11 s)\n",
            "Epoch: 1, Train Loss: 92.07, Test Loss: 0.92 (0.48 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.54 s)\n",
            "Epoch: 3, Train Loss: 92.08, Test Loss: 0.92 (0.44 s)\n",
            "Epoch: 4, Train Loss: 92.09, Test Loss: 0.92 (0.39 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.23 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 7, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 8, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.13, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 14, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.07, Test Loss: 0.92 (0.21 s)\n",
            "Epoch: 16, Train Loss: 92.05, Test Loss: 0.92 (0.25 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.24 s)\n",
            "Epoch: 18, Train Loss: 92.06, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.25 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=20: 0.923116147518158\n",
            "Mean Test loss for hidden_dim=30, z_dim=20: 0.9207401275634766\n",
            "Training with hidden_dim=30, z_dim=30\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (12.95 s)\n",
            "Epoch: 1, Train Loss: 92.06, Test Loss: 0.92 (0.51 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.59 s)\n",
            "Epoch: 3, Train Loss: 92.07, Test Loss: 0.92 (0.40 s)\n",
            "Epoch: 4, Train Loss: 92.07, Test Loss: 0.92 (0.31 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 7, Train Loss: 92.10, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 8, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.09, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 12, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.05, Test Loss: 0.93 (0.15 s)\n",
            "Epoch: 18, Train Loss: 92.07, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=30: 0.9201259016990662\n",
            "Mean Test loss for hidden_dim=30, z_dim=30: 0.9213138818740845\n",
            "Training with hidden_dim=30, z_dim=40\n",
            "Epoch: 0, Train Loss: 92.05, Test Loss: 0.92 (8.88 s)\n",
            "Epoch: 1, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 4, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 6, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 7, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 8, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 12, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 13, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 14, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 19, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=40: 0.917217493057251\n",
            "Mean Test loss for hidden_dim=30, z_dim=40: 0.9207998514175415\n",
            "Training with hidden_dim=30, z_dim=50\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (9.67 s)\n",
            "Epoch: 1, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.11, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 5, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 6, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 7, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 8, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.06, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 12, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 13, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 17, Train Loss: 92.06, Test Loss: 0.93 (0.17 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 19, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=50: 0.9181046485900879\n",
            "Mean Test loss for hidden_dim=30, z_dim=50: 0.9212174415588379\n",
            "Training with hidden_dim=40, z_dim=20\n",
            "Epoch: 0, Train Loss: 92.06, Test Loss: 0.92 (8.76 s)\n",
            "Epoch: 1, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 3, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.19 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 7, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 8, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 10, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.11, Test Loss: 0.92 (0.14 s)\n",
            "Epoch: 12, Train Loss: 92.13, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 16, Train Loss: 92.05, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 18, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=20: 0.9231770038604736\n",
            "Mean Test loss for hidden_dim=40, z_dim=20: 0.9207643270492554\n",
            "Training with hidden_dim=40, z_dim=30\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (8.89 s)\n",
            "Epoch: 1, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 3, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 7, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 8, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.09, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.05, Test Loss: 0.93 (0.15 s)\n",
            "Epoch: 18, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.17 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=30: 0.9201891422271729\n",
            "Mean Test loss for hidden_dim=40, z_dim=30: 0.9213563203811646\n",
            "Training with hidden_dim=40, z_dim=40\n",
            "Epoch: 0, Train Loss: 92.05, Test Loss: 0.92 (7.52 s)\n",
            "Epoch: 1, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 4, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 5, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 6, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 7, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 8, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 9, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 13, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 14, Train Loss: 92.13, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.05, Test Loss: 0.92 (0.18 s)\n",
            "Epoch: 16, Train Loss: 92.11, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.25 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 19, Train Loss: 92.05, Test Loss: 0.92 (0.25 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=40: 0.9172320365905762\n",
            "Mean Test loss for hidden_dim=40, z_dim=40: 0.9208173751831055\n",
            "Training with hidden_dim=40, z_dim=50\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (8.03 s)\n",
            "Epoch: 1, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 2, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 5, Train Loss: 92.07, Test Loss: 0.92 (0.22 s)\n",
            "Epoch: 6, Train Loss: 92.10, Test Loss: 0.92 (0.28 s)\n",
            "Epoch: 7, Train Loss: 92.07, Test Loss: 0.92 (0.25 s)\n",
            "Epoch: 8, Train Loss: 92.09, Test Loss: 0.92 (0.25 s)\n",
            "Epoch: 9, Train Loss: 92.12, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 10, Train Loss: 92.06, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.25 s)\n",
            "Epoch: 12, Train Loss: 92.12, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 13, Train Loss: 92.11, Test Loss: 0.92 (0.38 s)\n",
            "Epoch: 14, Train Loss: 92.11, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 15, Train Loss: 92.08, Test Loss: 0.92 (0.22 s)\n",
            "Epoch: 16, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 17, Train Loss: 92.06, Test Loss: 0.93 (0.16 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 19, Train Loss: 92.12, Test Loss: 0.92 (0.17 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=50: 0.9181785583496094\n",
            "Mean Test loss for hidden_dim=40, z_dim=50: 0.9212445020675659\n",
            "Training with hidden_dim=50, z_dim=20\n",
            "Epoch: 0, Train Loss: 92.06, Test Loss: 0.92 (7.68 s)\n",
            "Epoch: 1, Train Loss: 92.07, Test Loss: 0.92 (0.21 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 3, Train Loss: 92.09, Test Loss: 0.92 (1.15 s)\n",
            "Epoch: 4, Train Loss: 92.09, Test Loss: 0.92 (0.40 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.26 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 7, Train Loss: 92.09, Test Loss: 0.92 (0.27 s)\n",
            "Epoch: 8, Train Loss: 92.08, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 10, Train Loss: 92.04, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 12, Train Loss: 92.13, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 13, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 14, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 15, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.05, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 18, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=20: 0.9231603741645813\n",
            "Mean Test loss for hidden_dim=50, z_dim=20: 0.9207416772842407\n",
            "Training with hidden_dim=50, z_dim=30\n",
            "Epoch: 0, Train Loss: 92.09, Test Loss: 0.92 (10.05 s)\n",
            "Epoch: 1, Train Loss: 92.06, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.07, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 4, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 5, Train Loss: 92.10, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 6, Train Loss: 92.05, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 7, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 8, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 9, Train Loss: 92.06, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 10, Train Loss: 92.08, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 11, Train Loss: 92.09, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 13, Train Loss: 92.05, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 14, Train Loss: 92.13, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 15, Train Loss: 92.06, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.09, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 17, Train Loss: 92.05, Test Loss: 0.93 (0.15 s)\n",
            "Epoch: 18, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 19, Train Loss: 92.07, Test Loss: 0.92 (0.15 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=30: 0.9201430678367615\n",
            "Mean Test loss for hidden_dim=50, z_dim=30: 0.9213812947273254\n",
            "Training with hidden_dim=50, z_dim=40\n",
            "Epoch: 0, Train Loss: 92.05, Test Loss: 0.92 (9.61 s)\n",
            "Epoch: 1, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 2, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 4, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 5, Train Loss: 92.11, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 6, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 7, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 8, Train Loss: 92.06, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 9, Train Loss: 92.11, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 10, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 11, Train Loss: 92.12, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.11, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 13, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 14, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 15, Train Loss: 92.05, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 16, Train Loss: 92.11, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 17, Train Loss: 92.07, Test Loss: 0.92 (0.19 s)\n",
            "Epoch: 18, Train Loss: 92.10, Test Loss: 0.92 (0.21 s)\n",
            "Epoch: 19, Train Loss: 92.05, Test Loss: 0.92 (0.19 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=40: 0.9172465801239014\n",
            "Mean Test loss for hidden_dim=50, z_dim=40: 0.9208342432975769\n",
            "Training with hidden_dim=50, z_dim=50\n",
            "Epoch: 0, Train Loss: 92.08, Test Loss: 0.92 (10.32 s)\n",
            "Epoch: 1, Train Loss: 92.08, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 2, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 3, Train Loss: 92.11, Test Loss: 0.92 (0.18 s)\n",
            "Epoch: 4, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 5, Train Loss: 92.07, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 6, Train Loss: 92.10, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 7, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 8, Train Loss: 92.09, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 9, Train Loss: 92.12, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 10, Train Loss: 92.06, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 11, Train Loss: 92.13, Test Loss: 0.92 (0.15 s)\n",
            "Epoch: 12, Train Loss: 92.12, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 13, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 14, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 15, Train Loss: 92.08, Test Loss: 0.92 (0.17 s)\n",
            "Epoch: 16, Train Loss: 92.07, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 17, Train Loss: 92.06, Test Loss: 0.93 (0.16 s)\n",
            "Epoch: 18, Train Loss: 92.11, Test Loss: 0.92 (0.16 s)\n",
            "Epoch: 19, Train Loss: 92.13, Test Loss: 0.92 (0.16 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=50: 0.9181371927261353\n",
            "Mean Test loss for hidden_dim=50, z_dim=50: 0.9213021397590637\n",
            "Grid search complete.\n",
            "Results: {(20, 20): Array(0.923106, dtype=float32), (20, 30): Array(0.92014986, dtype=float32), (20, 40): Array(0.9173188, dtype=float32), (20, 50): Array(0.9182265, dtype=float32), (30, 20): Array(0.92311615, dtype=float32), (30, 30): Array(0.9201259, dtype=float32), (30, 40): Array(0.9172175, dtype=float32), (30, 50): Array(0.91810465, dtype=float32), (40, 20): Array(0.923177, dtype=float32), (40, 30): Array(0.92018914, dtype=float32), (40, 40): Array(0.91723204, dtype=float32), (40, 50): Array(0.91817856, dtype=float32), (50, 20): Array(0.9231604, dtype=float32), (50, 30): Array(0.92014307, dtype=float32), (50, 40): Array(0.9172466, dtype=float32), (50, 50): Array(0.9181372, dtype=float32)}\n",
            "Mean Test Loss Results: {(20, 20): Array(0.9207327, dtype=float32), (20, 30): Array(0.9213196, dtype=float32), (20, 40): Array(0.9207714, dtype=float32), (20, 50): Array(0.9211856, dtype=float32), (30, 20): Array(0.9207401, dtype=float32), (30, 30): Array(0.9213139, dtype=float32), (30, 40): Array(0.92079985, dtype=float32), (30, 50): Array(0.92121744, dtype=float32), (40, 20): Array(0.9207643, dtype=float32), (40, 30): Array(0.9213563, dtype=float32), (40, 40): Array(0.9208174, dtype=float32), (40, 50): Array(0.9212445, dtype=float32), (50, 20): Array(0.9207417, dtype=float32), (50, 30): Array(0.9213813, dtype=float32), (50, 40): Array(0.92083424, dtype=float32), (50, 50): Array(0.92130214, dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_loss_results_final)\n",
        "print(test_loss_results_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROJghrFwVTFd",
        "outputId": "6fc9d563-5595-487d-c727-a58f096c9d5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(20, 20): Array(0.923106, dtype=float32), (20, 30): Array(0.92014986, dtype=float32), (20, 40): Array(0.9173188, dtype=float32), (20, 50): Array(0.9182265, dtype=float32), (30, 20): Array(0.92311615, dtype=float32), (30, 30): Array(0.9201259, dtype=float32), (30, 40): Array(0.9172175, dtype=float32), (30, 50): Array(0.91810465, dtype=float32), (40, 20): Array(0.923177, dtype=float32), (40, 30): Array(0.92018914, dtype=float32), (40, 40): Array(0.91723204, dtype=float32), (40, 50): Array(0.91817856, dtype=float32), (50, 20): Array(0.9231604, dtype=float32), (50, 30): Array(0.92014307, dtype=float32), (50, 40): Array(0.9172466, dtype=float32), (50, 50): Array(0.9181372, dtype=float32)}\n",
            "{(20, 20): Array(0.9207327, dtype=float32), (20, 30): Array(0.9213196, dtype=float32), (20, 40): Array(0.9207714, dtype=float32), (20, 50): Array(0.9211856, dtype=float32), (30, 20): Array(0.9207401, dtype=float32), (30, 30): Array(0.9213139, dtype=float32), (30, 40): Array(0.92079985, dtype=float32), (30, 50): Array(0.92121744, dtype=float32), (40, 20): Array(0.9207643, dtype=float32), (40, 30): Array(0.9213563, dtype=float32), (40, 40): Array(0.9208174, dtype=float32), (40, 50): Array(0.9212445, dtype=float32), (50, 20): Array(0.9207417, dtype=float32), (50, 30): Array(0.9213813, dtype=float32), (50, 40): Array(0.92083424, dtype=float32), (50, 50): Array(0.92130214, dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimal Hyperparams are 30 hidden dims and 40 latent dims\n"
      ],
      "metadata": {
        "id": "RQSdxxnaWn1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initiate Training Loop with optimal hyperparams"
      ],
      "metadata": {
        "id": "Gb1HhnafTooi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = numpyro.optim.Adam(step_size = args[\"learning_rate\"])\n",
        "svi = SVI(\n",
        "        vae_model,\n",
        "        vae_guide,\n",
        "        adam,\n",
        "        RenyiELBO(),\n",
        "        hidden_dim = args[\"hidden_dim\"],\n",
        "        z_dim = args[\"z_dim\"]\n",
        "    )\n",
        "\n",
        "rng_key, rng_key_samp, rng_key_init = random.split(args[\"rng_key\"],3)\n",
        "#(num_samples, num_regions)\n",
        "init_batch = agg_gp_predictive(rng_key_, args)[\"gp_aggr\"] #(num_samples, num_regions) <- i.e (5,58)\n",
        "svi_state = svi.init(rng_key_init, init_batch)\n",
        "\n",
        "test_loss_list = []"
      ],
      "metadata": {
        "id": "_NR2_Or-Tq_E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(args[\"num_epochs\"]):\n",
        "    rng_key, rng_key_train, rng_key_test, rng_key_infer = random.split(rng_key, 4)\n",
        "    t_start = time.time()\n",
        "\n",
        "    num_train = 1000\n",
        "    # Where forward/backward pass gets called for train\n",
        "    train_loss , svi_state = epoch_train(rng_key_train, svi_state, num_train)\n",
        "\n",
        "    num_test = 1000\n",
        "\n",
        "    # Where forward/backward pass gets called for test\n",
        "    test_loss = eval_test(rng_key_test, svi_state, num_test)\n",
        "    test_loss_list += [test_loss]\n",
        "\n",
        "    print(\"Epoch : {}, train loss : {:.2f}, test loss : {:.2f} ({:.2f} s.)\".format(i, train_loss, test_loss, time.time() - t_start))\n",
        "\n",
        "    if math.isnan(test_loss):\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T77REeqrUXy7",
        "outputId": "a0f9e4c1-f7fb-4976-ce04-880f74c49ec2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0, train loss : 920.80, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 1, train loss : 920.90, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 2, train loss : 920.93, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 3, train loss : 920.79, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 4, train loss : 920.90, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 5, train loss : 920.90, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 6, train loss : 920.93, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 7, train loss : 920.90, test loss : 0.93 (0.00 s.)\n",
            "Epoch : 8, train loss : 920.93, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 9, train loss : 920.82, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 10, train loss : 920.98, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 11, train loss : 920.87, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 12, train loss : 920.94, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 13, train loss : 920.93, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 14, train loss : 920.90, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 15, train loss : 920.89, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 16, train loss : 920.83, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 17, train loss : 920.99, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 18, train loss : 920.90, test loss : 0.92 (0.00 s.)\n",
            "Epoch : 19, train loss : 920.92, test loss : 0.92 (0.00 s.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the decoder\n",
        "decoder_params = svi.get_params(svi_state)"
      ],
      "metadata": {
        "id": "eXgAJbgnUlCl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save the decoder"
      ],
      "metadata": {
        "id": "4fldbVSkT0RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get script directory\n",
        "script_dir = os.getcwd()  # Get current working directory\n",
        "\n",
        "# Define the correct save path inside model_weights/\n",
        "save_dir = os.path.abspath(os.path.join(script_dir, \"..\", model_weights\", \"aggVAE\"))\n",
        "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
        "\n",
        "# Save decoder parameters\n",
        "save_path = os.path.join(save_dir, f\"aggVAE_e{args['num_epochs']}_h{args['hidden_dim']}_z{args['z_dim']}\")\n",
        "\n",
        "with open(save_path, \"wb\") as file:\n",
        "    pickle.dump(decoder_params, file)\n",
        "\n",
        "print(f\"Decoder parameters saved to {save_path}\")"
      ],
      "metadata": {
        "id": "v9zDJExcT1OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967bf144-621d-4ad2-b1fe-07207c818a39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder parameters saved to /content/model_weights/aggVAE/aggVAE_e20_h30_z40\n"
          ]
        }
      ]
    }
  ]
}