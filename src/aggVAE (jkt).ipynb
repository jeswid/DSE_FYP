{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6OHOp4nw7bc"
      },
      "source": [
        "### Description: This notebook demonstrates training VAE encoder on GP aggregates and disease mapping using aggVAE(section 5.2.7 - 5.2.12, the aggVAE components). This notebook also can be used to reproduce values in tables 5-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bPZJu7mlw7bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import jax\n",
        "import jax.nn as nn\n",
        "import math\n",
        "import itertools\n",
        "from jax import lax, random\n",
        "from jax.example_libraries import stax\n",
        "import jax.numpy as jnp\n",
        "from jax.random import PRNGKey\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpyro\n",
        "import pickle\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import SVI, Trace_ELBO, RenyiELBO\n",
        "import arviz as az\n",
        "import sys\n",
        "from pyprojroot import here\n",
        "import time\n",
        "import plotly.express as px\n",
        "import geopandas as gpd\n",
        "sys.path.append(str(here() / \"simulation study\" / \"src\"))\n",
        "# Import our modular components\n",
        "from kernels import exp_sq_kernel, M_g\n",
        "from loader_jkt import load_data\n",
        "from gp import gp_aggr\n",
        "from vae import vae_model, vae_guide, vae_decoder\n",
        "from plotting import plot_process, plot_incidence_map\n",
        "import matplotlib.pyplot as plt\n",
        "from numpyro.infer import NUTS, MCMC, Predictive, init_to_median, init_to_uniform, init_to_sample, init_to_mean, init_to_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3GQie9Dw7be"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8sxCkg9w7be",
        "outputId": "55720599-b89e-4c16-98c2-6c9ebeebc622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 'pol_pts_lo', 'pol_pts_hi', 'df_lo', 'df_hi'])\n"
          ]
        }
      ],
      "source": [
        "# Load the spatial grid and polygon data\n",
        "spatial_data = load_data()\n",
        "print(spatial_data.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whJ-5gndw7be"
      },
      "source": [
        "## 2. Set up aggVAE Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "38gAq6Tdw7be"
      },
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "args = {\n",
        "    \"x\": spatial_data[\"x\"],\n",
        "    \"gp_kernel\": exp_sq_kernel,\n",
        "    \"noise\": 1.e-2,\n",
        "    \"jitter\": 1.e-2,\n",
        "    \"M_lo\": jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    \"M_hi\":  jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    \"vae_var\": 0.1,\n",
        "    \"batch_size\": 5,\n",
        "    \"hidden_dim\": 50,\n",
        "    \"z_dim\": 40,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"num_epochs\": 29,\n",
        "    \"rng_key\": PRNGKey(6)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HsfpX-0w7bf"
      },
      "source": [
        "## 3. Generate GP Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zkHFthuNw7bf",
        "outputId": "89e95d0b-7982-4286-e5f2-9ebf78cb3358"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "<extra></extra>",
                  "legendgroup": "",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "",
                  "orientation": "v",
                  "showlegend": false,
                  "type": "scatter",
                  "xaxis": "x",
                  "yaxis": "y"
                },
                {
                  "line": {
                    "color": "rgb(31, 119, 180)"
                  },
                  "opacity": 0.3,
                  "type": "scatter",
                  "x": {
                    "bdata": "AAECAwQF",
                    "dtype": "i1"
                  },
                  "y": {
                    "bdata": "9/2uQzSGe0K+Lc9BBsqhQl8nzkLsd5pC",
                    "dtype": "f4"
                  }
                },
                {
                  "line": {
                    "color": "rgb(31, 119, 180)"
                  },
                  "opacity": 0.3,
                  "type": "scatter",
                  "x": {
                    "bdata": "AAECAwQF",
                    "dtype": "i1"
                  },
                  "y": {
                    "bdata": "yCayRDyJekN1xt9CklyaQ9/w0UN3F6dD",
                    "dtype": "f4"
                  }
                },
                {
                  "line": {
                    "color": "rgb(31, 119, 180)"
                  },
                  "opacity": 0.3,
                  "type": "scatter",
                  "x": {
                    "bdata": "AAECAwQF",
                    "dtype": "i1"
                  },
                  "y": {
                    "bdata": "KKD9RGfvwUPBdEZDaK7HQyrbBUQd8v1D",
                    "dtype": "f4"
                  }
                },
                {
                  "line": {
                    "color": "rgb(31, 119, 180)"
                  },
                  "opacity": 0.3,
                  "type": "scatter",
                  "x": {
                    "bdata": "AAECAwQF",
                    "dtype": "i1"
                  },
                  "y": {
                    "bdata": "4QlNRSKGHETd4phDAJ0iRN9OW0QTRE1E",
                    "dtype": "f4"
                  }
                },
                {
                  "line": {
                    "color": "rgb(31, 119, 180)"
                  },
                  "opacity": 0.3,
                  "type": "scatter",
                  "x": {
                    "bdata": "AAECAwQF",
                    "dtype": "i1"
                  },
                  "y": {
                    "bdata": "yCFVRLC8HENY96FCcuosQyBiZ0MxglJD",
                    "dtype": "f4"
                  }
                }
              ],
              "layout": {
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "white",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "white",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "#C8D4E3",
                          "linecolor": "#C8D4E3",
                          "minorgridcolor": "#C8D4E3",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "#C8D4E3",
                          "linecolor": "#C8D4E3",
                          "minorgridcolor": "#C8D4E3",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "white",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "#C8D4E3"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "white",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "#EBF0F8",
                        "linecolor": "#EBF0F8",
                        "ticks": ""
                      },
                      "bgcolor": "white",
                      "radialaxis": {
                        "gridcolor": "#EBF0F8",
                        "linecolor": "#EBF0F8",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "white",
                        "gridcolor": "#DFE8F3",
                        "gridwidth": 2,
                        "linecolor": "#EBF0F8",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "#EBF0F8"
                      },
                      "yaxis": {
                        "backgroundcolor": "white",
                        "gridcolor": "#DFE8F3",
                        "gridwidth": 2,
                        "linecolor": "#EBF0F8",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "#EBF0F8"
                      },
                      "zaxis": {
                        "backgroundcolor": "white",
                        "gridcolor": "#DFE8F3",
                        "gridwidth": 2,
                        "linecolor": "#EBF0F8",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "#EBF0F8"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "#DFE8F3",
                        "linecolor": "#A2B1C6",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "#DFE8F3",
                        "linecolor": "#A2B1C6",
                        "ticks": ""
                      },
                      "bgcolor": "white",
                      "caxis": {
                        "gridcolor": "#DFE8F3",
                        "linecolor": "#A2B1C6",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "#EBF0F8",
                      "linecolor": "#EBF0F8",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "#EBF0F8",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "#EBF0F8",
                      "linecolor": "#EBF0F8",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "#EBF0F8",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "region"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "num cases"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create predictive function for GP\n",
        "from numpyro.infer import Predictive\n",
        "# Draw samples from the prior\n",
        "prior_samples = Predictive(gp_aggr, num_samples=5)(\n",
        "    PRNGKey(6),\n",
        "    config=args\n",
        ")\n",
        "\n",
        "# transform prior samples to arviz inference object\n",
        "prior_samples_arviz = az.from_numpyro(prior=prior_samples)\n",
        "\n",
        "plot_process(prior_samples_arviz.prior.gp_aggr.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Vp3pclw7bf"
      },
      "source": [
        "## 4. Train VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "2YwzUbGTw7bf"
      },
      "outputs": [],
      "source": [
        "# Initialize SVI\n",
        "optimizer = numpyro.optim.Adam(step_size=1e-3)\n",
        "agg_gp_predictive = Predictive(gp_aggr,num_samples = 5)\n",
        "@jax.jit\n",
        "def epoch_train(rng_key, svi_state, num_train):\n",
        "    def body_fn(i, val):\n",
        "        rng_key_i = jax.random.fold_in(rng_key, i) #Array(2,)\n",
        "        rng_key_i, rng_key_ls, rng_key_var, rng_key_noise = jax.random.split(rng_key_i, 4) #Tuple(Array(2,) x 4)\n",
        "        loss_sum, svi_state = val #val --svi_state\n",
        "\n",
        "        batch = agg_gp_predictive(rng_key_i, args)[\"gp_aggr\"] #(5,116) <- num_samples : 5, total_districts : 116\n",
        "        #* svi is where the vae_model & vae_guide gets applied\n",
        "        svi_state, loss = svi.update(svi_state, batch)\n",
        "        loss_sum += loss / args[\"batch_size\"]\n",
        "        return loss_sum, svi_state\n",
        "\n",
        "    return lax.fori_loop(lower = 0, upper = num_train, body_fun=body_fn, init_val=(0.0, svi_state))\n",
        "\n",
        "@jax.jit\n",
        "def eval_test(rng_key, svi_state, num_test):\n",
        "    def body_fn(i, loss_sum):\n",
        "        rng_key_i = jax.random.fold_in(rng_key, i)\n",
        "        rng_key_i, rng_key_ls, rng_key_varm, rng_key_noise = jax.random.split(rng_key_i, 4)\n",
        "        batch = agg_gp_predictive(rng_key_i, args)[\"gp_aggr\"]\n",
        "        #* svi is where the vae_model & vae_guide gets applied\n",
        "        loss = svi.evaluate(svi_state, batch) / args[\"batch_size\"]\n",
        "        loss_sum += loss\n",
        "        return loss_sum\n",
        "\n",
        "    loss = lax.fori_loop(lower = 0, upper = num_test,body_fun =  body_fn, init_val = 0.0)\n",
        "    loss = loss / num_test\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyerparameter tuning for h and z  --> used to produce values in Table 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with hidden_dim=20, z_dim=20\n",
            "Epoch: 0, Train Loss: 18298746880.00, Test Loss: 131595576.00 (13.33 s)\n",
            "Epoch: 1, Train Loss: 28472915968.00, Test Loss: 172952064.00 (0.22 s)\n",
            "Epoch: 2, Train Loss: 16623357952.00, Test Loss: 162045552.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 14992008192.00, Test Loss: 4303764992.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 3684347674624.00, Test Loss: 9992914944.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 15526137856.00, Test Loss: 361663070208.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 18069397504.00, Test Loss: 143981696.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 12369376256.00, Test Loss: 140706416.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 13913288704.00, Test Loss: 132283504.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 10682062848.00, Test Loss: 94213080.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 12442591232.00, Test Loss: 130829952.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 13886770176.00, Test Loss: 140524736.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 12460086272.00, Test Loss: 90007440.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 13462162432.00, Test Loss: 87056400.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 10587768832.00, Test Loss: 97858800.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 10638649344.00, Test Loss: 93230864.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 7788111360.00, Test Loss: 39903412.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 3782093568.00, Test Loss: 111264840.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 9277495296.00, Test Loss: 102024136.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 6711248384.00, Test Loss: 77752096.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=20: 77752096.0\n",
            "Mean Test loss for hidden_dim=20, z_dim=20: 18895400960.0\n",
            "Training with hidden_dim=20, z_dim=30\n",
            "Epoch: 0, Train Loss: 17227022336.00, Test Loss: 139208432.00 (13.30 s)\n",
            "Epoch: 1, Train Loss: 17571389440.00, Test Loss: 172727216.00 (0.23 s)\n",
            "Epoch: 2, Train Loss: 16790490112.00, Test Loss: 163944816.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 15270171648.00, Test Loss: 167078944.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 11811473408.00, Test Loss: 133527344.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 12045954048.00, Test Loss: 133845112.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 10343471104.00, Test Loss: 61716288.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 6635015680.00, Test Loss: 68964888.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 5106942976.00, Test Loss: 33853976.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 2705759488.00, Test Loss: 30271112.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 2045137536.00, Test Loss: 26779336.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 2469670144.00, Test Loss: 145188256.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 2572719104.00, Test Loss: 23576578.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 3594596608.00, Test Loss: 16655413.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 4590069760.00, Test Loss: 60338016.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 5693992960.00, Test Loss: 40818320.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 4367794688.00, Test Loss: 52393700.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 5184540672.00, Test Loss: 45381740.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 6176780800.00, Test Loss: 42548224.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4701738496.00, Test Loss: 45180912.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=30: 45180912.0\n",
            "Mean Test loss for hidden_dim=20, z_dim=30: 80199928.0\n",
            "Training with hidden_dim=20, z_dim=40\n",
            "Epoch: 0, Train Loss: 16664108032.00, Test Loss: 20714487808.00 (13.05 s)\n",
            "Epoch: 1, Train Loss: 15925243904.00, Test Loss: 158407936.00 (0.25 s)\n",
            "Epoch: 2, Train Loss: 4094697930752.00, Test Loss: 144140784.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 32966418432.00, Test Loss: 167540816.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 12653240320.00, Test Loss: 157903680.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 15950093312.00, Test Loss: 184071328.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: nan, Test Loss: nan (0.22 s)\n",
            "NaN encountered at hidden_dim=20, z_dim=40. Skipping...\n",
            "Final Test loss for hidden_dim=20, z_dim=40: 0.0\n",
            "Mean Test loss for hidden_dim=20, z_dim=40: 1132976512.0\n",
            "Training with hidden_dim=20, z_dim=50\n",
            "Epoch: 0, Train Loss: 16197377024.00, Test Loss: 144434980930287396927077525487616.00 (13.08 s)\n",
            "Epoch: 1, Train Loss: 3205249892352.00, Test Loss: 88651504.00 (0.25 s)\n",
            "Epoch: 2, Train Loss: 4642075136.00, Test Loss: 7854525952.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 1096093056.00, Test Loss: 7055071.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 47370964992.00, Test Loss: 23695318.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 2705323520.00, Test Loss: 506118733824.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 3666313472.00, Test Loss: 13125234.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 863081152.00, Test Loss: 8748412.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 1280349696.00, Test Loss: 12588839.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 854385472.00, Test Loss: 9265730.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 619487744.00, Test Loss: 6757058.50 (0.22 s)\n",
            "Epoch: 11, Train Loss: 641265472.00, Test Loss: 19777736.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 577794112.00, Test Loss: 5092281.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 4421325312.00, Test Loss: 19055534.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 950483264.00, Test Loss: 5503797.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 906020800.00, Test Loss: 5743829.50 (0.22 s)\n",
            "Epoch: 16, Train Loss: 516152864.00, Test Loss: 7086586.50 (0.22 s)\n",
            "Epoch: 17, Train Loss: 550695680.00, Test Loss: 4036850.25 (0.22 s)\n",
            "Epoch: 18, Train Loss: 1258664832.00, Test Loss: 8819586.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 955027328.00, Test Loss: 67852744.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=20, z_dim=50: 67852744.0\n",
            "Mean Test loss for hidden_dim=20, z_dim=50: 7.221749288299534e+30\n",
            "Training with hidden_dim=30, z_dim=20\n",
            "Epoch: 0, Train Loss: 16366849024.00, Test Loss: 5073657923465379840.00 (12.84 s)\n",
            "Epoch: 1, Train Loss: 22375493632.00, Test Loss: 134782864.00 (0.25 s)\n",
            "Epoch: 2, Train Loss: 152699879424.00, Test Loss: 150163840.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 13569867776.00, Test Loss: 146664752.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 10056466432.00, Test Loss: 121254888.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 12370326528.00, Test Loss: 117424640.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 11048695808.00, Test Loss: 74336664.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 6116044288.00, Test Loss: 70082088.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 6562300928.00, Test Loss: 69188952.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 5315743744.00, Test Loss: 65516336.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 4438071296.00, Test Loss: 47863628.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 4890769408.00, Test Loss: 59895992.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 5265528320.00, Test Loss: 42515648.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 5805731328.00, Test Loss: 44357196.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 5186000384.00, Test Loss: 47585940.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 5252740096.00, Test Loss: 39642980.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 4168611840.00, Test Loss: 57232912.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 5217687552.00, Test Loss: 42041832.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 6093855232.00, Test Loss: 40285312.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4700600320.00, Test Loss: 45794184.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=20: 45794184.0\n",
            "Mean Test loss for hidden_dim=30, z_dim=20: 2.53682896173269e+17\n",
            "Training with hidden_dim=30, z_dim=30\n",
            "Epoch: 0, Train Loss: 42263629824.00, Test Loss: 136577376.00 (13.02 s)\n",
            "Epoch: 1, Train Loss: 527880585216.00, Test Loss: 175205232.00 (0.24 s)\n",
            "Epoch: 2, Train Loss: 16765849600.00, Test Loss: 151315376.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 12101053440.00, Test Loss: 179805136.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 10092004352.00, Test Loss: 113808528.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 10195553280.00, Test Loss: 565694464.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 26071779328.00, Test Loss: 137193808.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 11468760064.00, Test Loss: 125669208.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 12455944192.00, Test Loss: 127377624.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 9174373376.00, Test Loss: 108777664.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 6171550720.00, Test Loss: 61458860.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 5930540544.00, Test Loss: 61250656.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 5268542464.00, Test Loss: 42351860.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 5834583040.00, Test Loss: 42213136.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 4962243584.00, Test Loss: 47400868.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 5104081920.00, Test Loss: 44516696.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 4473198592.00, Test Loss: 52640564.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 5242972672.00, Test Loss: 43077512.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 6008233984.00, Test Loss: 43326820.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4585038848.00, Test Loss: 45184280.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=30: 45184280.0\n",
            "Mean Test loss for hidden_dim=30, z_dim=30: 115242296.0\n",
            "Training with hidden_dim=30, z_dim=40\n",
            "Epoch: 0, Train Loss: 58228327055360.00, Test Loss: 141118080.00 (13.45 s)\n",
            "Epoch: 1, Train Loss: 18616528896.00, Test Loss: 171566416.00 (0.26 s)\n",
            "Epoch: 2, Train Loss: 16725505024.00, Test Loss: 165745824.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 46016425984.00, Test Loss: 165040832.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 23675115520.00, Test Loss: 724329664.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 16983375872.00, Test Loss: 874271060525056.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 27884826624.00, Test Loss: 132624360.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 11766417408.00, Test Loss: 127492992.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 13252399104.00, Test Loss: 130569856.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 10419168256.00, Test Loss: 114345448.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 7578955776.00, Test Loss: 63278604.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 5748995072.00, Test Loss: 14084810752.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 4554975744.00, Test Loss: 29012330.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 2957555200.00, Test Loss: 21546606.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 1985107840.00, Test Loss: 18780170.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 1911993472.00, Test Loss: 13611420.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 1767646464.00, Test Loss: 119976744.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 1998403072.00, Test Loss: 91489792.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 33653721088.00, Test Loss: 15057533.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 1349965824.00, Test Loss: 15593225.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=40: 15593225.0\n",
            "Mean Test loss for hidden_dim=30, z_dim=40: 43714365882368.0\n",
            "Training with hidden_dim=30, z_dim=50\n",
            "Epoch: 0, Train Loss: 16704791552.00, Test Loss: 133584496.00 (13.17 s)\n",
            "Epoch: 1, Train Loss: 2695268925440.00, Test Loss: 160537344.00 (0.24 s)\n",
            "Epoch: 2, Train Loss: 15409157120.00, Test Loss: 149364320.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 13753446400.00, Test Loss: 150809936.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 10818595840.00, Test Loss: 132592696.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 12343589888.00, Test Loss: 9437122560.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 12656887808.00, Test Loss: 87908848.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 6008124928.00, Test Loss: 94082960.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 7143241216.00, Test Loss: 65885184.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 4984005632.00, Test Loss: 87208432.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 4477913088.00, Test Loss: 40839132.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 8628727808.00, Test Loss: 52560372.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 4230729728.00, Test Loss: 27703690.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 4762025472.00, Test Loss: 48182984.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 3857188352.00, Test Loss: 34564336.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 4138444800.00, Test Loss: 29412144.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 2736782848.00, Test Loss: 39318464.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 2863812096.00, Test Loss: 55599876.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 40653832192.00, Test Loss: 45474196.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4655470592.00, Test Loss: 38912876.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=30, z_dim=50: 38912876.0\n",
            "Mean Test loss for hidden_dim=30, z_dim=50: 545583168.0\n",
            "Training with hidden_dim=40, z_dim=20\n",
            "Epoch: 0, Train Loss: 104965021696.00, Test Loss: 2426620672.00 (13.33 s)\n",
            "Epoch: 1, Train Loss: 1071732883456.00, Test Loss: 166005424.00 (0.22 s)\n",
            "Epoch: 2, Train Loss: 16048804864.00, Test Loss: 157515968.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 14941357056.00, Test Loss: 151158560.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 144806707200.00, Test Loss: 166345328.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 16479659008.00, Test Loss: 92878632.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 12529163264.00, Test Loss: 119538504.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 8679264256.00, Test Loss: 103622248.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 9906725888.00, Test Loss: 108430432.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 9154022400.00, Test Loss: 123768032.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 7945155584.00, Test Loss: 71016184.00 (0.21 s)\n",
            "Epoch: 11, Train Loss: 10240086016.00, Test Loss: 101355480.00 (0.21 s)\n",
            "Epoch: 12, Train Loss: 10245155840.00, Test Loss: 92729888.00 (0.21 s)\n",
            "Epoch: 13, Train Loss: 11775395840.00, Test Loss: 76615032.00 (0.21 s)\n",
            "Epoch: 14, Train Loss: 9541598208.00, Test Loss: 81232032.00 (0.21 s)\n",
            "Epoch: 15, Train Loss: 9019213824.00, Test Loss: 70893176.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 6321641472.00, Test Loss: 53521504.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 5435649024.00, Test Loss: 50068088.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 5605193216.00, Test Loss: 43658064.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4262213376.00, Test Loss: 44820424.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=20: 44820424.0\n",
            "Mean Test loss for hidden_dim=40, z_dim=20: 215089648.0\n",
            "Training with hidden_dim=40, z_dim=30\n",
            "Epoch: 0, Train Loss: 26758152192.00, Test Loss: 534833135616.00 (13.20 s)\n",
            "Epoch: 1, Train Loss: 13959248896.00, Test Loss: 133601176.00 (0.24 s)\n",
            "Epoch: 2, Train Loss: 48104366080.00, Test Loss: 26767954.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 2042880384.00, Test Loss: 9699696.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 163631726592.00, Test Loss: 1144076672.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 72944492544.00, Test Loss: 67022572.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 5760033280.00, Test Loss: 41659068.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 3457302016.00, Test Loss: 43828284.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 3947145984.00, Test Loss: 46293448.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 4105643264.00, Test Loss: 49293296.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 3470616832.00, Test Loss: 40105224.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 4269543424.00, Test Loss: 53131896.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 4770106368.00, Test Loss: 38321096.00 (0.21 s)\n",
            "Epoch: 13, Train Loss: 5250482688.00, Test Loss: 43169756.00 (0.21 s)\n",
            "Epoch: 14, Train Loss: 4791896576.00, Test Loss: 43578356.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 5198128128.00, Test Loss: 37318836.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 4111465728.00, Test Loss: 51624704.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 5276683264.00, Test Loss: 45914752.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 5975777280.00, Test Loss: 41611356.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4409018368.00, Test Loss: 44842384.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=30: 44842384.0\n",
            "Mean Test loss for hidden_dim=40, z_dim=30: 26841745408.0\n",
            "Training with hidden_dim=40, z_dim=40\n",
            "Epoch: 0, Train Loss: 256207918989312.00, Test Loss: 141794192.00 (13.72 s)\n",
            "Epoch: 1, Train Loss: 15739485184.00, Test Loss: 167692656.00 (0.25 s)\n",
            "Epoch: 2, Train Loss: 14505775104.00, Test Loss: 92770336.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 8868229120.00, Test Loss: 91762048.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 4219798784.00, Test Loss: 63150708.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 4577626112.00, Test Loss: 60744256.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 4647382528.00, Test Loss: 34265308.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 2760835072.00, Test Loss: 35659596.00 (0.21 s)\n",
            "Epoch: 8, Train Loss: 3493569280.00, Test Loss: 56580032.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 4071717888.00, Test Loss: 41385376.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 3361137664.00, Test Loss: 37306360.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 7985626624.00, Test Loss: 52851536.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 4479051776.00, Test Loss: 32863664.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 4738372096.00, Test Loss: 41409116.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 4061406976.00, Test Loss: 40057080.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 4803140096.00, Test Loss: 32679516.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 3700790784.00, Test Loss: 43598516.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 4550458880.00, Test Loss: 31439438.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 4983289856.00, Test Loss: 34834256.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 3949184768.00, Test Loss: 34298756.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=40: 34298756.0\n",
            "Mean Test loss for hidden_dim=40, z_dim=40: 58357132.0\n",
            "Training with hidden_dim=40, z_dim=50\n",
            "Epoch: 0, Train Loss: 1376123224064.00, Test Loss: 149259698176.00 (13.58 s)\n",
            "Epoch: 1, Train Loss: 207083503616.00, Test Loss: 25525332.00 (0.26 s)\n",
            "Epoch: 2, Train Loss: 6167675904.00, Test Loss: 47036596.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 3236472320.00, Test Loss: 53121032192.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 3390998528.00, Test Loss: 9221167.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 583142848.00, Test Loss: 17641616.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 54621282304.00, Test Loss: 22300124.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 1474234752.00, Test Loss: 14353771.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 1044757568.00, Test Loss: 12469898.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 545961280.00, Test Loss: 6023479.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 411752288.00, Test Loss: 4384881.50 (0.22 s)\n",
            "Epoch: 11, Train Loss: 443700192.00, Test Loss: 21399016.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 495858784.00, Test Loss: 3177736.25 (0.22 s)\n",
            "Epoch: 13, Train Loss: 373466848.00, Test Loss: 3076960.25 (0.22 s)\n",
            "Epoch: 14, Train Loss: 350838208.00, Test Loss: 2560290.75 (0.22 s)\n",
            "Epoch: 15, Train Loss: 285669376.00, Test Loss: 2154565.50 (0.22 s)\n",
            "Epoch: 16, Train Loss: 243843600.00, Test Loss: 2326415.75 (0.22 s)\n",
            "Epoch: 17, Train Loss: 205336560.00, Test Loss: 1503962.38 (0.22 s)\n",
            "Epoch: 18, Train Loss: 197307200.00, Test Loss: 1162160.75 (0.22 s)\n",
            "Epoch: 19, Train Loss: 118705224.00, Test Loss: 984627.81 (0.22 s)\n",
            "Final Test loss for hidden_dim=40, z_dim=50: 984627.8125\n",
            "Mean Test loss for hidden_dim=40, z_dim=50: 10128903168.0\n",
            "Training with hidden_dim=50, z_dim=20\n",
            "Epoch: 0, Train Loss: 674359995793408.00, Test Loss: 72657500372992.00 (12.81 s)\n",
            "Epoch: 1, Train Loss: 38249787392.00, Test Loss: 168220448.00 (0.24 s)\n",
            "Epoch: 2, Train Loss: 156706127872.00, Test Loss: 159195120.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 14873308160.00, Test Loss: 160473536.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: nan, Test Loss: nan (0.22 s)\n",
            "NaN encountered at hidden_dim=50, z_dim=20. Skipping...\n",
            "Final Test loss for hidden_dim=50, z_dim=20: 0.0\n",
            "Mean Test loss for hidden_dim=50, z_dim=20: 3824104505344.0\n",
            "Training with hidden_dim=50, z_dim=30\n",
            "Epoch: 0, Train Loss: 16831142912.00, Test Loss: 206557392.00 (12.62 s)\n",
            "Epoch: 1, Train Loss: 13498397696.00, Test Loss: 126533280.00 (0.24 s)\n",
            "Epoch: 2, Train Loss: 11643378688.00, Test Loss: 64101416.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 2467433984.00, Test Loss: 24682044.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 1589576832.00, Test Loss: 143080112.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 1011299200.00, Test Loss: 7803566.50 (0.22 s)\n",
            "Epoch: 6, Train Loss: 691793920.00, Test Loss: 19090876.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 371962240.00, Test Loss: 3355554.75 (0.22 s)\n",
            "Epoch: 8, Train Loss: 271687520.00, Test Loss: 10958450.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 209382608.00, Test Loss: 1762517.50 (0.22 s)\n",
            "Epoch: 10, Train Loss: 144228192.00, Test Loss: 1355298.38 (0.22 s)\n",
            "Epoch: 11, Train Loss: 135245712.00, Test Loss: 1128746.50 (0.22 s)\n",
            "Epoch: 12, Train Loss: 122426568.00, Test Loss: 865745.81 (0.22 s)\n",
            "Epoch: 13, Train Loss: 83663640.00, Test Loss: 566943.56 (0.22 s)\n",
            "Epoch: 14, Train Loss: 55840888.00, Test Loss: 640609.12 (0.22 s)\n",
            "Epoch: 15, Train Loss: 69067504.00, Test Loss: 791985.56 (0.22 s)\n",
            "Epoch: 16, Train Loss: 53963636.00, Test Loss: 545790.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 64508988.00, Test Loss: 574689.44 (0.22 s)\n",
            "Epoch: 18, Train Loss: 106549176.00, Test Loss: 530919.31 (0.22 s)\n",
            "Epoch: 19, Train Loss: 59458276.00, Test Loss: 602592.94 (0.22 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=30: 602592.9375\n",
            "Mean Test loss for hidden_dim=50, z_dim=30: 30776436.0\n",
            "Training with hidden_dim=50, z_dim=40\n",
            "Epoch: 0, Train Loss: 908468289536.00, Test Loss: 6267864612864.00 (12.98 s)\n",
            "Epoch: 1, Train Loss: 122673356800.00, Test Loss: 77297704.00 (0.23 s)\n",
            "Epoch: 2, Train Loss: 4152633344.00, Test Loss: 22530108.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 2110924928.00, Test Loss: 22920086.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 2093601024.00, Test Loss: 17998450.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 2199614720.00, Test Loss: 17415166.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 1549634688.00, Test Loss: 12632283.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 853214080.00, Test Loss: 10980077.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 837785152.00, Test Loss: 8940666.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 633217216.00, Test Loss: 8347720.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 424310848.00, Test Loss: 4664227.50 (0.22 s)\n",
            "Epoch: 11, Train Loss: 244820784.00, Test Loss: 4349628.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 108128944.00, Test Loss: 814958.38 (0.22 s)\n",
            "Epoch: 13, Train Loss: 91696088.00, Test Loss: 843165.50 (0.22 s)\n",
            "Epoch: 14, Train Loss: 61568004.00, Test Loss: 819492.88 (0.22 s)\n",
            "Epoch: 15, Train Loss: 73120240.00, Test Loss: 714827.56 (0.22 s)\n",
            "Epoch: 16, Train Loss: 59927412.00, Test Loss: 580619.44 (0.22 s)\n",
            "Epoch: 17, Train Loss: 66788008.00, Test Loss: 696584.62 (0.22 s)\n",
            "Epoch: 18, Train Loss: 72268912.00, Test Loss: 545003.69 (0.22 s)\n",
            "Epoch: 19, Train Loss: 60498272.00, Test Loss: 582650.62 (0.22 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=40: 582650.625\n",
            "Mean Test loss for hidden_dim=50, z_dim=40: 313403899904.0\n",
            "Training with hidden_dim=50, z_dim=50\n",
            "Epoch: 0, Train Loss: 24185989120.00, Test Loss: 140757024.00 (12.69 s)\n",
            "Epoch: 1, Train Loss: 15182881792.00, Test Loss: 154855488.00 (0.24 s)\n",
            "Epoch: 2, Train Loss: 11588297728.00, Test Loss: 85378560.00 (0.22 s)\n",
            "Epoch: 3, Train Loss: 4796367872.00, Test Loss: 53025812.00 (0.22 s)\n",
            "Epoch: 4, Train Loss: 3675482112.00, Test Loss: 32189298.00 (0.22 s)\n",
            "Epoch: 5, Train Loss: 3906331648.00, Test Loss: 1365955968.00 (0.22 s)\n",
            "Epoch: 6, Train Loss: 5198548480.00, Test Loss: 42992168.00 (0.22 s)\n",
            "Epoch: 7, Train Loss: 3465778176.00, Test Loss: 46776156.00 (0.22 s)\n",
            "Epoch: 8, Train Loss: 4216877824.00, Test Loss: 49206288.00 (0.22 s)\n",
            "Epoch: 9, Train Loss: 4389018112.00, Test Loss: 52094628.00 (0.22 s)\n",
            "Epoch: 10, Train Loss: 3867418880.00, Test Loss: 42690188.00 (0.22 s)\n",
            "Epoch: 11, Train Loss: 4461336064.00, Test Loss: 58831800.00 (0.22 s)\n",
            "Epoch: 12, Train Loss: 5064089088.00, Test Loss: 41602904.00 (0.22 s)\n",
            "Epoch: 13, Train Loss: 5657574400.00, Test Loss: 45016564.00 (0.22 s)\n",
            "Epoch: 14, Train Loss: 4961191424.00, Test Loss: 46769668.00 (0.22 s)\n",
            "Epoch: 15, Train Loss: 5371834880.00, Test Loss: 40624696.00 (0.22 s)\n",
            "Epoch: 16, Train Loss: 4285368064.00, Test Loss: 52482196.00 (0.22 s)\n",
            "Epoch: 17, Train Loss: 5191911936.00, Test Loss: 45276308.00 (0.22 s)\n",
            "Epoch: 18, Train Loss: 5774518784.00, Test Loss: 39912276.00 (0.22 s)\n",
            "Epoch: 19, Train Loss: 4542329344.00, Test Loss: 43252248.00 (0.22 s)\n",
            "Final Test loss for hidden_dim=50, z_dim=50: 43252248.0\n",
            "Mean Test loss for hidden_dim=50, z_dim=50: 123984512.0\n",
            "Grid search complete.\n",
            "Results: {(20, 20): Array(77752096., dtype=float32), (20, 30): Array(45180912., dtype=float32), (20, 40): Array(0., dtype=float32), (20, 50): Array(67852744., dtype=float32), (30, 20): Array(45794184., dtype=float32), (30, 30): Array(45184280., dtype=float32), (30, 40): Array(15593225., dtype=float32), (30, 50): Array(38912876., dtype=float32), (40, 20): Array(44820424., dtype=float32), (40, 30): Array(44842384., dtype=float32), (40, 40): Array(34298756., dtype=float32), (40, 50): Array(984627.8, dtype=float32), (50, 20): Array(0., dtype=float32), (50, 30): Array(602592.94, dtype=float32), (50, 40): Array(582650.6, dtype=float32), (50, 50): Array(43252248., dtype=float32)}\n",
            "Mean Test Loss Results: {(20, 20): Array(1.88954e+10, dtype=float32), (20, 30): Array(80199928., dtype=float32), (20, 40): Array(1.1329765e+09, dtype=float32), (20, 50): Array(7.221749e+30, dtype=float32), (30, 20): Array(2.536829e+17, dtype=float32), (30, 30): Array(1.15242296e+08, dtype=float32), (30, 40): Array(4.3714366e+13, dtype=float32), (30, 50): Array(5.4558317e+08, dtype=float32), (40, 20): Array(2.1508965e+08, dtype=float32), (40, 30): Array(2.6841745e+10, dtype=float32), (40, 40): Array(58357132., dtype=float32), (40, 50): Array(1.0128903e+10, dtype=float32), (50, 20): Array(3.8241045e+12, dtype=float32), (50, 30): Array(30776436., dtype=float32), (50, 40): Array(3.134039e+11, dtype=float32), (50, 50): Array(1.2398451e+08, dtype=float32)}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter grid\n",
        "hidden_dims = [20, 30, 40, 50]\n",
        "z_dims = [20, 30, 40, 50]\n",
        "\n",
        "# Store results\n",
        "test_loss_results_final = {}\n",
        "test_loss_results_mean = {}\n",
        "\n",
        "num_train = 100\n",
        "num_test = 100\n",
        "num_epochs = 20\n",
        "\n",
        "for hidden_dim, z_dim in itertools.product(hidden_dims, z_dims):\n",
        "    print(f\"Training with hidden_dim={hidden_dim}, z_dim={z_dim}\")\n",
        "\n",
        "    args[\"hidden_dim\"] = hidden_dim\n",
        "    args[\"z_dim\"] = z_dim\n",
        "\n",
        "    # Initialize optimizer and SVI\n",
        "    adam = numpyro.optim.Adam(step_size=args[\"learning_rate\"])\n",
        "    # Pass vae_var to vae_model using a lambda function\n",
        "    svi = SVI(\n",
        "        lambda batch: vae_model(batch, hidden_dim, z_dim, args[\"vae_var\"]),\n",
        "        lambda batch: vae_guide(batch, hidden_dim, z_dim),\n",
        "        adam,\n",
        "        RenyiELBO(),\n",
        "    )\n",
        "\n",
        "    # Split RNG keys\n",
        "    rng_key, rng_key_samp, rng_key_init = random.split(args[\"rng_key\"], 3)\n",
        "    init_batch = agg_gp_predictive(rng_key_samp, args)[\"gp_aggr\"]\n",
        "\n",
        "    # Initialize SVI state\n",
        "    svi_state = svi.init(rng_key_init, init_batch)\n",
        "\n",
        "    # Pre-allocate test loss array\n",
        "    test_loss_list = jnp.zeros(num_epochs)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        rng_key, rng_key_train, rng_key_test = random.split(rng_key, 3)\n",
        "        t_start = time.time()\n",
        "\n",
        "        train_loss, svi_state = epoch_train(rng_key_train, svi_state, num_train)\n",
        "        test_loss = eval_test(rng_key_test, svi_state, num_test)\n",
        "        test_loss_list = test_loss_list.at[epoch].set(test_loss)\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f} ({time.time() - t_start:.2f} s)\")\n",
        "\n",
        "        if math.isnan(test_loss):  # Stop early if NaN\n",
        "            print(f\"NaN encountered at hidden_dim={hidden_dim}, z_dim={z_dim}. Skipping...\")\n",
        "            break  # Stop training if NaN occurs\n",
        "\n",
        "    # Store results only if valid\n",
        "    if not math.isnan(test_loss_list[-1]):\n",
        "        test_loss_results_final[(hidden_dim, z_dim)] = test_loss_list[-1]\n",
        "        test_loss_results_mean[(hidden_dim, z_dim)] = jnp.nanmean(test_loss_list)\n",
        "        print(f\"Final Test loss for hidden_dim={hidden_dim}, z_dim={z_dim}: {test_loss_list[-1]}\")\n",
        "        print(f\"Mean Test loss for hidden_dim={hidden_dim}, z_dim={z_dim}: {jnp.nanmean(test_loss_list)}\")\n",
        "\n",
        "print(\"Grid search complete.\")\n",
        "print(\"Results:\", test_loss_results_final)\n",
        "print(\"Mean Test Loss Results:\", test_loss_results_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimal hyperparams used is (50, 40) at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0, train loss : 63324172288.00, test loss : 3790235.75 (2.17 s.)\n",
            "Epoch : 1, train loss : 2249416960.00, test loss : 1871734.88 (2.12 s.)\n",
            "Epoch : 2, train loss : 1701763840.00, test loss : 1547703.62 (2.13 s.)\n",
            "Epoch : 3, train loss : 1208848384.00, test loss : 713949.56 (2.13 s.)\n",
            "Epoch : 4, train loss : 364533504.00, test loss : 46471.78 (2.13 s.)\n",
            "Epoch : 5, train loss : 42744768.00, test loss : 60777.09 (2.13 s.)\n",
            "Epoch : 6, train loss : 38784588.00, test loss : 36633.82 (2.13 s.)\n",
            "Epoch : 7, train loss : 33073066.00, test loss : 29483.56 (2.13 s.)\n",
            "Epoch : 8, train loss : 2330169856.00, test loss : 2698056.75 (2.14 s.)\n",
            "Epoch : 9, train loss : 2309892096.00, test loss : 2195475.25 (2.11 s.)\n",
            "Epoch : 10, train loss : 2275153408.00, test loss : 1753061.75 (2.11 s.)\n",
            "Epoch : 11, train loss : 1805689216.00, test loss : 1734156.88 (2.13 s.)\n",
            "Epoch : 12, train loss : 2367365888.00, test loss : 1983115.12 (2.12 s.)\n",
            "Epoch : 13, train loss : 2351059456.00, test loss : 2238835.75 (2.13 s.)\n",
            "Epoch : 14, train loss : 2376594688.00, test loss : 2395072.00 (2.13 s.)\n",
            "Epoch : 15, train loss : 2468862464.00, test loss : 1308861.00 (2.13 s.)\n",
            "Epoch : 16, train loss : 2075570816.00, test loss : 2414122.00 (2.13 s.)\n",
            "Epoch : 17, train loss : 2342607872.00, test loss : 1622784.50 (2.13 s.)\n",
            "Epoch : 18, train loss : 2356560896.00, test loss : 1373807.88 (2.13 s.)\n",
            "Epoch : 19, train loss : 2537936128.00, test loss : 2561924.00 (2.13 s.)\n",
            "Epoch : 20, train loss : 2160542464.00, test loss : 1654907.00 (2.15 s.)\n",
            "Epoch : 21, train loss : 1764141952.00, test loss : 887806.19 (2.15 s.)\n",
            "Epoch : 22, train loss : 922310400.00, test loss : 635805.62 (2.15 s.)\n",
            "Epoch : 23, train loss : 924567104.00, test loss : 1103864.75 (2.15 s.)\n",
            "Epoch : 24, train loss : 1035288576.00, test loss : 1127929.88 (2.15 s.)\n",
            "Epoch : 25, train loss : 535859104.00, test loss : 2872564.25 (2.15 s.)\n",
            "Epoch : 26, train loss : 640220736.00, test loss : 601718.94 (2.14 s.)\n",
            "Epoch : 27, train loss : 651452416.00, test loss : 153222.48 (2.15 s.)\n",
            "Epoch : 28, train loss : 572464256.00, test loss : 408857.59 (2.15 s.)\n"
          ]
        }
      ],
      "source": [
        "#-------------------------- Train VAE -------------------------- #\n",
        "run = True\n",
        "if run:\n",
        "    adam = numpyro.optim.Adam(step_size = args[\"learning_rate\"])\n",
        "    svi = SVI(\n",
        "        model=lambda batch: vae_model(batch, args[\"hidden_dim\"], args[\"z_dim\"], args[\"vae_var\"]),\n",
        "        guide=lambda batch: vae_guide(batch, args[\"hidden_dim\"], args[\"z_dim\"]),\n",
        "        optim=adam,\n",
        "        loss=RenyiELBO(),\n",
        "    )\n",
        "    rng_key, rng_key_samp, rng_key_init = random.split(args[\"rng_key\"],3)\n",
        "    #(num_samples, num_regions)\n",
        "    init_batch = agg_gp_predictive(rng_key_samp, args)[\"gp_aggr\"] #(num_samples, num_regions) <- i.e (5,58)\n",
        "    svi_state = svi.init(rng_key_init, init_batch)\n",
        "\n",
        "    test_loss_list = []\n",
        "\n",
        "    for i in range(args[\"num_epochs\"]):\n",
        "        rng_key, rng_key_train, rng_key_test, rng_key_infer = random.split(rng_key, 4)\n",
        "        t_start = time.time()\n",
        "        num_train = 1000\n",
        "        # Where forward/backward pass gets called for train\n",
        "        train_loss , svi_state = epoch_train(rng_key_train, svi_state, num_train)\n",
        "        num_test = 1000\n",
        "        # Where forward/backward pass gets called for test\n",
        "        test_loss = eval_test(rng_key_test, svi_state, num_test)\n",
        "        test_loss_list += [test_loss]\n",
        "\n",
        "        print(\"Epoch : {}, train loss : {:.2f}, test loss : {:.2f} ({:.2f} s.)\".format(i, train_loss, test_loss, time.time() - t_start))\n",
        "        if np.isnan(test_loss):\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vae_params = svi.get_params(svi_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE parameters saved to /content/model_weights/aggVAE/aggVAE_e29_h50_z40_batch100.pkl\n"
          ]
        }
      ],
      "source": [
        "save_dir = \"/content/model_weights/aggVAE\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(save_dir, f\"aggVAE_e{args['num_epochs']}_h{args['hidden_dim']}_z{args['z_dim']}_batch{args['batch_size']}.pkl\")\n",
        "\n",
        "with open(save_path, \"wb\") as file:\n",
        "    pickle.dump(vae_params, file)\n",
        "\n",
        "print(f\"VAE parameters saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08_Ap8Jyw7bf"
      },
      "source": [
        "## Run MCMC using trained VAE encoder --> section 5.2.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n1wWr2lQw7bg"
      },
      "outputs": [],
      "source": [
        "#open saved encoder\n",
        "with open(\"../model weights/aggVAE/aggVAE_e29_h50_z40_batch5.pkl\", \"rb\") as file:\n",
        "    vae_params = pickle.load(file)\n",
        "\n",
        "encoder_params = vae_params[\"encoder$params\"]\n",
        "decoder_params = vae_params[\"decoder$params\"]\n",
        "\n",
        "# save decoder params inside args\n",
        "args[\"decoder_params\"] = decoder_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This function is to use the decoder to generate aggVAE priors as reconstructions of aggGP priors learnt by the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MoQN0kgmw7bg"
      },
      "outputs": [],
      "source": [
        "N = 6\n",
        "\n",
        "def vae_sample(args):\n",
        "    dec_params = args[\"decoder_params\"]\n",
        "    z_dim, h_dim = dec_params[0][0].shape\n",
        "    z = numpyro.sample(\"z\", dist.Normal(jnp.zeros(z_dim), jnp.ones(z_dim)))\n",
        "    dec_init_fn, dec_apply_fn = vae_decoder(h_dim, N)\n",
        "    x_recon = dec_apply_fn(dec_params, z)\n",
        "    vae_aggr = numpyro.deterministic(\"vae_aggr\", x_recon)\n",
        "    return vae_aggr\n",
        "\n",
        "rng_key, rng_key_predict = random.split(random.PRNGKey(3))\n",
        "vae_predictive = Predictive(vae_sample, num_samples = 5)\n",
        "vae_draws = vae_predictive(rng_key_predict, args)[\"vae_aggr\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This function covers steps 5.2.7 - 5.2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wWOfTL9_w7bg"
      },
      "outputs": [],
      "source": [
        "# ------------------- Func for Agg VAE Prev ------------------- #\n",
        "def prev_model_vae_aggr(config=None):\n",
        "\n",
        "    if config is None:\n",
        "        config = {}\n",
        "\n",
        "    # Set defaults\n",
        "    x = config.get('x', None)\n",
        "    gp_kernel = config.get('gp_kernel', exp_sq_kernel)\n",
        "    noise = config.get('noise', 1e-4)\n",
        "    jitter = config.get('jitter', 1e-4)\n",
        "    M_lo = config.get('M_lo', None)\n",
        "    M_hi = config.get('M_hi', None)\n",
        "    kernel_length_prior = config.get('kernel_length', dist.InverseGamma(4, 1))\n",
        "    kernel_var_prior = config.get('kernel_var', dist.LogNormal(0, 0.1))\n",
        "    pop_density = config.get('pop_density', None)\n",
        "    urban_frac = config.get('urban_frac', None)\n",
        "    hdi_index = config.get('hdi_index', None)\n",
        "    count = config.get(\"count\", None)\n",
        "\n",
        "     # Total cases: pass in province level dengue case counts, mask district level ones as NaN\n",
        "    count_mask = ~jnp.isnan(count)\n",
        "\n",
        "    total_population = config.get('total_population', None)\n",
        "    is_prior_pred = config.get('prior_pred', False)\n",
        "    out_dims = config.get('out_dims', 6)\n",
        "\n",
        "    # GP\n",
        "    config_gp = config.copy()\n",
        "    config_gp['x'] = x\n",
        "    config_gp['gp_kernel'] = gp_kernel\n",
        "    config_gp['noise'] = noise\n",
        "    config_gp['jitter'] = jitter\n",
        "    config_gp['M_lo'] = M_lo\n",
        "    config_gp['M_hi'] = M_hi\n",
        "    config_gp['kernel_length'] = kernel_length_prior\n",
        "    config_gp['kernel_var'] = kernel_var_prior\n",
        "\n",
        "    # get the decoder parameter, and sample latent variables z from a standard  --> section 5.2.7\n",
        "    decoder_params = config[\"decoder_params\"]\n",
        "    z_dim, hidden_dim = decoder_params[0][0].shape\n",
        "    z = numpyro.sample(\"z\", dist.Normal(jnp.zeros(z_dim), jnp.ones(z_dim)))\n",
        "\n",
        "    #Instantiate decoder, apply the decoder to z to get aggVAE priors vae_aggr --> section 5.2.7\n",
        "    _, decoder_apply = vae_decoder(hidden_dim, out_dims) \n",
        "    vae_aggr = numpyro.deterministic(\"vae_aggr\", decoder_apply(decoder_params, z))\n",
        "\n",
        "    #scaling factor to scale vae_aggr to the appropriate scale for accurate dengue case count predictions --> section 5.2.8\n",
        "    s = numpyro.sample(\"sigma1\", dist.HalfNormal(200))\n",
        "\n",
        "    #get the scaled vae_aggr as vae\n",
        "    vae = numpyro.deterministic(\"vae\", s * vae_aggr)\n",
        "\n",
        "    # BHM modelling --> section 5.2.8\n",
        "    # Assign priors to model the fixed effects\n",
        "    b0 = numpyro.sample(\"b0\", dist.Normal(100, 10))  # Intercept\n",
        "    b_pop_density = numpyro.sample(\"b_pop_density\", dist.Normal(0, 1))  # Effect of population density\n",
        "    b_hdi = numpyro.sample(\"b_hdi\", dist.Normal(0, 1))  # Effect of HDI\n",
        "    b_urban = numpyro.sample(\"b_urban\", dist.Normal(0, 1))  # Effect of urbanicity\n",
        "\n",
        "    #the linear predictor model --> section 5.2.8\n",
        "    lp = numpyro.deterministic(\"lp\", nn.softplus(b0 +\n",
        "                                      vae +\n",
        "                                      b_pop_density * pop_density +\n",
        "                                      b_hdi * hdi_index +\n",
        "                                      b_urban * urban_frac))\n",
        "\n",
        "    # Gaussian variance --> section 5.2.8\n",
        "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(5))\n",
        "\n",
        "    # Predict dengue case counts at both province and district - levels using the lp model\n",
        "    full_pred_cases = numpyro.sample(\n",
        "        \"full_pred_cases\",\n",
        "        dist.Normal(lp, sigma))\n",
        "\n",
        "    # Use masking to hide observed case count data at district level from the model, so feed province level data only to the model\n",
        "    # This is useful for posterior predictive checks!\n",
        "    with numpyro.handlers.mask(mask=count_mask):\n",
        "        numpyro.sample(\n",
        "            \"pred_cases\",  \n",
        "            dist.Normal(lp, sigma),\n",
        "            obs=None if is_prior_pred else count)\n",
        "\n",
        "    # Store full predictions \n",
        "    numpyro.deterministic(\"pred_cases_out\", full_pred_cases)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the data and filter for passing only individual years to the BHM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2E02jvXw7bg",
        "outputId": "fc2e2cf6-de1c-400b-9312-9ccc1229dc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 'pol_pts_lo', 'pol_pts_hi', 'df_lo', 'df_hi'])\n",
            "Dengue incidence by province and year (low resolution):\n",
            "                  incidence\n",
            "Province    Year           \n",
            "DKI Jakarta 2020   0.001519\n",
            "            2021   0.001315\n",
            "            2022   0.002667\n",
            "            2023   0.001983 \n",
            "\n",
            "We are using data for the year 2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spatial_data = load_data()\n",
        "print(spatial_data.keys())\n",
        "\n",
        "# Lets lok at the data and dissect it\n",
        "lo_prev = spatial_data[\"df_lo\"].copy()\n",
        "lo_prev['incidence'] = (lo_prev.Cases / lo_prev.Population)\n",
        "print(\"Dengue incidence by province and year (low resolution):\")\n",
        "print(lo_prev.groupby(['Province', 'Year'])[['incidence']].mean(), '\\n')\n",
        "\n",
        "# make sure we use only one year of data\n",
        "year_data = 2022\n",
        "print(f'We are using data for the year {year_data}\\n')\n",
        "\n",
        "# let us filter the data for the most recent year\n",
        "df_lo = spatial_data[\"df_lo\"][spatial_data[\"df_lo\"].Year == year_data]\n",
        "df_hi = spatial_data[\"df_hi\"][spatial_data[\"df_hi\"].Year == year_data]\n",
        "\n",
        "df_lo = df_lo.copy()\n",
        "df_hi = df_hi.copy()\n",
        "df_lo.loc[:, 'incidence'] = df_lo.Cases / df_lo.Population\n",
        "df_hi.loc[:, 'incidence'] = df_hi.Cases / df_hi.Population\n",
        "total_population = jnp.concatenate([df_lo.Population.values, df_hi.Population.values])\n",
        "count = jnp.concatenate([df_lo.Cases.values, jnp.full((df_hi.shape[0],), jnp.nan)])\n",
        "hdi_index = jnp.concatenate([df_lo.HDI.values, df_hi.HDI.values])*100\n",
        "pop_density = jnp.concatenate([df_lo.Pop_den.values*1e2, (df_hi.Pop_den.values)*1e-1])\n",
        "urban_frac = jnp.concatenate([df_lo.urbanicity.values, df_hi.urbanicity.values])*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set the aggVAE model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F2rpI1RRw7bg"
      },
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define the BHM used\n",
        "model =  prev_model_vae_aggr\n",
        "\n",
        "#define the MCMC params used\n",
        "prob = 0.9\n",
        "tree = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krupHwTQw7bg",
        "outputId": "aab1f758-9e19-41a6-cfec-85b3d9e4aac7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sample: 100%|| 2000/2000 [9:27:18<00:00, 17.02s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to run MCMC: 567 minutes\n"
          ]
        }
      ],
      "source": [
        "# Define the sampler\n",
        "sampler = NUTS(model, target_accept_prob = prob, max_tree_depth = tree)\n",
        "mcmc = MCMC(sampler,\n",
        "            num_warmup=1000,\n",
        "            num_samples=1000,\n",
        "            num_chains=4,\n",
        "            chain_method=\"vectorized\")\n",
        "\n",
        "start = time.time()\n",
        "mcmc.run(PRNGKey(2), config_count)\n",
        "end = time.time()\n",
        "t_elapsed_min = round((end - start) / 60)\n",
        "print(f\"Time taken to run MCMC: {t_elapsed_min} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3eyNAXFw7bg",
        "outputId": "4b97cac2-c654-4ab6-b925-1a31c722ef61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MCMC object for year 2022 saved successfully at ../model weights/aggVAEPrev\\mcmc_jkt_2022_567min_z40_prob0.9_treedepth18.pkl.\n"
          ]
        }
      ],
      "source": [
        "#save mcmc for aggVAE jkt yearly (change the year manually)\n",
        "# Save the MCMC object as a pickle file\n",
        "# Define the path where you want to save the MCMC files\n",
        "\n",
        "save_dir = \"../model weights/aggVAEPrev\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define the file path where to save the MCMC object\n",
        "file_path = os.path.join(save_dir, f\"mcmc_jkt_{year_data}_{t_elapsed_min}min_z{args[\"z_dim\"]}_prob{prob}_treedepth{tree}.pkl\")\n",
        "\n",
        "# Save the MCMC object as a pickle file\n",
        "with open(file_path, 'wb') as f:\n",
        "        pickle.dump(mcmc, f)\n",
        "\n",
        "print(f\"MCMC object for year {year_data} saved successfully at {file_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     99.72      8.67     98.10     85.09    114.41       nan      1.01\n",
            "             b_hdi     -0.07      0.86     -0.28     -1.43      1.51    904.59      1.01\n",
            "     b_pop_density      0.47      1.16      0.48     -1.25      1.80      4.09      1.37\n",
            "           b_urban     -0.08      0.89     -0.39     -1.39      1.60     37.05      1.04\n",
            "full_pred_cases[0]   2112.72      6.29   2112.35   2103.26   2123.13   2145.95      1.00\n",
            "full_pred_cases[1]    376.25    138.00    348.80    198.18    612.92     22.35      1.09\n",
            "full_pred_cases[2]    177.32    152.57    151.07     -7.99    399.83      6.58      1.22\n",
            "full_pred_cases[3]    453.48    149.47    437.87    277.01    711.55     11.43      1.13\n",
            "full_pred_cases[4]    612.62    151.25    594.74    424.93    847.68     17.56      1.10\n",
            "full_pred_cases[5]    585.21    126.98    565.96    393.14    751.71    404.43      1.01\n",
            "             sigma      3.68      3.08      3.04      0.44      8.05      5.15      1.30\n",
            "            sigma1     96.24     67.30     97.89     12.05    175.11       nan      1.01\n",
            "              z[0]     -0.21      0.91     -0.50     -1.56      1.52     39.24      1.04\n",
            "              z[1]     -0.28      0.96     -0.47     -1.47      1.53     10.38      1.11\n",
            "              z[2]      0.19      0.97      0.31     -1.55      1.33      7.01      1.18\n",
            "              z[3]     -0.04      0.91     -0.36     -1.39      1.66     80.59      1.02\n",
            "              z[4]      0.27      1.07      0.38     -1.75      1.34      5.62      1.23\n",
            "              z[5]      0.19      0.86      0.50     -1.36      1.56     65.04      1.03\n",
            "              z[6]      0.13      0.88      0.26     -1.50      1.53   2239.65      1.00\n",
            "              z[7]     -0.51      1.12     -0.55     -1.71      1.27      4.59      1.31\n",
            "              z[8]     -0.61      1.26     -0.47     -2.25      1.07      3.22      1.57\n",
            "              z[9]      0.47      1.17      0.44     -1.33      1.83      4.08      1.37\n",
            "             z[10]      0.26      0.93      0.54     -1.31      1.66     17.05      1.07\n",
            "             z[11]      0.15      1.01      0.32     -1.56      1.55      8.65      1.14\n",
            "             z[12]     -0.16      0.95     -0.38     -1.58      1.40     11.93      1.10\n",
            "             z[13]     -0.25      1.02     -0.36     -1.30      1.65      5.88      1.22\n",
            "             z[14]      0.15      0.96      0.38     -1.50      1.56     10.90      1.11\n",
            "             z[15]      0.14      0.94      0.39     -1.66      1.36     13.96      1.08\n",
            "             z[16]      0.11      0.93      0.39     -1.61      1.39     18.97      1.07\n",
            "             z[17]     -0.16      0.97     -0.35     -1.36      1.68      8.56      1.13\n",
            "             z[18]      0.02      0.86     -0.08     -1.48      1.49   3124.07      1.00\n",
            "             z[19]      0.06      0.91     -0.15     -1.47      1.67   1787.13      1.01\n",
            "             z[20]      0.08      0.93      0.29     -1.55      1.40     12.03      1.10\n",
            "             z[21]      0.01      0.86     -0.06     -1.51      1.45   1820.95      1.00\n",
            "             z[22]     -0.28      0.85     -0.55     -1.60      1.21     28.39      1.05\n",
            "             z[23]      0.13      0.94      0.38     -1.65      1.42     14.38      1.08\n",
            "             z[24]     -0.02      0.88      0.11     -1.60      1.43   2792.68      1.00\n",
            "             z[25]     -0.31      0.87     -0.52     -1.44      1.35     13.52      1.09\n",
            "             z[26]     -0.10      0.88     -0.17     -1.58      1.45   2274.31      1.00\n",
            "             z[27]     -0.35      0.99     -0.47     -1.40      1.55      7.35      1.17\n",
            "             z[28]      0.14      0.84      0.31     -1.43      1.43   1874.26      1.01\n",
            "             z[29]      0.49      1.11      0.51     -1.27      1.71      4.41      1.33\n",
            "             z[30]     -0.48      1.24     -0.41     -2.03      1.22      3.49      1.49\n",
            "             z[31]     -0.41      1.21     -0.35     -1.88      1.33      3.67      1.45\n",
            "             z[32]      0.21      0.88      0.53     -1.31      1.66     54.80      1.03\n",
            "             z[33]     -0.12      0.91     -0.31     -1.37      1.48     10.90      1.11\n",
            "             z[34]     -0.01      0.85      0.15     -1.45      1.45   1987.57      1.01\n",
            "             z[35]     -0.06      0.90     -0.30     -1.36      1.58     17.54      1.07\n",
            "             z[36]      0.07      0.87      0.06     -1.44      1.56   2868.85      1.00\n",
            "             z[37]     -0.63      1.20     -0.56     -2.13      1.04      3.48      1.49\n",
            "             z[38]      0.44      1.05      0.53     -1.35      1.56      4.93      1.28\n",
            "             z[39]     -0.23      1.02     -0.34     -1.45      1.55      6.06      1.21\n",
            "\n",
            "Number of divergences: 601\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>2112.720</td>\n",
              "      <td>6.289</td>\n",
              "      <td>2100.305</td>\n",
              "      <td>2126.072</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.468</td>\n",
              "      <td>2397.0</td>\n",
              "      <td>1306.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>376.249</td>\n",
              "      <td>138.002</td>\n",
              "      <td>147.484</td>\n",
              "      <td>678.758</td>\n",
              "      <td>19.721</td>\n",
              "      <td>6.712</td>\n",
              "      <td>45.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>177.320</td>\n",
              "      <td>152.574</td>\n",
              "      <td>-9.871</td>\n",
              "      <td>437.506</td>\n",
              "      <td>39.749</td>\n",
              "      <td>3.751</td>\n",
              "      <td>21.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>453.479</td>\n",
              "      <td>149.471</td>\n",
              "      <td>190.497</td>\n",
              "      <td>748.053</td>\n",
              "      <td>29.805</td>\n",
              "      <td>5.989</td>\n",
              "      <td>22.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>612.623</td>\n",
              "      <td>151.249</td>\n",
              "      <td>377.967</td>\n",
              "      <td>923.387</td>\n",
              "      <td>24.903</td>\n",
              "      <td>8.871</td>\n",
              "      <td>26.0</td>\n",
              "      <td>365.0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>585.209</td>\n",
              "      <td>126.977</td>\n",
              "      <td>342.223</td>\n",
              "      <td>785.918</td>\n",
              "      <td>6.295</td>\n",
              "      <td>13.682</td>\n",
              "      <td>546.0</td>\n",
              "      <td>601.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>2112.906</td>\n",
              "      <td>4.584</td>\n",
              "      <td>2103.844</td>\n",
              "      <td>2122.495</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.348</td>\n",
              "      <td>3060.0</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>376.083</td>\n",
              "      <td>137.902</td>\n",
              "      <td>146.292</td>\n",
              "      <td>677.864</td>\n",
              "      <td>19.980</td>\n",
              "      <td>6.706</td>\n",
              "      <td>42.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>177.412</td>\n",
              "      <td>152.554</td>\n",
              "      <td>0.000</td>\n",
              "      <td>434.777</td>\n",
              "      <td>39.697</td>\n",
              "      <td>3.762</td>\n",
              "      <td>21.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>453.669</td>\n",
              "      <td>149.346</td>\n",
              "      <td>210.748</td>\n",
              "      <td>770.045</td>\n",
              "      <td>29.707</td>\n",
              "      <td>5.964</td>\n",
              "      <td>22.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>612.842</td>\n",
              "      <td>151.178</td>\n",
              "      <td>373.388</td>\n",
              "      <td>918.735</td>\n",
              "      <td>24.804</td>\n",
              "      <td>8.879</td>\n",
              "      <td>26.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>585.235</td>\n",
              "      <td>126.830</td>\n",
              "      <td>354.474</td>\n",
              "      <td>795.337</td>\n",
              "      <td>6.288</td>\n",
              "      <td>13.699</td>\n",
              "      <td>551.0</td>\n",
              "      <td>613.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>99.717</td>\n",
              "      <td>8.668</td>\n",
              "      <td>82.635</td>\n",
              "      <td>117.411</td>\n",
              "      <td>0.169</td>\n",
              "      <td>1.105</td>\n",
              "      <td>2715.0</td>\n",
              "      <td>1335.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.475</td>\n",
              "      <td>1.162</td>\n",
              "      <td>-1.667</td>\n",
              "      <td>1.804</td>\n",
              "      <td>0.388</td>\n",
              "      <td>0.017</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>1.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>-0.066</td>\n",
              "      <td>0.865</td>\n",
              "      <td>-1.762</td>\n",
              "      <td>1.658</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.111</td>\n",
              "      <td>1225.0</td>\n",
              "      <td>1540.0</td>\n",
              "      <td>1.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-0.078</td>\n",
              "      <td>0.890</td>\n",
              "      <td>-1.742</td>\n",
              "      <td>1.662</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.079</td>\n",
              "      <td>128.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>1.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1968.057</td>\n",
              "      <td>163.556</td>\n",
              "      <td>1705.287</td>\n",
              "      <td>2307.898</td>\n",
              "      <td>28.586</td>\n",
              "      <td>7.375</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1486.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>287.686</td>\n",
              "      <td>99.803</td>\n",
              "      <td>117.429</td>\n",
              "      <td>495.527</td>\n",
              "      <td>5.068</td>\n",
              "      <td>11.150</td>\n",
              "      <td>140.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>75.255</td>\n",
              "      <td>142.358</td>\n",
              "      <td>-162.586</td>\n",
              "      <td>332.828</td>\n",
              "      <td>15.590</td>\n",
              "      <td>13.800</td>\n",
              "      <td>27.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>365.804</td>\n",
              "      <td>113.566</td>\n",
              "      <td>189.759</td>\n",
              "      <td>610.975</td>\n",
              "      <td>8.365</td>\n",
              "      <td>11.486</td>\n",
              "      <td>37.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>525.317</td>\n",
              "      <td>123.346</td>\n",
              "      <td>314.436</td>\n",
              "      <td>771.001</td>\n",
              "      <td>6.898</td>\n",
              "      <td>12.994</td>\n",
              "      <td>73.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>497.390</td>\n",
              "      <td>103.189</td>\n",
              "      <td>305.575</td>\n",
              "      <td>643.962</td>\n",
              "      <td>5.614</td>\n",
              "      <td>14.786</td>\n",
              "      <td>52.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  2112.720    6.289  2100.305  2126.072      0.135    0.468   \n",
              "pred_cases_out[1]   376.249  138.002   147.484   678.758     19.721    6.712   \n",
              "pred_cases_out[2]   177.320  152.574    -9.871   437.506     39.749    3.751   \n",
              "pred_cases_out[3]   453.479  149.471   190.497   748.053     29.805    5.989   \n",
              "pred_cases_out[4]   612.623  151.249   377.967   923.387     24.903    8.871   \n",
              "pred_cases_out[5]   585.209  126.977   342.223   785.918      6.295   13.682   \n",
              "lp[0]              2112.906    4.584  2103.844  2122.495      0.085    0.348   \n",
              "lp[1]               376.083  137.902   146.292   677.864     19.980    6.706   \n",
              "lp[2]               177.412  152.554     0.000   434.777     39.697    3.762   \n",
              "lp[3]               453.669  149.346   210.748   770.045     29.707    5.964   \n",
              "lp[4]               612.842  151.178   373.388   918.735     24.804    8.879   \n",
              "lp[5]               585.235  126.830   354.474   795.337      6.288   13.699   \n",
              "b0                   99.717    8.668    82.635   117.411      0.169    1.105   \n",
              "b_pop_density         0.475    1.162    -1.667     1.804      0.388    0.017   \n",
              "b_hdi                -0.066    0.865    -1.762     1.658      0.025    0.111   \n",
              "b_urban              -0.078    0.890    -1.742     1.662      0.098    0.079   \n",
              "vae[0]             1968.057  163.556  1705.287  2307.898     28.586    7.375   \n",
              "vae[1]              287.686   99.803   117.429   495.527      5.068   11.150   \n",
              "vae[2]               75.255  142.358  -162.586   332.828     15.590   13.800   \n",
              "vae[3]              365.804  113.566   189.759   610.975      8.365   11.486   \n",
              "vae[4]              525.317  123.346   314.436   771.001      6.898   12.994   \n",
              "vae[5]              497.390  103.189   305.575   643.962      5.614   14.786   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    2397.0    1306.0   1.53  \n",
              "pred_cases_out[1]      45.0     407.0   1.09  \n",
              "pred_cases_out[2]      21.0     664.0   1.14  \n",
              "pred_cases_out[3]      22.0     374.0   1.15  \n",
              "pred_cases_out[4]      26.0     365.0   1.12  \n",
              "pred_cases_out[5]     546.0     601.0   1.53  \n",
              "lp[0]                3060.0    1123.0   1.53  \n",
              "lp[1]                  42.0     419.0   1.09  \n",
              "lp[2]                  21.0     377.0   1.15  \n",
              "lp[3]                  22.0     369.0   1.15  \n",
              "lp[4]                  26.0     371.0   1.13  \n",
              "lp[5]                 551.0     613.0   1.53  \n",
              "b0                   2715.0    1335.0   1.53  \n",
              "b_pop_density          10.0    2001.0   1.33  \n",
              "b_hdi                1225.0    1540.0   1.52  \n",
              "b_urban               128.0    1404.0   1.24  \n",
              "vae[0]                 43.0    1486.0   1.07  \n",
              "vae[1]                140.0     391.0   1.18  \n",
              "vae[2]                 27.0     385.0   1.11  \n",
              "vae[3]                 37.0     396.0   1.09  \n",
              "vae[4]                 73.0     398.0   1.10  \n",
              "vae[5]                 52.0     540.0   1.06  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive for posterior predictive checks\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        "    )\n",
        "\n",
        "# %%\n",
        "print(mcmc.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Posterior Predictive Checks - Convergence diagnostics (high effects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 22\n",
            "Average ESS for all aggVAE-low effects : 23\n",
            "Max r_hat for all aggVAE-low : 1.0700000524520874\n",
            "Average ESS for all aggVAE-high effects : 22\n",
            "Max r_hat for all aggVAE-high : 1.100000023841858\n"
          ]
        }
      ],
      "source": [
        "ss = numpyro.diagnostics.summary(mcmc.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Append predictions to the original df for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 95.1488\n",
            "MAE as % of average observed prevalence: 18.22%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot predicted vs actual observed prevalence at province level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "plot_incidence_map(df_lo, ax = ax[0], title = \"Low-Res Observed Prevalence\")\n",
        "plot_incidence_map(df_lo, plot_col = 'pred_cases', ax = ax[1], title = \"Low-Res Predicted Prevalence\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot predicted vs actual observed prevalence at district level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "plot_incidence_map(df_hi, ax = ax[0], title = \"High-Res Observed Prevalence\")\n",
        "plot_incidence_map(df_hi, plot_col = 'pred_cases', ax = ax[1], title = \"High-Res Predicted Prevalence\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the df predictions (change the year naming convention manually)\n",
        "#df_hi.to_csv(\"../data/processed/df_hi_jkt_2022_aggVAE_preds.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MCMC Fine Tuning Results (see which one produces the best Rhat and ESS. If both Rhat < 1.01 and ESS > 100 measure based on MAE (%) and RMSE)\n",
        "# This section produces values for tables 5-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model =  prev_model_vae_aggr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load MCMC objects\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2023_23min_z40_prob0.85_treedepth15.pkl\", \"rb\") as f_1:\n",
        "    mcmc_1 = pickle.load(f_1)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2023_31min_z40_prob0.9_treedepth15.pkl\", \"rb\") as f_2:\n",
        "    mcmc_2 = pickle.load(f_2)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2023_59min_z40_prob0.95_treedepth15.pkl\", \"rb\") as f_3:\n",
        "    mcmc_3 = pickle.load(f_3)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2023_1min_z30_default_batch5.pkl\", \"rb\") as f_4:\n",
        "    mcmc_4 = pickle.load(f_4)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2023_3min_z40_default_batch5.pkl\", \"rb\") as f_5:\n",
        "    mcmc_5 = pickle.load(f_5)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2023_5min_z40_default_batch100.pkl\", \"rb\") as f_6:\n",
        "    mcmc_6 = pickle.load(f_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 'pol_pts_lo', 'pol_pts_hi', 'df_lo', 'df_hi'])\n",
            "Dengue incidence by province and year (low resolution):\n",
            "                  incidence\n",
            "Province    Year           \n",
            "DKI Jakarta 2020   0.001519\n",
            "            2021   0.001315\n",
            "            2022   0.002667\n",
            "            2023   0.001983 \n",
            "\n",
            "We are using data for the year 2023\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#load the 2023 dataset\n",
        "spatial_data = load_data()\n",
        "print(spatial_data.keys())\n",
        "\n",
        "# Lets lok at the data and dissect it\n",
        "lo_prev = spatial_data[\"df_lo\"].copy()\n",
        "lo_prev['incidence'] = (lo_prev.Cases / lo_prev.Population)\n",
        "print(\"Dengue incidence by province and year (low resolution):\")\n",
        "print(lo_prev.groupby(['Province', 'Year'])[['incidence']].mean(), '\\n')\n",
        "\n",
        "# make sure we use only one year of data\n",
        "year_data = 2023\n",
        "print(f'We are using data for the year {year_data}\\n')\n",
        "\n",
        "# let us filter the data for the most recent year\n",
        "df_lo = spatial_data[\"df_lo\"][spatial_data[\"df_lo\"].Year == year_data]\n",
        "df_hi = spatial_data[\"df_hi\"][spatial_data[\"df_hi\"].Year == year_data]\n",
        "\n",
        "df_lo = df_lo.copy()\n",
        "df_hi = df_hi.copy()\n",
        "df_lo.loc[:, 'incidence'] = df_lo.Cases / df_lo.Population\n",
        "df_hi.loc[:, 'incidence'] = df_hi.Cases / df_hi.Population\n",
        "total_population = jnp.concatenate([df_lo.Population.values, df_hi.Population.values])\n",
        "count = jnp.concatenate([df_lo.Cases.values, jnp.full((df_hi.shape[0],), jnp.nan)])\n",
        "hdi_index = jnp.concatenate([df_lo.HDI.values, df_hi.HDI.values])*100\n",
        "pop_density = jnp.concatenate([df_lo.Pop_den.values*1e2, (df_hi.Pop_den.values)*1e-1])\n",
        "urban_frac = jnp.concatenate([df_lo.urbanicity.values, df_hi.urbanicity.values])*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine the best batch size, on 2023 dataset and default MCMC settings (for ease of computation) - Rhat, ESS values for Table 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MCMC 5 (z = 40, n = 1000) - 2023, batch size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "args[\"z_dim\"] = 40\n",
        "#open saved encoder\n",
        "with open(\"../model weights/aggVAE/aggVAE_e29_h50_z40_batch5.pkl\", \"rb\") as file:\n",
        "    vae_params = pickle.load(file)\n",
        "\n",
        "encoder_params = vae_params[\"encoder$params\"]\n",
        "decoder_params = vae_params[\"decoder$params\"]\n",
        "\n",
        "# save decoder params inside args\n",
        "args[\"decoder_params\"] = decoder_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     99.26      9.83     99.68     83.72    114.89     61.90      1.05\n",
            "             b_hdi     -0.37      1.10     -0.33     -2.23      1.46      8.57      1.27\n",
            "     b_pop_density      0.33      0.97      0.32     -1.21      1.91     35.71      1.10\n",
            "           b_urban     -0.31      1.39     -0.11     -2.67      1.56      3.49      1.64\n",
            "full_pred_cases[0]   1557.16     13.36   1560.03   1539.70   1576.54     11.21      1.40\n",
            "full_pred_cases[1]    214.16    183.06    176.60    -11.40    429.02      2.31      2.86\n",
            "full_pred_cases[2]    126.64    146.01      8.37    -13.09    326.79      2.54      2.22\n",
            "full_pred_cases[3]    257.65    203.07    212.67    -11.23    490.37      2.24      3.12\n",
            "full_pred_cases[4]    339.13    237.29    334.41    -13.65    586.18      2.16      3.75\n",
            "full_pred_cases[5]    332.03    211.15    393.10     -9.20    543.93      2.27      3.02\n",
            "             sigma      6.44      3.08      6.08      1.54     11.10     24.77      1.23\n",
            "            sigma1    140.58    119.05    104.96     10.34    334.51      3.51      1.63\n",
            "              z[0]     -0.10      1.14     -0.09     -1.87      1.91     19.58      1.35\n",
            "              z[1]      0.04      0.94      0.10     -1.66      1.51     44.11      1.12\n",
            "              z[2]     -0.35      1.00     -0.31     -1.82      1.35     47.61      1.07\n",
            "              z[3]      0.22      0.99      0.23     -1.37      1.85     66.02      1.05\n",
            "              z[4]      0.17      1.02      0.23     -1.46      1.76     41.91      1.12\n",
            "              z[5]      0.05      0.98      0.06     -1.28      1.91     39.42      1.09\n",
            "              z[6]      0.13      0.99      0.22     -1.34      1.73     21.91      1.11\n",
            "              z[7]     -0.29      1.01     -0.25     -1.99      1.20     63.78      1.08\n",
            "              z[8]      0.11      0.92      0.14     -1.36      1.65     97.46      1.08\n",
            "              z[9]      0.35      0.99      0.31     -1.32      1.97     23.58      1.08\n",
            "             z[10]      0.10      1.01      0.10     -1.41      1.84     65.91      1.04\n",
            "             z[11]      0.33      1.04      0.32     -1.45      1.81     14.13      1.21\n",
            "             z[12]      0.22      0.90      0.21     -1.13      1.77     72.41      1.03\n",
            "             z[13]      0.05      0.92      0.01     -1.43      1.54     85.97      1.07\n",
            "             z[14]     -0.10      0.96     -0.15     -1.56      1.55     18.88      1.13\n",
            "             z[15]     -0.02      0.84     -0.04     -1.36      1.46     56.25      1.07\n",
            "             z[16]      0.01      0.87      0.07     -1.40      1.51     48.78      1.10\n",
            "             z[17]      0.14      1.12      0.14     -1.89      1.88     28.05      1.20\n",
            "             z[18]      0.33      0.96      0.30     -1.19      2.04     19.50      1.15\n",
            "             z[19]     -0.03      0.89     -0.04     -1.43      1.48    120.07      1.02\n",
            "             z[20]      0.30      0.95      0.31     -1.18      1.87     36.94      1.08\n",
            "             z[21]     -0.19      0.99     -0.15     -1.72      1.42      9.76      1.18\n",
            "             z[22]      0.02      1.12     -0.04     -2.00      1.87      6.47      1.26\n",
            "             z[23]     -0.06      1.06     -0.05     -1.76      1.70     39.43      1.13\n",
            "             z[24]      0.08      1.06      0.04     -1.46      2.08     40.87      1.04\n",
            "             z[25]     -0.15      1.06     -0.12     -2.08      1.39     11.44      1.19\n",
            "             z[26]     -0.05      1.02     -0.06     -1.70      1.58     40.14      1.12\n",
            "             z[27]      0.07      0.99      0.10     -1.60      1.60     92.99      1.04\n",
            "             z[28]      0.05      0.95      0.01     -1.50      1.51     89.24      1.01\n",
            "             z[29]      0.02      1.20      0.03     -2.09      1.85     48.92      1.07\n",
            "             z[30]      0.11      0.97      0.12     -1.39      1.73     76.67      1.05\n",
            "             z[31]      0.17      0.82      0.18     -1.09      1.48    124.00      1.04\n",
            "             z[32]      0.15      1.00      0.18     -1.63      1.66     52.11      1.10\n",
            "             z[33]     -0.16      0.93     -0.28     -1.54      1.45     27.61      1.13\n",
            "             z[34]      0.14      1.05      0.13     -1.46      2.08     32.82      1.09\n",
            "             z[35]      0.25      1.01      0.31     -1.33      1.90     21.71      1.10\n",
            "             z[36]      0.10      0.86      0.13     -1.30      1.48     75.42      1.06\n",
            "             z[37]     -0.26      0.92     -0.25     -1.69      1.36     86.47      1.02\n",
            "             z[38]      0.08      0.95      0.07     -1.37      1.65     81.60      1.02\n",
            "             z[39]      0.09      0.96      0.12     -1.53      1.68     56.13      1.08\n",
            "\n",
            "Number of divergences: 336\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1557.161</td>\n",
              "      <td>13.365</td>\n",
              "      <td>1524.115</td>\n",
              "      <td>1576.543</td>\n",
              "      <td>4.291</td>\n",
              "      <td>4.554</td>\n",
              "      <td>18.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>214.156</td>\n",
              "      <td>183.055</td>\n",
              "      <td>-13.123</td>\n",
              "      <td>466.704</td>\n",
              "      <td>84.566</td>\n",
              "      <td>15.922</td>\n",
              "      <td>5.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>126.636</td>\n",
              "      <td>146.013</td>\n",
              "      <td>-18.084</td>\n",
              "      <td>353.392</td>\n",
              "      <td>63.819</td>\n",
              "      <td>8.875</td>\n",
              "      <td>7.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>257.647</td>\n",
              "      <td>203.067</td>\n",
              "      <td>-13.528</td>\n",
              "      <td>525.974</td>\n",
              "      <td>95.191</td>\n",
              "      <td>23.445</td>\n",
              "      <td>5.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>2.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>339.133</td>\n",
              "      <td>237.288</td>\n",
              "      <td>-15.512</td>\n",
              "      <td>635.931</td>\n",
              "      <td>113.318</td>\n",
              "      <td>40.538</td>\n",
              "      <td>5.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>2.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>332.030</td>\n",
              "      <td>211.151</td>\n",
              "      <td>-10.150</td>\n",
              "      <td>582.005</td>\n",
              "      <td>98.536</td>\n",
              "      <td>38.692</td>\n",
              "      <td>6.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1559.488</td>\n",
              "      <td>8.428</td>\n",
              "      <td>1543.307</td>\n",
              "      <td>1576.077</td>\n",
              "      <td>2.291</td>\n",
              "      <td>2.280</td>\n",
              "      <td>21.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>214.571</td>\n",
              "      <td>182.556</td>\n",
              "      <td>0.000</td>\n",
              "      <td>465.974</td>\n",
              "      <td>84.342</td>\n",
              "      <td>15.970</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>127.030</td>\n",
              "      <td>145.658</td>\n",
              "      <td>0.000</td>\n",
              "      <td>344.522</td>\n",
              "      <td>63.640</td>\n",
              "      <td>8.902</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>257.442</td>\n",
              "      <td>203.123</td>\n",
              "      <td>0.000</td>\n",
              "      <td>525.424</td>\n",
              "      <td>95.288</td>\n",
              "      <td>23.453</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>339.582</td>\n",
              "      <td>236.796</td>\n",
              "      <td>0.000</td>\n",
              "      <td>634.901</td>\n",
              "      <td>113.076</td>\n",
              "      <td>40.341</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>332.040</td>\n",
              "      <td>211.012</td>\n",
              "      <td>0.000</td>\n",
              "      <td>581.307</td>\n",
              "      <td>98.532</td>\n",
              "      <td>38.849</td>\n",
              "      <td>6.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>99.256</td>\n",
              "      <td>9.832</td>\n",
              "      <td>82.473</td>\n",
              "      <td>119.268</td>\n",
              "      <td>1.241</td>\n",
              "      <td>0.599</td>\n",
              "      <td>64.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>1.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.332</td>\n",
              "      <td>0.972</td>\n",
              "      <td>-1.269</td>\n",
              "      <td>2.249</td>\n",
              "      <td>0.169</td>\n",
              "      <td>0.057</td>\n",
              "      <td>33.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>-0.373</td>\n",
              "      <td>1.104</td>\n",
              "      <td>-2.422</td>\n",
              "      <td>1.764</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.109</td>\n",
              "      <td>12.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-0.314</td>\n",
              "      <td>1.394</td>\n",
              "      <td>-3.150</td>\n",
              "      <td>1.823</td>\n",
              "      <td>0.545</td>\n",
              "      <td>0.307</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1480.399</td>\n",
              "      <td>197.658</td>\n",
              "      <td>1124.429</td>\n",
              "      <td>1842.420</td>\n",
              "      <td>62.464</td>\n",
              "      <td>17.555</td>\n",
              "      <td>10.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>99.530</td>\n",
              "      <td>184.962</td>\n",
              "      <td>-308.508</td>\n",
              "      <td>336.426</td>\n",
              "      <td>76.483</td>\n",
              "      <td>48.590</td>\n",
              "      <td>7.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>-112.428</td>\n",
              "      <td>294.223</td>\n",
              "      <td>-746.719</td>\n",
              "      <td>236.124</td>\n",
              "      <td>124.835</td>\n",
              "      <td>77.006</td>\n",
              "      <td>6.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>150.353</td>\n",
              "      <td>204.408</td>\n",
              "      <td>-314.806</td>\n",
              "      <td>396.940</td>\n",
              "      <td>83.547</td>\n",
              "      <td>54.271</td>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>256.669</td>\n",
              "      <td>218.198</td>\n",
              "      <td>-242.337</td>\n",
              "      <td>537.706</td>\n",
              "      <td>87.084</td>\n",
              "      <td>55.900</td>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>284.610</td>\n",
              "      <td>129.495</td>\n",
              "      <td>-14.839</td>\n",
              "      <td>470.249</td>\n",
              "      <td>43.371</td>\n",
              "      <td>23.182</td>\n",
              "      <td>10.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1557.161   13.365  1524.115  1576.543      4.291    4.554   \n",
              "pred_cases_out[1]   214.156  183.055   -13.123   466.704     84.566   15.922   \n",
              "pred_cases_out[2]   126.636  146.013   -18.084   353.392     63.819    8.875   \n",
              "pred_cases_out[3]   257.647  203.067   -13.528   525.974     95.191   23.445   \n",
              "pred_cases_out[4]   339.133  237.288   -15.512   635.931    113.318   40.538   \n",
              "pred_cases_out[5]   332.030  211.151   -10.150   582.005     98.536   38.692   \n",
              "lp[0]              1559.488    8.428  1543.307  1576.077      2.291    2.280   \n",
              "lp[1]               214.571  182.556     0.000   465.974     84.342   15.970   \n",
              "lp[2]               127.030  145.658     0.000   344.522     63.640    8.902   \n",
              "lp[3]               257.442  203.123     0.000   525.424     95.288   23.453   \n",
              "lp[4]               339.582  236.796     0.000   634.901    113.076   40.341   \n",
              "lp[5]               332.040  211.012     0.000   581.307     98.532   38.849   \n",
              "b0                   99.256    9.832    82.473   119.268      1.241    0.599   \n",
              "b_pop_density         0.332    0.972    -1.269     2.249      0.169    0.057   \n",
              "b_hdi                -0.373    1.104    -2.422     1.764      0.315    0.109   \n",
              "b_urban              -0.314    1.394    -3.150     1.823      0.545    0.307   \n",
              "vae[0]             1480.399  197.658  1124.429  1842.420     62.464   17.555   \n",
              "vae[1]               99.530  184.962  -308.508   336.426     76.483   48.590   \n",
              "vae[2]             -112.428  294.223  -746.719   236.124    124.835   77.006   \n",
              "vae[3]              150.353  204.408  -314.806   396.940     83.547   54.271   \n",
              "vae[4]              256.669  218.198  -242.337   537.706     87.084   55.900   \n",
              "vae[5]              284.610  129.495   -14.839   470.249     43.371   23.182   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]      18.0      17.0   1.19  \n",
              "pred_cases_out[1]       5.0      28.0   2.04  \n",
              "pred_cases_out[2]       7.0      36.0   1.61  \n",
              "pred_cases_out[3]       5.0      58.0   2.10  \n",
              "pred_cases_out[4]       5.0      27.0   2.10  \n",
              "pred_cases_out[5]       6.0      22.0   2.04  \n",
              "lp[0]                  21.0      14.0   1.14  \n",
              "lp[1]                   5.0       4.0   2.23  \n",
              "lp[2]                   6.0       5.0   1.98  \n",
              "lp[3]                   5.0       4.0   2.24  \n",
              "lp[4]                   5.0       6.0   2.20  \n",
              "lp[5]                   6.0      30.0   2.05  \n",
              "b0                     64.0     148.0   1.05  \n",
              "b_pop_density          33.0     114.0   1.10  \n",
              "b_hdi                  12.0      54.0   1.27  \n",
              "b_urban                 7.0      12.0   1.58  \n",
              "vae[0]                 10.0      44.0   1.30  \n",
              "vae[1]                  7.0      26.0   1.58  \n",
              "vae[2]                  6.0      33.0   1.74  \n",
              "vae[3]                  7.0      27.0   1.54  \n",
              "vae[4]                  8.0      28.0   1.48  \n",
              "vae[5]                 10.0      37.0   1.34  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_5.get_samples()\n",
        "\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_5,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        "    )\n",
        "\n",
        "# %%\n",
        "print(mcmc_5.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 5\n",
            "Average ESS for all aggVAE-low effects : 5\n",
            "Max r_hat for all aggVAE-low : 1.3799999952316284\n",
            "Average ESS for all aggVAE-high effects : 4\n",
            "Max r_hat for all aggVAE-high : 1.590000033378601\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_5.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MCMC 6 (z = 40, n = 1000) - 2023, batch size 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "args[\"z_dim\"] = 40\n",
        "#open saved encoder\n",
        "with open(\"../model weights/aggVAE/aggVAE_e29_h50_z40_batch100.pkl\", \"rb\") as file:\n",
        "    vae_params = pickle.load(file)\n",
        "\n",
        "encoder_params = vae_params[\"encoder$params\"]\n",
        "decoder_params = vae_params[\"decoder$params\"]\n",
        "\n",
        "# save decoder params inside args\n",
        "args[\"decoder_params\"] = decoder_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    102.49     11.96    103.78     85.09    116.84      2.00     47.46\n",
            "             b_hdi     -0.04      1.13      0.38     -1.97      1.03      2.01     21.86\n",
            "     b_pop_density      0.12      0.65      0.38     -0.99      0.69      2.01     20.33\n",
            "           b_urban     -1.09      1.02     -0.84     -2.80      0.00      2.05      7.04\n",
            "full_pred_cases[0]   1571.17     10.64   1571.71   1549.49   1583.00      5.30      1.61\n",
            "full_pred_cases[1]     58.13     99.78     15.12    -27.80    228.12      2.00    180.88\n",
            "full_pred_cases[2]     16.47     39.62      4.46    -19.28     84.02      2.02     18.40\n",
            "full_pred_cases[3]     75.47    123.46     12.61     -5.57    288.77      2.00     90.15\n",
            "full_pred_cases[4]    117.87    160.22     46.26     -8.78    389.85      2.00    244.22\n",
            "full_pred_cases[5]    182.90    126.00    152.72     44.48    382.38      2.00    168.41\n",
            "             sigma     12.45      6.04     13.65      2.72     19.43      2.02     10.55\n",
            "            sigma1    305.59    160.25    326.54     47.29    482.36      2.02     12.97\n",
            "              z[0]      0.55      0.88      0.43     -0.68      1.63      2.04     10.11\n",
            "              z[1]      0.76      0.34      0.72      0.25      1.20      2.04      9.45\n",
            "              z[2]      0.21      1.22     -0.01     -1.45      2.01      2.01     20.36\n",
            "              z[3]      0.38      1.23     -0.06     -0.76      2.30      2.07      7.93\n",
            "              z[4]     -0.21      0.36     -0.09     -0.95      0.14      2.12      5.18\n",
            "              z[5]      0.56      1.14      0.61     -1.03      2.16      2.05     11.45\n",
            "              z[6]     -0.32      0.82     -0.57     -1.21      1.07      2.01     20.56\n",
            "              z[7]      0.37      1.23      0.02     -1.03      2.34      2.00     26.23\n",
            "              z[8]      0.05      0.98      0.27     -1.27      1.32      2.02     14.54\n",
            "              z[9]     -0.20      0.72     -0.01     -1.39      0.55      2.00     29.65\n",
            "             z[10]      1.31      0.55      1.45      0.38      1.91      2.02     13.25\n",
            "             z[11]      1.98      0.57      1.81      1.29      2.86      2.04     10.15\n",
            "             z[12]      1.24      0.32      1.30      0.77      1.53      2.20      4.14\n",
            "             z[13]      0.14      0.92      0.51     -1.20      1.33      2.04      8.23\n",
            "             z[14]     -0.11      1.41      0.67     -2.55      0.85      2.01     25.39\n",
            "             z[15]      0.80      0.69      0.75     -0.15      1.73      2.02     12.24\n",
            "             z[16]     -1.00      0.80     -1.11     -1.90      0.30      2.01     13.28\n",
            "             z[17]      0.51      0.44      0.38      0.04      1.09      2.01     13.55\n",
            "             z[18]      0.92      1.02      1.17     -0.68      2.19      2.01     26.77\n",
            "             z[19]     -0.43      1.15     -0.87     -1.59      1.51      2.00     40.83\n",
            "             z[20]     -0.14      0.95     -0.17     -1.39      1.28      2.02     15.79\n",
            "             z[21]     -0.01      1.06     -0.22     -0.99      1.79      2.02     16.33\n",
            "             z[22]     -0.22      0.74     -0.48     -1.06      0.92      2.01     14.37\n",
            "             z[23]     -0.14      1.19      0.28     -2.11      1.11      2.02     17.95\n",
            "             z[24]     -0.91      0.51     -0.65     -1.78     -0.48      2.00     25.88\n",
            "             z[25]      0.49      0.88      0.49     -0.58      1.48      2.01     14.06\n",
            "             z[26]     -0.59      0.53     -0.64     -1.12      0.25      2.01     12.95\n",
            "             z[27]      0.24      0.96      0.21     -1.14      1.66      2.02     12.32\n",
            "             z[28]      0.29      0.65      0.42     -0.83      1.08      2.01     18.46\n",
            "             z[29]     -0.73      0.11     -0.76     -0.88     -0.57      2.58      2.75\n",
            "             z[30]     -0.22      0.92     -0.54     -1.04      1.34      2.03      8.73\n",
            "             z[31]      0.72      0.75      0.78     -0.42      1.69      2.00     27.24\n",
            "             z[32]      0.38      0.92      0.29     -0.76      1.80      2.05     13.02\n",
            "             z[33]     -0.31      0.97     -0.64     -1.35      1.23      2.01     23.29\n",
            "             z[34]      0.17      0.39      0.25     -0.35      0.72      2.72      2.46\n",
            "             z[35]     -0.32      0.30     -0.33     -0.83      0.14      2.31      3.10\n",
            "             z[36]     -0.07      0.40     -0.23     -0.51      0.50      2.03     13.34\n",
            "             z[37]      0.36      0.65      0.57     -0.86      0.97      2.02     11.58\n",
            "             z[38]      0.07      0.97      0.47     -1.62      0.96      2.02     19.02\n",
            "             z[39]     -0.15      0.40      0.04     -0.81      0.18      2.18      3.77\n",
            "\n",
            "Number of divergences: 0\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1571.171</td>\n",
              "      <td>10.639</td>\n",
              "      <td>1541.461</td>\n",
              "      <td>1583.036</td>\n",
              "      <td>4.005</td>\n",
              "      <td>3.210</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>58.134</td>\n",
              "      <td>99.781</td>\n",
              "      <td>-27.805</td>\n",
              "      <td>228.696</td>\n",
              "      <td>49.690</td>\n",
              "      <td>27.813</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>16.469</td>\n",
              "      <td>39.624</td>\n",
              "      <td>-23.626</td>\n",
              "      <td>85.528</td>\n",
              "      <td>19.700</td>\n",
              "      <td>10.099</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>75.472</td>\n",
              "      <td>123.457</td>\n",
              "      <td>-5.579</td>\n",
              "      <td>290.024</td>\n",
              "      <td>61.477</td>\n",
              "      <td>35.338</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>117.867</td>\n",
              "      <td>160.222</td>\n",
              "      <td>-8.772</td>\n",
              "      <td>390.995</td>\n",
              "      <td>79.789</td>\n",
              "      <td>44.053</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>182.901</td>\n",
              "      <td>125.998</td>\n",
              "      <td>43.009</td>\n",
              "      <td>382.504</td>\n",
              "      <td>62.745</td>\n",
              "      <td>29.776</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1571.111</td>\n",
              "      <td>13.858</td>\n",
              "      <td>1544.985</td>\n",
              "      <td>1599.719</td>\n",
              "      <td>3.861</td>\n",
              "      <td>1.895</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>57.088</td>\n",
              "      <td>98.894</td>\n",
              "      <td>0.000</td>\n",
              "      <td>229.270</td>\n",
              "      <td>49.248</td>\n",
              "      <td>28.431</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>20.193</td>\n",
              "      <td>34.992</td>\n",
              "      <td>0.000</td>\n",
              "      <td>81.994</td>\n",
              "      <td>17.420</td>\n",
              "      <td>10.065</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>71.560</td>\n",
              "      <td>123.963</td>\n",
              "      <td>0.000</td>\n",
              "      <td>287.246</td>\n",
              "      <td>61.732</td>\n",
              "      <td>35.638</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>110.798</td>\n",
              "      <td>164.022</td>\n",
              "      <td>0.000</td>\n",
              "      <td>393.501</td>\n",
              "      <td>81.669</td>\n",
              "      <td>46.275</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>179.082</td>\n",
              "      <td>125.362</td>\n",
              "      <td>34.655</td>\n",
              "      <td>381.956</td>\n",
              "      <td>62.332</td>\n",
              "      <td>30.801</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>102.493</td>\n",
              "      <td>11.965</td>\n",
              "      <td>85.090</td>\n",
              "      <td>117.027</td>\n",
              "      <td>5.957</td>\n",
              "      <td>2.136</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.120</td>\n",
              "      <td>0.647</td>\n",
              "      <td>-0.990</td>\n",
              "      <td>0.709</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.180</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>-0.038</td>\n",
              "      <td>1.131</td>\n",
              "      <td>-1.969</td>\n",
              "      <td>1.129</td>\n",
              "      <td>0.563</td>\n",
              "      <td>0.308</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-1.085</td>\n",
              "      <td>1.017</td>\n",
              "      <td>-2.883</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.501</td>\n",
              "      <td>0.255</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1558.400</td>\n",
              "      <td>86.958</td>\n",
              "      <td>1438.769</td>\n",
              "      <td>1701.731</td>\n",
              "      <td>42.348</td>\n",
              "      <td>19.634</td>\n",
              "      <td>5.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>-157.401</td>\n",
              "      <td>282.033</td>\n",
              "      <td>-537.114</td>\n",
              "      <td>169.131</td>\n",
              "      <td>139.984</td>\n",
              "      <td>39.972</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>-496.836</td>\n",
              "      <td>446.041</td>\n",
              "      <td>-1076.745</td>\n",
              "      <td>24.050</td>\n",
              "      <td>221.432</td>\n",
              "      <td>58.244</td>\n",
              "      <td>5.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>-145.366</td>\n",
              "      <td>330.367</td>\n",
              "      <td>-595.056</td>\n",
              "      <td>227.714</td>\n",
              "      <td>164.002</td>\n",
              "      <td>47.583</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>-47.639</td>\n",
              "      <td>330.172</td>\n",
              "      <td>-487.629</td>\n",
              "      <td>334.172</td>\n",
              "      <td>163.808</td>\n",
              "      <td>44.464</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>172.041</td>\n",
              "      <td>112.443</td>\n",
              "      <td>43.665</td>\n",
              "      <td>316.986</td>\n",
              "      <td>55.399</td>\n",
              "      <td>11.227</td>\n",
              "      <td>5.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1571.171   10.639  1541.461  1583.036      4.005    3.210   \n",
              "pred_cases_out[1]    58.134   99.781   -27.805   228.696     49.690   27.813   \n",
              "pred_cases_out[2]    16.469   39.624   -23.626    85.528     19.700   10.099   \n",
              "pred_cases_out[3]    75.472  123.457    -5.579   290.024     61.477   35.338   \n",
              "pred_cases_out[4]   117.867  160.222    -8.772   390.995     79.789   44.053   \n",
              "pred_cases_out[5]   182.901  125.998    43.009   382.504     62.745   29.776   \n",
              "lp[0]              1571.111   13.858  1544.985  1599.719      3.861    1.895   \n",
              "lp[1]                57.088   98.894     0.000   229.270     49.248   28.431   \n",
              "lp[2]                20.193   34.992     0.000    81.994     17.420   10.065   \n",
              "lp[3]                71.560  123.963     0.000   287.246     61.732   35.638   \n",
              "lp[4]               110.798  164.022     0.000   393.501     81.669   46.275   \n",
              "lp[5]               179.082  125.362    34.655   381.956     62.332   30.801   \n",
              "b0                  102.493   11.965    85.090   117.027      5.957    2.136   \n",
              "b_pop_density         0.120    0.647    -0.990     0.709      0.322    0.180   \n",
              "b_hdi                -0.038    1.131    -1.969     1.129      0.563    0.308   \n",
              "b_urban              -1.085    1.017    -2.883     0.004      0.501    0.255   \n",
              "vae[0]             1558.400   86.958  1438.769  1701.731     42.348   19.634   \n",
              "vae[1]             -157.401  282.033  -537.114   169.131    139.984   39.972   \n",
              "vae[2]             -496.836  446.041 -1076.745    24.050    221.432   58.244   \n",
              "vae[3]             -145.366  330.367  -595.056   227.714    164.002   47.583   \n",
              "vae[4]              -47.639  330.172  -487.629   334.172    163.808   44.464   \n",
              "vae[5]              172.041  112.443    43.665   316.986     55.399   11.227   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]       7.0      17.0   1.98  \n",
              "pred_cases_out[1]       5.0      19.0   3.14  \n",
              "pred_cases_out[2]       5.0      15.0   2.99  \n",
              "pred_cases_out[3]       4.0      13.0   3.61  \n",
              "pred_cases_out[4]       4.0      12.0   3.85  \n",
              "pred_cases_out[5]       4.0      11.0   3.51  \n",
              "lp[0]                  13.0      30.0   1.23  \n",
              "lp[1]                   5.0       4.0   3.22  \n",
              "lp[2]                   5.0       4.0   3.30  \n",
              "lp[3]                   4.0       4.0   3.73  \n",
              "lp[4]                   4.0       4.0   3.66  \n",
              "lp[5]                   5.0      25.0   3.08  \n",
              "b0                      4.0      15.0   3.30  \n",
              "b_pop_density           5.0      13.0   2.72  \n",
              "b_hdi                   4.0      11.0   3.50  \n",
              "b_urban                 5.0      12.0   3.28  \n",
              "vae[0]                  5.0      28.0   2.49  \n",
              "vae[1]                  4.0      12.0   3.37  \n",
              "vae[2]                  5.0      27.0   3.13  \n",
              "vae[3]                  4.0      12.0   3.33  \n",
              "vae[4]                  4.0      12.0   3.33  \n",
              "vae[5]                  5.0      21.0   2.30  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_6.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_6,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},)\n",
        "\n",
        "# %%\n",
        "print(mcmc_6.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 2\n",
            "Average ESS for all aggVAE-low effects : 2\n",
            "Max r_hat for all aggVAE-low : 28.40999984741211\n",
            "Average ESS for all aggVAE-high effects : 2\n",
            "Max r_hat for all aggVAE-high : 35.720001220703125\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_6.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine the best target_accept_prob, setting tree depth = 20, on 2023 dataset --> used to produce values for Tables 7 (Rhat, ESS) and 8 (Rhat, ESS, RMSE, MAE (%))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MCMC 1 (z = 40, n = 1000 Inference, target accept prob = 0.85, tree depth 15) - 2023, batch size 5 (table 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    100.01      9.70     99.87     84.51    115.72   3609.96      1.00\n",
            "             b_hdi      0.08      1.02      0.08     -1.58      1.75   1460.67      1.00\n",
            "     b_pop_density      0.08      1.02      0.08     -1.55      1.75   2591.65      1.00\n",
            "           b_urban      0.05      1.01      0.03     -1.55      1.75   1555.27      1.00\n",
            "full_pred_cases[0]   1562.00      8.06   1562.00   1548.86   1575.06   2861.36      1.00\n",
            "full_pred_cases[1]    328.06    136.39    328.80     97.27    551.71    640.25      1.01\n",
            "full_pred_cases[2]    192.13    138.94    190.00    -11.34    375.45    722.12      1.00\n",
            "full_pred_cases[3]    387.86    141.02    392.14    158.52    619.72    653.50      1.01\n",
            "full_pred_cases[4]    503.53    139.13    506.97    271.81    717.27    598.49      1.01\n",
            "full_pred_cases[5]    473.46    137.01    463.61    262.52    679.28    593.84      1.00\n",
            "             sigma      5.02      2.88      4.58      0.78      9.46    297.12      1.02\n",
            "            sigma1     80.28     70.42     56.93      7.54    181.67    659.10      1.01\n",
            "              z[0]     -0.04      0.99     -0.03     -1.69      1.56   4075.50      1.00\n",
            "              z[1]     -0.08      0.97     -0.07     -1.72      1.48   3219.87      1.00\n",
            "              z[2]     -0.06      1.03     -0.08     -1.72      1.66   2972.52      1.00\n",
            "              z[3]      0.08      1.04      0.06     -1.51      1.91   2627.51      1.00\n",
            "              z[4]     -0.08      1.05     -0.09     -1.83      1.60   2562.01      1.00\n",
            "              z[5]      0.05      0.97      0.06     -1.47      1.67   2783.57      1.00\n",
            "              z[6]      0.09      1.00      0.10     -1.53      1.72   3247.77      1.00\n",
            "              z[7]     -0.09      1.04     -0.08     -1.78      1.59   2886.88      1.00\n",
            "              z[8]     -0.08      1.00     -0.08     -1.71      1.56   3517.76      1.00\n",
            "              z[9]     -0.02      0.99     -0.05     -1.58      1.61   2964.98      1.00\n",
            "             z[10]      0.08      1.00      0.07     -1.58      1.71   3306.84      1.00\n",
            "             z[11]     -0.12      1.01     -0.13     -1.80      1.53   2350.42      1.00\n",
            "             z[12]      0.03      0.99      0.02     -1.51      1.67   2764.36      1.00\n",
            "             z[13]      0.03      1.01      0.04     -1.64      1.65   2898.96      1.00\n",
            "             z[14]     -0.09      0.97     -0.07     -1.67      1.51   2830.61      1.00\n",
            "             z[15]     -0.11      1.01     -0.10     -1.80      1.50   2957.16      1.00\n",
            "             z[16]     -0.06      0.99     -0.05     -1.75      1.49   3296.19      1.00\n",
            "             z[17]      0.10      1.01      0.09     -1.54      1.77   2841.57      1.00\n",
            "             z[18]      0.04      1.00      0.04     -1.58      1.71   2953.77      1.00\n",
            "             z[19]      0.10      0.97      0.06     -1.41      1.78   2915.54      1.00\n",
            "             z[20]     -0.09      1.02     -0.11     -1.78      1.51   2236.98      1.00\n",
            "             z[21]      0.01      0.99     -0.02     -1.60      1.68   3113.94      1.00\n",
            "             z[22]     -0.14      0.97     -0.15     -1.70      1.51   2697.33      1.00\n",
            "             z[23]     -0.06      0.95     -0.05     -1.71      1.42   3649.30      1.00\n",
            "             z[24]     -0.06      1.02     -0.07     -1.61      1.71   2994.20      1.00\n",
            "             z[25]     -0.08      0.96     -0.06     -1.81      1.36   3281.25      1.00\n",
            "             z[26]     -0.06      0.99     -0.05     -1.61      1.67   3385.64      1.00\n",
            "             z[27]     -0.06      1.05     -0.07     -1.65      1.72   2961.76      1.00\n",
            "             z[28]      0.08      0.97      0.07     -1.48      1.71   3296.90      1.00\n",
            "             z[29]      0.08      0.97      0.07     -1.44      1.71   2766.80      1.00\n",
            "             z[30]      0.05      0.99      0.05     -1.64      1.62   3134.78      1.00\n",
            "             z[31]      0.05      0.96      0.08     -1.55      1.57   2234.38      1.00\n",
            "             z[32]      0.09      1.02      0.09     -1.67      1.73   2694.87      1.00\n",
            "             z[33]      0.08      0.95      0.06     -1.45      1.65   2698.99      1.00\n",
            "             z[34]     -0.09      0.99     -0.13     -1.72      1.55   2814.84      1.00\n",
            "             z[35]      0.09      0.96      0.08     -1.51      1.65   3309.35      1.00\n",
            "             z[36]      0.06      1.00      0.06     -1.67      1.62   3124.36      1.00\n",
            "             z[37]     -0.09      1.00     -0.12     -1.78      1.49   2395.33      1.00\n",
            "             z[38]      0.04      0.99      0.04     -1.56      1.65   3023.26      1.00\n",
            "             z[39]      0.09      0.96      0.08     -1.45      1.72   2893.86      1.00\n",
            "\n",
            "Number of divergences: 891\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1561.999</td>\n",
              "      <td>8.059</td>\n",
              "      <td>1546.667</td>\n",
              "      <td>1578.896</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.298</td>\n",
              "      <td>3172.0</td>\n",
              "      <td>1583.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>328.063</td>\n",
              "      <td>136.390</td>\n",
              "      <td>85.323</td>\n",
              "      <td>629.426</td>\n",
              "      <td>5.378</td>\n",
              "      <td>3.757</td>\n",
              "      <td>649.0</td>\n",
              "      <td>628.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>192.125</td>\n",
              "      <td>138.936</td>\n",
              "      <td>-16.369</td>\n",
              "      <td>409.060</td>\n",
              "      <td>5.165</td>\n",
              "      <td>2.994</td>\n",
              "      <td>727.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>387.857</td>\n",
              "      <td>141.025</td>\n",
              "      <td>127.517</td>\n",
              "      <td>675.265</td>\n",
              "      <td>5.512</td>\n",
              "      <td>3.774</td>\n",
              "      <td>662.0</td>\n",
              "      <td>761.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>503.530</td>\n",
              "      <td>139.129</td>\n",
              "      <td>240.873</td>\n",
              "      <td>782.733</td>\n",
              "      <td>5.667</td>\n",
              "      <td>4.715</td>\n",
              "      <td>627.0</td>\n",
              "      <td>638.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>473.460</td>\n",
              "      <td>137.011</td>\n",
              "      <td>226.650</td>\n",
              "      <td>732.950</td>\n",
              "      <td>5.599</td>\n",
              "      <td>7.737</td>\n",
              "      <td>729.0</td>\n",
              "      <td>568.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1562.085</td>\n",
              "      <td>5.905</td>\n",
              "      <td>1550.519</td>\n",
              "      <td>1574.146</td>\n",
              "      <td>0.106</td>\n",
              "      <td>0.203</td>\n",
              "      <td>3418.0</td>\n",
              "      <td>1817.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>328.052</td>\n",
              "      <td>136.223</td>\n",
              "      <td>0.000</td>\n",
              "      <td>540.643</td>\n",
              "      <td>5.376</td>\n",
              "      <td>3.764</td>\n",
              "      <td>646.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>192.125</td>\n",
              "      <td>138.902</td>\n",
              "      <td>0.000</td>\n",
              "      <td>409.759</td>\n",
              "      <td>5.159</td>\n",
              "      <td>2.983</td>\n",
              "      <td>691.0</td>\n",
              "      <td>970.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>387.998</td>\n",
              "      <td>140.696</td>\n",
              "      <td>126.688</td>\n",
              "      <td>671.645</td>\n",
              "      <td>5.504</td>\n",
              "      <td>3.784</td>\n",
              "      <td>661.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>503.564</td>\n",
              "      <td>138.952</td>\n",
              "      <td>247.932</td>\n",
              "      <td>789.307</td>\n",
              "      <td>5.646</td>\n",
              "      <td>4.691</td>\n",
              "      <td>630.0</td>\n",
              "      <td>633.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>473.315</td>\n",
              "      <td>136.975</td>\n",
              "      <td>199.674</td>\n",
              "      <td>707.571</td>\n",
              "      <td>5.615</td>\n",
              "      <td>7.743</td>\n",
              "      <td>724.0</td>\n",
              "      <td>564.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>100.009</td>\n",
              "      <td>9.698</td>\n",
              "      <td>81.193</td>\n",
              "      <td>116.986</td>\n",
              "      <td>0.161</td>\n",
              "      <td>0.165</td>\n",
              "      <td>3614.0</td>\n",
              "      <td>2480.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.078</td>\n",
              "      <td>1.019</td>\n",
              "      <td>-1.770</td>\n",
              "      <td>2.067</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.020</td>\n",
              "      <td>2642.0</td>\n",
              "      <td>1937.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.078</td>\n",
              "      <td>1.017</td>\n",
              "      <td>-1.742</td>\n",
              "      <td>2.064</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.018</td>\n",
              "      <td>1475.0</td>\n",
              "      <td>1932.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>0.047</td>\n",
              "      <td>1.012</td>\n",
              "      <td>-1.868</td>\n",
              "      <td>1.936</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.019</td>\n",
              "      <td>1594.0</td>\n",
              "      <td>2188.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1441.770</td>\n",
              "      <td>176.293</td>\n",
              "      <td>1115.489</td>\n",
              "      <td>1775.341</td>\n",
              "      <td>4.119</td>\n",
              "      <td>3.507</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>215.863</td>\n",
              "      <td>85.030</td>\n",
              "      <td>59.429</td>\n",
              "      <td>394.699</td>\n",
              "      <td>2.927</td>\n",
              "      <td>3.411</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>64.080</td>\n",
              "      <td>118.122</td>\n",
              "      <td>-169.982</td>\n",
              "      <td>274.205</td>\n",
              "      <td>4.470</td>\n",
              "      <td>5.392</td>\n",
              "      <td>885.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>275.801</td>\n",
              "      <td>95.613</td>\n",
              "      <td>59.828</td>\n",
              "      <td>437.551</td>\n",
              "      <td>3.033</td>\n",
              "      <td>3.480</td>\n",
              "      <td>1189.0</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>392.359</td>\n",
              "      <td>106.807</td>\n",
              "      <td>190.780</td>\n",
              "      <td>604.434</td>\n",
              "      <td>3.314</td>\n",
              "      <td>3.909</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>362.974</td>\n",
              "      <td>103.774</td>\n",
              "      <td>196.551</td>\n",
              "      <td>567.939</td>\n",
              "      <td>3.827</td>\n",
              "      <td>8.025</td>\n",
              "      <td>1251.0</td>\n",
              "      <td>794.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1561.999    8.059  1546.667  1578.896      0.152    0.298   \n",
              "pred_cases_out[1]   328.063  136.390    85.323   629.426      5.378    3.757   \n",
              "pred_cases_out[2]   192.125  138.936   -16.369   409.060      5.165    2.994   \n",
              "pred_cases_out[3]   387.857  141.025   127.517   675.265      5.512    3.774   \n",
              "pred_cases_out[4]   503.530  139.129   240.873   782.733      5.667    4.715   \n",
              "pred_cases_out[5]   473.460  137.011   226.650   732.950      5.599    7.737   \n",
              "lp[0]              1562.085    5.905  1550.519  1574.146      0.106    0.203   \n",
              "lp[1]               328.052  136.223     0.000   540.643      5.376    3.764   \n",
              "lp[2]               192.125  138.902     0.000   409.759      5.159    2.983   \n",
              "lp[3]               387.998  140.696   126.688   671.645      5.504    3.784   \n",
              "lp[4]               503.564  138.952   247.932   789.307      5.646    4.691   \n",
              "lp[5]               473.315  136.975   199.674   707.571      5.615    7.743   \n",
              "b0                  100.009    9.698    81.193   116.986      0.161    0.165   \n",
              "b_pop_density         0.078    1.019    -1.770     2.067      0.020    0.020   \n",
              "b_hdi                 0.078    1.017    -1.742     2.064      0.026    0.018   \n",
              "b_urban               0.047    1.012    -1.868     1.936      0.026    0.019   \n",
              "vae[0]             1441.770  176.293  1115.489  1775.341      4.119    3.507   \n",
              "vae[1]              215.863   85.030    59.429   394.699      2.927    3.411   \n",
              "vae[2]               64.080  118.122  -169.982   274.205      4.470    5.392   \n",
              "vae[3]              275.801   95.613    59.828   437.551      3.033    3.480   \n",
              "vae[4]              392.359  106.807   190.780   604.434      3.314    3.909   \n",
              "vae[5]              362.974  103.774   196.551   567.939      3.827    8.025   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    3172.0    1583.0   1.02  \n",
              "pred_cases_out[1]     649.0     628.0   1.00  \n",
              "pred_cases_out[2]     727.0     931.0   1.00  \n",
              "pred_cases_out[3]     662.0     761.0   1.01  \n",
              "pred_cases_out[4]     627.0     638.0   1.01  \n",
              "pred_cases_out[5]     729.0     568.0   1.00  \n",
              "lp[0]                3418.0    1817.0   1.01  \n",
              "lp[1]                 646.0     609.0   1.00  \n",
              "lp[2]                 691.0     970.0   1.01  \n",
              "lp[3]                 661.0     664.0   1.01  \n",
              "lp[4]                 630.0     633.0   1.01  \n",
              "lp[5]                 724.0     564.0   1.00  \n",
              "b0                   3614.0    2480.0   1.00  \n",
              "b_pop_density        2642.0    1937.0   1.00  \n",
              "b_hdi                1475.0    1932.0   1.00  \n",
              "b_urban              1594.0    2188.0   1.00  \n",
              "vae[0]               1866.0    1709.0   1.00  \n",
              "vae[1]               1017.0    1122.0   1.01  \n",
              "vae[2]                885.0     888.0   1.01  \n",
              "vae[3]               1189.0    1030.0   1.00  \n",
              "vae[4]               1203.0    1207.0   1.00  \n",
              "vae[5]               1251.0     794.0   1.01  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_1.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_1,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},)\n",
        "\n",
        "# %%\n",
        "print(mcmc_1.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 805\n",
            "Average ESS for all aggVAE-low effects : 819\n",
            "Max r_hat for all aggVAE-low : 1.0099999904632568\n",
            "Average ESS for all aggVAE-high effects : 802\n",
            "Max r_hat for all aggVAE-high : 1.0099999904632568\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_1.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 102.7880\n",
            "MAE as % of actual value (averaged over all observations): 29.04%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MCMC 2 (z = 40, n = 1000, target accept prob = 0.9, tree depth = 15) - year is 2023 (table 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    100.01      9.62    100.00     83.39    115.08   2589.66      1.00\n",
            "             b_hdi      0.03      1.00      0.04     -1.64      1.62   1361.65      1.00\n",
            "     b_pop_density      0.07      0.99      0.07     -1.72      1.53   2691.22      1.00\n",
            "           b_urban      0.04      1.01      0.04     -1.56      1.81   1177.84      1.00\n",
            "full_pred_cases[0]   1561.71      7.99   1561.94   1549.13   1574.72   1885.27      1.00\n",
            "full_pred_cases[1]    324.35    138.10    324.65     96.91    542.57    434.25      1.00\n",
            "full_pred_cases[2]    190.59    139.72    184.32    -14.21    376.21    492.93      1.01\n",
            "full_pred_cases[3]    385.45    142.98    387.88    148.58    606.22    443.60      1.00\n",
            "full_pred_cases[4]    499.71    141.24    502.05    274.02    713.02    415.69      1.00\n",
            "full_pred_cases[5]    465.99    133.54    455.03    248.61    653.35    447.20      1.00\n",
            "             sigma      4.94      2.95      4.36      0.71      9.16    117.93      1.04\n",
            "            sigma1     79.79     70.80     56.15      6.83    176.66    582.75      1.02\n",
            "              z[0]     -0.04      1.00     -0.03     -1.59      1.67   2930.63      1.00\n",
            "              z[1]     -0.08      1.01     -0.08     -1.74      1.53   2758.52      1.00\n",
            "              z[2]     -0.07      0.99     -0.04     -1.74      1.48   3063.65      1.00\n",
            "              z[3]      0.06      1.00      0.05     -1.55      1.66   2409.53      1.00\n",
            "              z[4]     -0.07      1.04     -0.08     -1.70      1.65   2376.13      1.00\n",
            "              z[5]      0.02      0.99      0.03     -1.58      1.60   2643.89      1.00\n",
            "              z[6]      0.03      1.01      0.06     -1.67      1.63   2760.70      1.00\n",
            "              z[7]     -0.10      1.01     -0.10     -1.72      1.56   2876.75      1.00\n",
            "              z[8]     -0.05      0.99     -0.05     -1.63      1.60   2785.55      1.00\n",
            "              z[9]      0.03      1.01      0.02     -1.56      1.73   3357.79      1.00\n",
            "             z[10]      0.05      1.00      0.03     -1.57      1.67   3123.63      1.00\n",
            "             z[11]     -0.12      0.98     -0.14     -1.80      1.43   2296.83      1.00\n",
            "             z[12]      0.08      1.03      0.09     -1.58      1.77   1931.05      1.00\n",
            "             z[13]      0.05      1.00      0.07     -1.66      1.58   2934.27      1.00\n",
            "             z[14]     -0.08      0.99     -0.06     -1.64      1.58   3101.99      1.00\n",
            "             z[15]     -0.10      1.01     -0.09     -1.77      1.56   3250.40      1.00\n",
            "             z[16]     -0.02      1.00     -0.01     -1.66      1.55   2672.39      1.00\n",
            "             z[17]      0.08      0.98      0.09     -1.50      1.74   3298.94      1.00\n",
            "             z[18]      0.04      1.00      0.03     -1.61      1.67   3253.82      1.00\n",
            "             z[19]      0.10      1.00      0.10     -1.49      1.84   3167.53      1.00\n",
            "             z[20]     -0.13      0.98     -0.16     -1.66      1.58   2110.65      1.00\n",
            "             z[21]      0.05      0.95      0.04     -1.50      1.67   2609.03      1.00\n",
            "             z[22]     -0.16      0.98     -0.20     -1.79      1.39   2497.19      1.00\n",
            "             z[23]     -0.05      1.00     -0.08     -1.62      1.68   3213.16      1.00\n",
            "             z[24]     -0.07      1.00     -0.10     -1.68      1.57   2643.41      1.00\n",
            "             z[25]     -0.09      0.98     -0.08     -1.75      1.45   2893.33      1.00\n",
            "             z[26]     -0.07      0.97     -0.06     -1.67      1.53   3102.03      1.00\n",
            "             z[27]     -0.08      1.04     -0.06     -1.83      1.56   2764.73      1.00\n",
            "             z[28]      0.06      0.96      0.04     -1.51      1.58   2503.82      1.00\n",
            "             z[29]      0.09      0.98      0.07     -1.52      1.67   2401.55      1.00\n",
            "             z[30]      0.04      1.00      0.05     -1.54      1.75   3351.98      1.00\n",
            "             z[31]      0.03      0.99      0.03     -1.56      1.69   3310.96      1.00\n",
            "             z[32]      0.08      0.99      0.08     -1.60      1.62   2750.36      1.00\n",
            "             z[33]      0.11      0.98      0.09     -1.59      1.69   2960.96      1.00\n",
            "             z[34]     -0.07      0.98     -0.08     -1.66      1.58   2623.12      1.00\n",
            "             z[35]      0.08      0.99      0.05     -1.48      1.77   2980.20      1.00\n",
            "             z[36]      0.06      0.99      0.06     -1.63      1.63   3577.39      1.00\n",
            "             z[37]     -0.12      0.96     -0.14     -1.53      1.58   2170.18      1.00\n",
            "             z[38]      0.06      1.01      0.05     -1.60      1.70   3055.04      1.00\n",
            "             z[39]      0.07      1.00      0.07     -1.51      1.80   2166.60      1.00\n",
            "\n",
            "Number of divergences: 906\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1561.707</td>\n",
              "      <td>7.994</td>\n",
              "      <td>1545.754</td>\n",
              "      <td>1577.814</td>\n",
              "      <td>0.183</td>\n",
              "      <td>0.380</td>\n",
              "      <td>2361.0</td>\n",
              "      <td>1179.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>324.347</td>\n",
              "      <td>138.098</td>\n",
              "      <td>63.302</td>\n",
              "      <td>598.177</td>\n",
              "      <td>6.533</td>\n",
              "      <td>5.281</td>\n",
              "      <td>469.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>190.594</td>\n",
              "      <td>139.721</td>\n",
              "      <td>-14.392</td>\n",
              "      <td>427.159</td>\n",
              "      <td>6.228</td>\n",
              "      <td>3.844</td>\n",
              "      <td>499.0</td>\n",
              "      <td>807.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>385.452</td>\n",
              "      <td>142.977</td>\n",
              "      <td>113.651</td>\n",
              "      <td>669.494</td>\n",
              "      <td>6.682</td>\n",
              "      <td>5.251</td>\n",
              "      <td>472.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>499.712</td>\n",
              "      <td>141.244</td>\n",
              "      <td>241.980</td>\n",
              "      <td>774.120</td>\n",
              "      <td>6.825</td>\n",
              "      <td>6.321</td>\n",
              "      <td>459.0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>465.991</td>\n",
              "      <td>133.540</td>\n",
              "      <td>233.173</td>\n",
              "      <td>717.134</td>\n",
              "      <td>6.234</td>\n",
              "      <td>8.161</td>\n",
              "      <td>548.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1561.815</td>\n",
              "      <td>5.672</td>\n",
              "      <td>1551.341</td>\n",
              "      <td>1573.258</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.231</td>\n",
              "      <td>3056.0</td>\n",
              "      <td>1691.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>324.399</td>\n",
              "      <td>138.147</td>\n",
              "      <td>0.000</td>\n",
              "      <td>533.418</td>\n",
              "      <td>6.542</td>\n",
              "      <td>5.282</td>\n",
              "      <td>466.0</td>\n",
              "      <td>569.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>190.769</td>\n",
              "      <td>139.514</td>\n",
              "      <td>0.000</td>\n",
              "      <td>421.212</td>\n",
              "      <td>6.215</td>\n",
              "      <td>3.846</td>\n",
              "      <td>487.0</td>\n",
              "      <td>713.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>385.324</td>\n",
              "      <td>142.915</td>\n",
              "      <td>114.318</td>\n",
              "      <td>670.423</td>\n",
              "      <td>6.683</td>\n",
              "      <td>5.228</td>\n",
              "      <td>469.0</td>\n",
              "      <td>617.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>499.639</td>\n",
              "      <td>141.171</td>\n",
              "      <td>238.386</td>\n",
              "      <td>772.516</td>\n",
              "      <td>6.822</td>\n",
              "      <td>6.335</td>\n",
              "      <td>459.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>465.956</td>\n",
              "      <td>133.516</td>\n",
              "      <td>226.307</td>\n",
              "      <td>709.730</td>\n",
              "      <td>6.229</td>\n",
              "      <td>8.154</td>\n",
              "      <td>549.0</td>\n",
              "      <td>564.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>100.014</td>\n",
              "      <td>9.619</td>\n",
              "      <td>81.868</td>\n",
              "      <td>117.972</td>\n",
              "      <td>0.187</td>\n",
              "      <td>0.181</td>\n",
              "      <td>2671.0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.072</td>\n",
              "      <td>0.992</td>\n",
              "      <td>-1.724</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.019</td>\n",
              "      <td>2703.0</td>\n",
              "      <td>2223.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.031</td>\n",
              "      <td>1.002</td>\n",
              "      <td>-1.840</td>\n",
              "      <td>1.870</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.017</td>\n",
              "      <td>1396.0</td>\n",
              "      <td>1946.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>0.044</td>\n",
              "      <td>1.009</td>\n",
              "      <td>-1.776</td>\n",
              "      <td>2.031</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.017</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1675.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1446.395</td>\n",
              "      <td>173.592</td>\n",
              "      <td>1122.464</td>\n",
              "      <td>1774.407</td>\n",
              "      <td>4.617</td>\n",
              "      <td>3.086</td>\n",
              "      <td>1419.0</td>\n",
              "      <td>1796.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>216.064</td>\n",
              "      <td>87.774</td>\n",
              "      <td>50.790</td>\n",
              "      <td>376.010</td>\n",
              "      <td>3.246</td>\n",
              "      <td>4.716</td>\n",
              "      <td>950.0</td>\n",
              "      <td>875.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>67.023</td>\n",
              "      <td>119.685</td>\n",
              "      <td>-165.932</td>\n",
              "      <td>250.387</td>\n",
              "      <td>4.657</td>\n",
              "      <td>7.537</td>\n",
              "      <td>842.0</td>\n",
              "      <td>871.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>277.170</td>\n",
              "      <td>98.798</td>\n",
              "      <td>82.751</td>\n",
              "      <td>442.118</td>\n",
              "      <td>3.356</td>\n",
              "      <td>5.044</td>\n",
              "      <td>1147.0</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>392.500</td>\n",
              "      <td>108.431</td>\n",
              "      <td>188.999</td>\n",
              "      <td>589.397</td>\n",
              "      <td>3.588</td>\n",
              "      <td>5.039</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>1053.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>359.630</td>\n",
              "      <td>96.798</td>\n",
              "      <td>200.295</td>\n",
              "      <td>539.712</td>\n",
              "      <td>3.460</td>\n",
              "      <td>6.751</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1561.707    7.994  1545.754  1577.814      0.183    0.380   \n",
              "pred_cases_out[1]   324.347  138.098    63.302   598.177      6.533    5.281   \n",
              "pred_cases_out[2]   190.594  139.721   -14.392   427.159      6.228    3.844   \n",
              "pred_cases_out[3]   385.452  142.977   113.651   669.494      6.682    5.251   \n",
              "pred_cases_out[4]   499.712  141.244   241.980   774.120      6.825    6.321   \n",
              "pred_cases_out[5]   465.991  133.540   233.173   717.134      6.234    8.161   \n",
              "lp[0]              1561.815    5.672  1551.341  1573.258      0.110    0.231   \n",
              "lp[1]               324.399  138.147     0.000   533.418      6.542    5.282   \n",
              "lp[2]               190.769  139.514     0.000   421.212      6.215    3.846   \n",
              "lp[3]               385.324  142.915   114.318   670.423      6.683    5.228   \n",
              "lp[4]               499.639  141.171   238.386   772.516      6.822    6.335   \n",
              "lp[5]               465.956  133.516   226.307   709.730      6.229    8.154   \n",
              "b0                  100.014    9.619    81.868   117.972      0.187    0.181   \n",
              "b_pop_density         0.072    0.992    -1.724     2.044      0.019    0.019   \n",
              "b_hdi                 0.031    1.002    -1.840     1.870      0.027    0.017   \n",
              "b_urban               0.044    1.009    -1.776     2.031      0.029    0.017   \n",
              "vae[0]             1446.395  173.592  1122.464  1774.407      4.617    3.086   \n",
              "vae[1]              216.064   87.774    50.790   376.010      3.246    4.716   \n",
              "vae[2]               67.023  119.685  -165.932   250.387      4.657    7.537   \n",
              "vae[3]              277.170   98.798    82.751   442.118      3.356    5.044   \n",
              "vae[4]              392.500  108.431   188.999   589.397      3.588    5.039   \n",
              "vae[5]              359.630   96.798   200.295   539.712      3.460    6.751   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    2361.0    1179.0   1.02  \n",
              "pred_cases_out[1]     469.0     580.0   1.00  \n",
              "pred_cases_out[2]     499.0     807.0   1.01  \n",
              "pred_cases_out[3]     472.0     610.0   1.00  \n",
              "pred_cases_out[4]     459.0     529.0   1.00  \n",
              "pred_cases_out[5]     548.0     558.0   1.00  \n",
              "lp[0]                3056.0    1691.0   1.02  \n",
              "lp[1]                 466.0     569.0   1.00  \n",
              "lp[2]                 487.0     713.0   1.01  \n",
              "lp[3]                 469.0     617.0   1.00  \n",
              "lp[4]                 459.0     555.0   1.00  \n",
              "lp[5]                 549.0     564.0   1.00  \n",
              "b0                   2671.0    2003.0   1.00  \n",
              "b_pop_density        2703.0    2223.0   1.00  \n",
              "b_hdi                1396.0    1946.0   1.00  \n",
              "b_urban              1200.0    1675.0   1.00  \n",
              "vae[0]               1419.0    1796.0   1.00  \n",
              "vae[1]                950.0     875.0   1.01  \n",
              "vae[2]                842.0     871.0   1.01  \n",
              "vae[3]               1147.0    1050.0   1.01  \n",
              "vae[4]               1180.0    1053.0   1.00  \n",
              "vae[5]               1207.0     920.0   1.00  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_2.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_2,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        "    )\n",
        "\n",
        "# %%\n",
        "print(mcmc_2.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 1117\n",
            "Average ESS for all aggVAE-low effects : 1121\n",
            "Max r_hat for all aggVAE-low : 1.0099999904632568\n",
            "Average ESS for all aggVAE-high effects : 1117\n",
            "Max r_hat for all aggVAE-high : 1.0099999904632568\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_2.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 99.3886\n",
            "MAE as % of actual value (averaged over all observations): 28.17%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MCMC 3 (z = 40, n = 1000, target accept prob = 0.95, tree depth = 15) - year is 2023 - BEST! (tables 7 and 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     94.14     13.29     95.49     76.55    111.39      3.10      1.61\n",
            "             b_hdi      0.00      0.87     -0.00     -1.51      1.47   1980.44      1.00\n",
            "     b_pop_density      0.66      1.41      0.50     -1.15      2.53      3.09      1.63\n",
            "           b_urban     -0.11      0.88     -0.40     -1.55      1.38     35.33      1.05\n",
            "full_pred_cases[0]   1561.76      6.10   1560.95   1552.70   1571.04   2266.47      1.00\n",
            "full_pred_cases[1]    284.49    133.42    253.29    125.91    534.28     10.63      1.14\n",
            "full_pred_cases[2]    151.54    127.42     94.80    -11.04    335.73     18.67      1.09\n",
            "full_pred_cases[3]    341.46    139.18    315.28    174.94    599.55     11.18      1.13\n",
            "full_pred_cases[4]    452.43    145.50    437.44    294.28    703.99      8.05      1.18\n",
            "full_pred_cases[5]    428.04    142.87    413.72    279.87    656.04      6.48      1.22\n",
            "             sigma      3.21      2.92      2.55      0.29      7.45      5.88      1.26\n",
            "            sigma1     81.52     75.08     45.89     10.30    188.53     14.90      1.08\n",
            "              z[0]      0.06      0.88      0.32     -1.62      1.38    194.12      1.02\n",
            "              z[1]      0.22      0.96      0.39     -1.47      1.48      7.62      1.15\n",
            "              z[2]     -0.27      0.95     -0.47     -1.42      1.65     11.68      1.10\n",
            "              z[3]      0.07      0.86      0.07     -1.38      1.56   3994.40      1.00\n",
            "              z[4]      0.04      0.91      0.35     -1.60      1.44     74.29      1.02\n",
            "              z[5]      0.04      0.85      0.02     -1.34      1.63   4102.87      1.00\n",
            "              z[6]      0.05      0.88      0.01     -1.41      1.61   3643.49      1.00\n",
            "              z[7]     -0.08      0.86     -0.19     -1.41      1.49   2514.44      1.00\n",
            "              z[8]      0.08      0.91      0.36     -1.52      1.58     30.21      1.04\n",
            "              z[9]      0.10      0.91      0.44     -1.58      1.47     51.10      1.03\n",
            "             z[10]      0.58      1.23      0.52     -1.16      2.09      3.55      1.47\n",
            "             z[11]      0.14      0.93      0.35     -1.45      1.49     12.26      1.09\n",
            "             z[12]      0.13      0.89      0.44     -1.58      1.36     63.01      1.03\n",
            "             z[13]      0.34      1.01      0.45     -1.44      1.49      6.32      1.19\n",
            "             z[14]      0.32      1.10      0.36     -1.52      1.50      4.57      1.31\n",
            "             z[15]      0.26      1.04      0.37     -1.52      1.41      5.26      1.25\n",
            "             z[16]      0.19      0.93      0.40     -1.44      1.43      9.32      1.12\n",
            "             z[17]      0.13      0.89      0.44     -1.49      1.50     73.74      1.02\n",
            "             z[18]      0.65      1.36      0.52     -1.15      2.45      3.12      1.61\n",
            "             z[19]      0.30      0.95      0.52     -1.35      1.60     11.13      1.10\n",
            "             z[20]     -0.19      0.87     -0.44     -1.57      1.35    290.24      1.02\n",
            "             z[21]      0.02      0.86     -0.00     -1.35      1.62   3158.71      1.00\n",
            "             z[22]     -0.41      0.98     -0.53     -1.64      1.30      6.76      1.18\n",
            "             z[23]      0.00      0.87      0.24     -1.60      1.44    191.48      1.01\n",
            "             z[24]     -0.11      0.89     -0.31     -1.47      1.58   2706.70      1.01\n",
            "             z[25]     -0.45      1.07     -0.45     -1.62      1.30      4.49      1.32\n",
            "             z[26]     -0.08      0.90     -0.18     -1.61      1.45   3589.13      1.00\n",
            "             z[27]     -0.16      0.91     -0.47     -1.57      1.48    134.81      1.02\n",
            "             z[28]     -0.53      1.33     -0.35     -2.31      1.18      3.06      1.65\n",
            "             z[29]     -0.22      0.97     -0.34     -1.24      1.66      6.64      1.18\n",
            "             z[30]      0.20      0.88      0.50     -1.43      1.55     32.06      1.04\n",
            "             z[31]     -0.00      0.86     -0.11     -1.59      1.37   2576.68      1.00\n",
            "             z[32]      0.23      0.92      0.49     -1.43      1.61     20.54      1.06\n",
            "             z[33]     -0.04      0.85     -0.31     -1.42      1.41    102.91      1.02\n",
            "             z[34]      0.06      0.89      0.35     -1.67      1.35     40.29      1.04\n",
            "             z[35]     -0.06      0.88     -0.33     -1.41      1.53     31.09      1.04\n",
            "             z[36]     -0.11      0.91     -0.40     -1.50      1.54     27.18      1.05\n",
            "             z[37]     -0.07      0.85     -0.14     -1.39      1.51   4639.75      1.00\n",
            "             z[38]      0.10      0.86      0.15     -1.29      1.67   3335.51      1.00\n",
            "             z[39]      0.09      0.88      0.17     -1.36      1.70   3716.38      1.00\n",
            "\n",
            "Number of divergences: 386\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1561.765</td>\n",
              "      <td>6.104</td>\n",
              "      <td>1550.237</td>\n",
              "      <td>1573.990</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.356</td>\n",
              "      <td>2996.0</td>\n",
              "      <td>1242.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>284.492</td>\n",
              "      <td>133.424</td>\n",
              "      <td>75.087</td>\n",
              "      <td>570.267</td>\n",
              "      <td>28.542</td>\n",
              "      <td>5.132</td>\n",
              "      <td>26.0</td>\n",
              "      <td>993.0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>151.536</td>\n",
              "      <td>127.425</td>\n",
              "      <td>-11.503</td>\n",
              "      <td>383.134</td>\n",
              "      <td>21.008</td>\n",
              "      <td>9.817</td>\n",
              "      <td>106.0</td>\n",
              "      <td>878.0</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>341.463</td>\n",
              "      <td>139.184</td>\n",
              "      <td>129.350</td>\n",
              "      <td>640.734</td>\n",
              "      <td>28.889</td>\n",
              "      <td>3.612</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1128.0</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>452.432</td>\n",
              "      <td>145.505</td>\n",
              "      <td>245.374</td>\n",
              "      <td>742.620</td>\n",
              "      <td>35.284</td>\n",
              "      <td>4.028</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1157.0</td>\n",
              "      <td>1.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>428.042</td>\n",
              "      <td>142.873</td>\n",
              "      <td>241.529</td>\n",
              "      <td>706.711</td>\n",
              "      <td>38.669</td>\n",
              "      <td>5.783</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1162.0</td>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1562.032</td>\n",
              "      <td>4.265</td>\n",
              "      <td>1553.375</td>\n",
              "      <td>1570.435</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.353</td>\n",
              "      <td>3607.0</td>\n",
              "      <td>1407.0</td>\n",
              "      <td>1.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>284.662</td>\n",
              "      <td>133.259</td>\n",
              "      <td>82.326</td>\n",
              "      <td>575.608</td>\n",
              "      <td>28.448</td>\n",
              "      <td>4.585</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>151.414</td>\n",
              "      <td>127.360</td>\n",
              "      <td>0.000</td>\n",
              "      <td>382.323</td>\n",
              "      <td>20.962</td>\n",
              "      <td>9.896</td>\n",
              "      <td>82.0</td>\n",
              "      <td>899.0</td>\n",
              "      <td>1.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>341.496</td>\n",
              "      <td>139.178</td>\n",
              "      <td>131.648</td>\n",
              "      <td>640.956</td>\n",
              "      <td>28.804</td>\n",
              "      <td>3.626</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1171.0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>452.443</td>\n",
              "      <td>145.292</td>\n",
              "      <td>244.853</td>\n",
              "      <td>742.954</td>\n",
              "      <td>35.106</td>\n",
              "      <td>4.024</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1131.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>427.910</td>\n",
              "      <td>143.055</td>\n",
              "      <td>239.391</td>\n",
              "      <td>706.226</td>\n",
              "      <td>38.765</td>\n",
              "      <td>5.802</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>94.145</td>\n",
              "      <td>13.288</td>\n",
              "      <td>76.547</td>\n",
              "      <td>114.478</td>\n",
              "      <td>5.164</td>\n",
              "      <td>1.408</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.661</td>\n",
              "      <td>1.405</td>\n",
              "      <td>-1.488</td>\n",
              "      <td>2.530</td>\n",
              "      <td>0.547</td>\n",
              "      <td>0.156</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2265.0</td>\n",
              "      <td>1.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.869</td>\n",
              "      <td>-1.624</td>\n",
              "      <td>1.839</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.116</td>\n",
              "      <td>1876.0</td>\n",
              "      <td>1431.0</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-0.110</td>\n",
              "      <td>0.878</td>\n",
              "      <td>-1.768</td>\n",
              "      <td>1.645</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.094</td>\n",
              "      <td>92.0</td>\n",
              "      <td>1744.0</td>\n",
              "      <td>1.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1398.013</td>\n",
              "      <td>182.654</td>\n",
              "      <td>1169.783</td>\n",
              "      <td>1780.640</td>\n",
              "      <td>50.322</td>\n",
              "      <td>2.833</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1898.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>199.240</td>\n",
              "      <td>91.366</td>\n",
              "      <td>40.479</td>\n",
              "      <td>395.295</td>\n",
              "      <td>9.769</td>\n",
              "      <td>6.180</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1273.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>50.837</td>\n",
              "      <td>119.806</td>\n",
              "      <td>-189.227</td>\n",
              "      <td>262.677</td>\n",
              "      <td>3.515</td>\n",
              "      <td>11.396</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>256.626</td>\n",
              "      <td>101.713</td>\n",
              "      <td>46.447</td>\n",
              "      <td>439.841</td>\n",
              "      <td>9.116</td>\n",
              "      <td>8.379</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1299.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>367.918</td>\n",
              "      <td>115.317</td>\n",
              "      <td>172.433</td>\n",
              "      <td>606.541</td>\n",
              "      <td>17.480</td>\n",
              "      <td>4.692</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1305.0</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>342.962</td>\n",
              "      <td>109.916</td>\n",
              "      <td>196.160</td>\n",
              "      <td>564.076</td>\n",
              "      <td>22.267</td>\n",
              "      <td>6.014</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>1.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1561.765    6.104  1550.237  1573.990      0.128    0.356   \n",
              "pred_cases_out[1]   284.492  133.424    75.087   570.267     28.542    5.132   \n",
              "pred_cases_out[2]   151.536  127.425   -11.503   383.134     21.008    9.817   \n",
              "pred_cases_out[3]   341.463  139.184   129.350   640.734     28.889    3.612   \n",
              "pred_cases_out[4]   452.432  145.505   245.374   742.620     35.284    4.028   \n",
              "pred_cases_out[5]   428.042  142.873   241.529   706.711     38.669    5.783   \n",
              "lp[0]              1562.032    4.265  1553.375  1570.435      0.078    0.353   \n",
              "lp[1]               284.662  133.259    82.326   575.608     28.448    4.585   \n",
              "lp[2]               151.414  127.360     0.000   382.323     20.962    9.896   \n",
              "lp[3]               341.496  139.178   131.648   640.956     28.804    3.626   \n",
              "lp[4]               452.443  145.292   244.853   742.954     35.106    4.024   \n",
              "lp[5]               427.910  143.055   239.391   706.226     38.765    5.802   \n",
              "b0                   94.145   13.288    76.547   114.478      5.164    1.408   \n",
              "b_pop_density         0.661    1.405    -1.488     2.530      0.547    0.156   \n",
              "b_hdi                 0.001    0.869    -1.624     1.839      0.019    0.116   \n",
              "b_urban              -0.110    0.878    -1.768     1.645      0.107    0.094   \n",
              "vae[0]             1398.013  182.654  1169.783  1780.640     50.322    2.833   \n",
              "vae[1]              199.240   91.366    40.479   395.295      9.769    6.180   \n",
              "vae[2]               50.837  119.806  -189.227   262.677      3.515   11.396   \n",
              "vae[3]              256.626  101.713    46.447   439.841      9.116    8.379   \n",
              "vae[4]              367.918  115.317   172.433   606.541     17.480    4.692   \n",
              "vae[5]              342.962  109.916   196.160   564.076     22.267    6.014   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    2996.0    1242.0   1.53  \n",
              "pred_cases_out[1]      26.0     993.0   1.12  \n",
              "pred_cases_out[2]     106.0     878.0   1.25  \n",
              "pred_cases_out[3]      28.0    1128.0   1.11  \n",
              "pred_cases_out[4]      18.0    1157.0   1.17  \n",
              "pred_cases_out[5]      13.0    1162.0   1.23  \n",
              "lp[0]                3607.0    1407.0   1.51  \n",
              "lp[1]                  24.0    1000.0   1.13  \n",
              "lp[2]                  82.0     899.0   1.27  \n",
              "lp[3]                  25.0    1171.0   1.12  \n",
              "lp[4]                  17.0    1131.0   1.18  \n",
              "lp[5]                  12.0    1169.0   1.25  \n",
              "b0                      8.0       4.0   1.44  \n",
              "b_pop_density           8.0    2265.0   1.45  \n",
              "b_hdi                1876.0    1431.0   1.54  \n",
              "b_urban                92.0    1744.0   1.21  \n",
              "vae[0]                 15.0    1898.0   1.18  \n",
              "vae[1]                 36.0    1273.0   1.08  \n",
              "vae[2]               1077.0    1326.0   1.54  \n",
              "vae[3]                 43.0    1299.0   1.07  \n",
              "vae[4]                 28.0    1305.0   1.10  \n",
              "vae[5]                 16.0    1270.0   1.17  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_3.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_3,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        "    )\n",
        "\n",
        "# %%\n",
        "print(mcmc_3.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 1260\n",
            "Average ESS for all aggVAE-low effects : 1173\n",
            "Max r_hat for all aggVAE-low : 1.0099999904632568\n",
            "Average ESS for all aggVAE-high effects : 1278\n",
            "Max r_hat for all aggVAE-high : 1.0\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_3.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### error metrics for table 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 82.1362\n",
            "MAE as % of actual value (averaged over all observations): 20.26%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#this is the best parameters, so we download the predictions to be used\n",
        "#df_hi.to_csv(\"../data/processed/df_hi_jkt_2023_aggVAE_preds.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MCMC 4 (z = 30, n = 1000 Inference, target accept prob = 0.8, tree depth 10 (default) - bc alr converged, so using default MCMC settings is ok) - 2023, batch size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "args[\"z_dim\"] = 30\n",
        "#open saved encoder\n",
        "with open(\"../model weights/aggVAE/aggVAE_e50_h50_z30_batch5.pkl\", \"rb\") as file:\n",
        "    vae_params = pickle.load(file)\n",
        "\n",
        "encoder_params = vae_params[\"encoder$params\"]\n",
        "decoder_params = vae_params[\"decoder$params\"]\n",
        "\n",
        "# save decoder params inside args\n",
        "args[\"decoder_params\"] = decoder_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    100.24      9.90    100.09     83.21    115.97    750.00      1.00\n",
            "             b_hdi      0.12      1.00      0.14     -1.66      1.63    286.63      1.01\n",
            "     b_pop_density      0.07      1.01      0.07     -1.53      1.71    390.24      1.00\n",
            "           b_urban      0.11      1.02      0.14     -1.59      1.72    261.76      1.01\n",
            "full_pred_cases[0]   1561.61      8.55   1562.05   1548.64   1575.12    528.91      1.01\n",
            "full_pred_cases[1]    401.71    111.46    401.85    221.37    586.26    153.74      1.01\n",
            "full_pred_cases[2]    281.03    121.40    281.80     94.96    492.20    158.71      1.01\n",
            "full_pred_cases[3]    452.69    111.12    453.59    274.88    638.40    152.26      1.01\n",
            "full_pred_cases[4]    559.50    101.98    560.76    400.04    737.20    151.75      1.01\n",
            "full_pred_cases[5]    522.66    101.76    522.32    360.77    696.49    157.25      1.01\n",
            "             sigma      5.68      2.73      5.20      1.56      9.59    277.75      1.02\n",
            "            sigma1    138.06     70.06    121.29     40.02    238.57    486.15      1.00\n",
            "              z[0]     -0.10      0.99     -0.12     -1.68      1.63    785.52      1.01\n",
            "              z[1]     -0.07      0.98     -0.07     -1.63      1.54    784.87      1.00\n",
            "              z[2]     -0.18      1.03     -0.20     -1.80      1.54    618.12      1.00\n",
            "              z[3]      0.16      1.01      0.17     -1.51      1.74    571.14      1.01\n",
            "              z[4]      0.15      0.99      0.15     -1.65      1.58    786.28      1.01\n",
            "              z[5]      0.13      0.95      0.10     -1.43      1.70    732.41      1.00\n",
            "              z[6]     -0.16      1.01     -0.16     -1.86      1.42    547.25      1.01\n",
            "              z[7]     -0.19      1.02     -0.20     -1.81      1.51    776.62      1.00\n",
            "              z[8]     -0.05      0.96     -0.05     -1.60      1.51    786.17      1.01\n",
            "              z[9]      0.18      1.01      0.16     -1.31      1.95    589.04      1.00\n",
            "             z[10]      0.14      1.00      0.15     -1.60      1.62    711.70      1.00\n",
            "             z[11]     -0.06      0.99     -0.05     -1.55      1.61    661.83      1.01\n",
            "             z[12]      0.21      0.95      0.24     -1.33      1.77    580.35      1.00\n",
            "             z[13]      0.12      0.97      0.14     -1.58      1.63    702.12      1.00\n",
            "             z[14]     -0.15      0.97     -0.16     -1.71      1.40    759.85      1.00\n",
            "             z[15]     -0.18      1.00     -0.17     -1.67      1.62    552.52      1.01\n",
            "             z[16]     -0.15      1.03     -0.12     -1.95      1.49    781.16      1.00\n",
            "             z[17]      0.05      1.05      0.05     -1.51      1.94    655.57      1.01\n",
            "             z[18]     -0.01      0.99      0.01     -1.66      1.53    653.52      1.01\n",
            "             z[19]      0.18      0.99      0.16     -1.57      1.70    801.18      1.00\n",
            "             z[20]     -0.13      0.97     -0.14     -1.70      1.47    804.86      1.00\n",
            "             z[21]     -0.11      0.92     -0.13     -1.65      1.43    807.26      1.01\n",
            "             z[22]     -0.05      0.98     -0.07     -1.61      1.63    998.18      1.00\n",
            "             z[23]      0.21      1.03      0.18     -1.32      2.01    452.11      1.01\n",
            "             z[24]     -0.09      1.00     -0.09     -1.69      1.50    815.28      1.00\n",
            "             z[25]     -0.06      0.98     -0.06     -1.72      1.44    643.53      1.01\n",
            "             z[26]     -0.06      0.98     -0.08     -1.56      1.60    770.36      1.01\n",
            "             z[27]     -0.14      0.98     -0.11     -1.69      1.51    793.74      1.00\n",
            "             z[28]      0.14      0.96      0.15     -1.49      1.72    849.40      1.00\n",
            "             z[29]      0.05      1.01      0.06     -1.49      1.78    597.51      1.01\n",
            "\n",
            "Number of divergences: 785\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1561.608</td>\n",
              "      <td>8.548</td>\n",
              "      <td>1544.568</td>\n",
              "      <td>1577.866</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.374</td>\n",
              "      <td>598.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>401.708</td>\n",
              "      <td>111.463</td>\n",
              "      <td>192.986</td>\n",
              "      <td>604.072</td>\n",
              "      <td>8.790</td>\n",
              "      <td>4.509</td>\n",
              "      <td>162.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>281.028</td>\n",
              "      <td>121.398</td>\n",
              "      <td>57.448</td>\n",
              "      <td>507.012</td>\n",
              "      <td>9.375</td>\n",
              "      <td>4.537</td>\n",
              "      <td>167.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>452.687</td>\n",
              "      <td>111.125</td>\n",
              "      <td>258.690</td>\n",
              "      <td>666.797</td>\n",
              "      <td>8.801</td>\n",
              "      <td>4.500</td>\n",
              "      <td>160.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>559.500</td>\n",
              "      <td>101.984</td>\n",
              "      <td>371.597</td>\n",
              "      <td>747.594</td>\n",
              "      <td>8.109</td>\n",
              "      <td>4.072</td>\n",
              "      <td>160.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>522.660</td>\n",
              "      <td>101.760</td>\n",
              "      <td>338.918</td>\n",
              "      <td>715.924</td>\n",
              "      <td>7.952</td>\n",
              "      <td>4.137</td>\n",
              "      <td>164.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1561.816</td>\n",
              "      <td>6.121</td>\n",
              "      <td>1550.059</td>\n",
              "      <td>1573.676</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.198</td>\n",
              "      <td>1136.0</td>\n",
              "      <td>1144.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>401.773</td>\n",
              "      <td>111.323</td>\n",
              "      <td>192.326</td>\n",
              "      <td>601.550</td>\n",
              "      <td>8.783</td>\n",
              "      <td>4.514</td>\n",
              "      <td>162.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>280.964</td>\n",
              "      <td>121.179</td>\n",
              "      <td>58.716</td>\n",
              "      <td>508.813</td>\n",
              "      <td>9.366</td>\n",
              "      <td>4.536</td>\n",
              "      <td>168.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>452.630</td>\n",
              "      <td>110.831</td>\n",
              "      <td>256.236</td>\n",
              "      <td>663.117</td>\n",
              "      <td>8.780</td>\n",
              "      <td>4.476</td>\n",
              "      <td>161.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>559.357</td>\n",
              "      <td>101.889</td>\n",
              "      <td>367.209</td>\n",
              "      <td>743.183</td>\n",
              "      <td>8.114</td>\n",
              "      <td>4.094</td>\n",
              "      <td>159.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>522.705</td>\n",
              "      <td>101.578</td>\n",
              "      <td>339.450</td>\n",
              "      <td>718.005</td>\n",
              "      <td>7.948</td>\n",
              "      <td>4.154</td>\n",
              "      <td>163.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>100.243</td>\n",
              "      <td>9.897</td>\n",
              "      <td>81.623</td>\n",
              "      <td>118.522</td>\n",
              "      <td>0.360</td>\n",
              "      <td>0.255</td>\n",
              "      <td>769.0</td>\n",
              "      <td>1463.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.071</td>\n",
              "      <td>1.010</td>\n",
              "      <td>-1.595</td>\n",
              "      <td>2.100</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.023</td>\n",
              "      <td>409.0</td>\n",
              "      <td>856.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.122</td>\n",
              "      <td>0.995</td>\n",
              "      <td>-1.741</td>\n",
              "      <td>1.978</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.028</td>\n",
              "      <td>298.0</td>\n",
              "      <td>696.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>0.112</td>\n",
              "      <td>1.021</td>\n",
              "      <td>-1.771</td>\n",
              "      <td>1.983</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.025</td>\n",
              "      <td>279.0</td>\n",
              "      <td>693.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1432.389</td>\n",
              "      <td>172.688</td>\n",
              "      <td>1133.312</td>\n",
              "      <td>1767.303</td>\n",
              "      <td>8.327</td>\n",
              "      <td>4.047</td>\n",
              "      <td>431.0</td>\n",
              "      <td>939.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>280.696</td>\n",
              "      <td>43.569</td>\n",
              "      <td>205.614</td>\n",
              "      <td>360.602</td>\n",
              "      <td>1.793</td>\n",
              "      <td>1.837</td>\n",
              "      <td>606.0</td>\n",
              "      <td>894.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>158.961</td>\n",
              "      <td>35.223</td>\n",
              "      <td>99.428</td>\n",
              "      <td>223.643</td>\n",
              "      <td>1.420</td>\n",
              "      <td>1.854</td>\n",
              "      <td>663.0</td>\n",
              "      <td>885.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>330.956</td>\n",
              "      <td>46.555</td>\n",
              "      <td>248.255</td>\n",
              "      <td>413.448</td>\n",
              "      <td>1.943</td>\n",
              "      <td>1.607</td>\n",
              "      <td>580.0</td>\n",
              "      <td>892.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>438.389</td>\n",
              "      <td>58.532</td>\n",
              "      <td>331.271</td>\n",
              "      <td>539.791</td>\n",
              "      <td>2.463</td>\n",
              "      <td>1.780</td>\n",
              "      <td>568.0</td>\n",
              "      <td>970.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>402.999</td>\n",
              "      <td>62.536</td>\n",
              "      <td>295.294</td>\n",
              "      <td>518.080</td>\n",
              "      <td>2.504</td>\n",
              "      <td>2.453</td>\n",
              "      <td>638.0</td>\n",
              "      <td>1047.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1561.608    8.548  1544.568  1577.866      0.370    0.374   \n",
              "pred_cases_out[1]   401.708  111.463   192.986   604.072      8.790    4.509   \n",
              "pred_cases_out[2]   281.028  121.398    57.448   507.012      9.375    4.537   \n",
              "pred_cases_out[3]   452.687  111.125   258.690   666.797      8.801    4.500   \n",
              "pred_cases_out[4]   559.500  101.984   371.597   747.594      8.109    4.072   \n",
              "pred_cases_out[5]   522.660  101.760   338.918   715.924      7.952    4.137   \n",
              "lp[0]              1561.816    6.121  1550.059  1573.676      0.190    0.198   \n",
              "lp[1]               401.773  111.323   192.326   601.550      8.783    4.514   \n",
              "lp[2]               280.964  121.179    58.716   508.813      9.366    4.536   \n",
              "lp[3]               452.630  110.831   256.236   663.117      8.780    4.476   \n",
              "lp[4]               559.357  101.889   367.209   743.183      8.114    4.094   \n",
              "lp[5]               522.705  101.578   339.450   718.005      7.948    4.154   \n",
              "b0                  100.243    9.897    81.623   118.522      0.360    0.255   \n",
              "b_pop_density         0.071    1.010    -1.595     2.100      0.050    0.023   \n",
              "b_hdi                 0.122    0.995    -1.741     1.978      0.057    0.028   \n",
              "b_urban               0.112    1.021    -1.771     1.983      0.061    0.025   \n",
              "vae[0]             1432.389  172.688  1133.312  1767.303      8.327    4.047   \n",
              "vae[1]              280.696   43.569   205.614   360.602      1.793    1.837   \n",
              "vae[2]              158.961   35.223    99.428   223.643      1.420    1.854   \n",
              "vae[3]              330.956   46.555   248.255   413.448      1.943    1.607   \n",
              "vae[4]              438.389   58.532   331.271   539.791      2.463    1.780   \n",
              "vae[5]              402.999   62.536   295.294   518.080      2.504    2.453   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]     598.0     575.0   1.01  \n",
              "pred_cases_out[1]     162.0     287.0   1.01  \n",
              "pred_cases_out[2]     167.0     297.0   1.01  \n",
              "pred_cases_out[3]     160.0     260.0   1.01  \n",
              "pred_cases_out[4]     160.0     271.0   1.01  \n",
              "pred_cases_out[5]     164.0     276.0   1.01  \n",
              "lp[0]                1136.0    1144.0   1.01  \n",
              "lp[1]                 162.0     278.0   1.01  \n",
              "lp[2]                 168.0     304.0   1.01  \n",
              "lp[3]                 161.0     268.0   1.01  \n",
              "lp[4]                 159.0     274.0   1.01  \n",
              "lp[5]                 163.0     262.0   1.01  \n",
              "b0                    769.0    1463.0   1.00  \n",
              "b_pop_density         409.0     856.0   1.01  \n",
              "b_hdi                 298.0     696.0   1.01  \n",
              "b_urban               279.0     693.0   1.01  \n",
              "vae[0]                431.0     939.0   1.00  \n",
              "vae[1]                606.0     894.0   1.00  \n",
              "vae[2]                663.0     885.0   1.00  \n",
              "vae[3]                580.0     892.0   1.00  \n",
              "vae[4]                568.0     970.0   1.00  \n",
              "vae[5]                638.0    1047.0   1.00  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating  posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_4.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "\n",
        "# transform posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_4,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},)\n",
        "\n",
        "# %%\n",
        "print(mcmc_4.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 472\n",
            "Average ESS for all aggVAE-low effects : 476\n",
            "Max r_hat for all aggVAE-low : 1.0\n",
            "Average ESS for all aggVAE-high effects : 472\n",
            "Max r_hat for all aggVAE-high : 1.0\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_4.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error metrics for table 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 149.9626\n",
            "MAE as % of actual value (averaged over all observations): 51.72%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine the best target_accept_prob on the 2022 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "args[\"z_dim\"] = 40\n",
        "#open saved encoder\n",
        "with open(\"../model weights/aggVAE/aggVAE_e29_h50_z40_batch5.pkl\", \"rb\") as file:\n",
        "    vae_params = pickle.load(file)\n",
        "\n",
        "encoder_params = vae_params[\"encoder$params\"]\n",
        "decoder_params = vae_params[\"decoder$params\"]\n",
        "\n",
        "# save decoder params inside args\n",
        "args[\"decoder_params\"] = decoder_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load the mcmc data u want\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2022_53min_z40_prob0.95_treedepth15.pkl\", \"rb\") as f_1:\n",
        "    mcmc_1 = pickle.load(f_1)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2022_567min_z40_prob0.9_treedepth18.pkl\", \"rb\") as f_2:\n",
        "    mcmc_2 = pickle.load(f_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 'pol_pts_lo', 'pol_pts_hi', 'df_lo', 'df_hi'])\n",
            "Dengue incidence by province and year (low resolution):\n",
            "                  incidence\n",
            "Province    Year           \n",
            "DKI Jakarta 2020   0.001519\n",
            "            2021   0.001315\n",
            "            2022   0.002667\n",
            "            2023   0.001983 \n",
            "\n",
            "We are using data for the year 2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "spatial_data = load_data()\n",
        "print(spatial_data.keys())\n",
        "\n",
        "# Lets lok at the data and dissect it\n",
        "lo_prev = spatial_data[\"df_lo\"].copy()\n",
        "lo_prev['incidence'] = (lo_prev.Cases / lo_prev.Population)\n",
        "print(\"Dengue incidence by province and year (low resolution):\")\n",
        "print(lo_prev.groupby(['Province', 'Year'])[['incidence']].mean(), '\\n')\n",
        "\n",
        "# make sure we use only one year of data (change manually)\n",
        "year_data = 2022\n",
        "print(f'We are using data for the year {year_data}\\n')\n",
        "\n",
        "# let us filter the data for the years 2023, 2022, 2021, 2020 (must change the input manually for year_data)\n",
        "df_lo = spatial_data[\"df_lo\"][spatial_data[\"df_lo\"].Year == year_data]\n",
        "df_hi = spatial_data[\"df_hi\"][spatial_data[\"df_hi\"].Year == year_data]\n",
        "\n",
        "df_lo = df_lo.copy()\n",
        "df_hi = df_hi.copy()\n",
        "df_lo.loc[:, 'incidence'] = df_lo.Cases / df_lo.Population\n",
        "df_hi.loc[:, 'incidence'] = df_hi.Cases / df_hi.Population\n",
        "\n",
        "total_population = jnp.concatenate([df_lo.Population.values, df_hi.Population.values])\n",
        "count = jnp.concatenate([df_lo.Cases.values, jnp.full((df_hi.shape[0],), jnp.nan)])\n",
        "hdi_index = jnp.concatenate([df_lo.HDI.values, df_hi.HDI.values])*100\n",
        "pop_density = jnp.concatenate([df_lo.Pop_den.values*1e2, (df_hi.Pop_den.values)*1e-1])\n",
        "urban_frac = jnp.concatenate([df_lo.urbanicity.values, df_hi.urbanicity.values])*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.95, tree depth 15 (Rhat, ESS for table 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_1.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_1,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     98.70      9.10     95.92     85.42    115.10    101.36      1.06\n",
            "             b_hdi     -0.06      0.83     -0.21     -1.42      1.40    423.72      1.01\n",
            "     b_pop_density     -0.23      0.93     -0.50     -1.54      1.49     30.74      1.08\n",
            "           b_urban     -0.28      0.90     -0.30     -1.81      1.27     14.38      1.12\n",
            "full_pred_cases[0]   2113.63      5.33   2113.14   2106.00   2121.56   2098.48      1.01\n",
            "full_pred_cases[1]    363.45    110.97    326.26    209.73    565.51     25.04      1.08\n",
            "full_pred_cases[2]    154.32    131.36    118.38    -11.91    358.94      7.35      1.20\n",
            "full_pred_cases[3]    447.92    118.24    412.70    302.16    671.71     22.84      1.08\n",
            "full_pred_cases[4]    611.77    112.95    577.29    491.76    838.63     42.76      1.06\n",
            "full_pred_cases[5]    575.38    103.02    597.69    416.80    730.94     24.27      1.08\n",
            "             sigma      3.14      2.89      2.49      0.14      7.22      4.72      1.33\n",
            "            sigma1    128.75     81.09    111.13     20.84    212.87      4.96      1.29\n",
            "              z[0]     -0.20      0.98     -0.49     -1.56      1.65     32.10      1.07\n",
            "              z[1]      0.03      0.82      0.25     -1.40      1.35    559.78      1.02\n",
            "              z[2]     -0.46      1.23     -0.38     -2.01      1.29      3.39      1.58\n",
            "              z[3]      0.23      0.99      0.41     -1.54      1.40      7.61      1.18\n",
            "              z[4]     -0.22      1.03     -0.43     -1.59      1.60      8.24      1.16\n",
            "              z[5]     -0.08      0.82     -0.34     -1.31      1.39     36.96      1.07\n",
            "              z[6]      0.01      0.81      0.00     -1.39      1.30    364.88      1.01\n",
            "              z[7]      0.24      1.06      0.35     -1.58      1.45      5.91      1.25\n",
            "              z[8]      0.09      0.92      0.27     -1.65      1.15     11.06      1.12\n",
            "              z[9]      0.39      1.00      0.54     -1.36      1.41      5.86      1.26\n",
            "             z[10]     -0.24      0.94     -0.45     -1.51      1.54     13.96      1.11\n",
            "             z[11]     -0.19      0.80      0.01     -1.65      1.07     53.84      1.04\n",
            "             z[12]     -0.10      0.86     -0.35     -1.37      1.48     50.38      1.05\n",
            "             z[13]     -0.06      0.96     -0.28     -1.42      1.57     10.59      1.13\n",
            "             z[14]      0.00      0.86      0.11     -1.43      1.47    243.55      1.01\n",
            "             z[15]     -0.01      0.79      0.00     -1.48      1.35    102.01      1.02\n",
            "             z[16]     -0.02      0.88      0.00     -1.47      1.56    303.01      1.01\n",
            "             z[17]      0.50      1.30      0.35     -1.30      2.19      3.27      1.61\n",
            "             z[18]     -0.05      0.97     -0.34     -1.43      1.65     19.25      1.09\n",
            "             z[19]     -0.03      0.84      0.09     -1.50      1.29     59.46      1.04\n",
            "             z[20]     -0.22      0.87     -0.37     -1.57      1.38    270.93      1.01\n",
            "             z[21]     -0.11      0.86     -0.29     -1.36      1.41     13.00      1.09\n",
            "             z[22]     -0.16      0.87     -0.44     -1.55      1.30     19.17      1.08\n",
            "             z[23]     -0.30      0.96     -0.52     -1.64      1.40     16.48      1.14\n",
            "             z[24]      0.01      0.91      0.35     -1.66      1.41     88.19      1.03\n",
            "             z[25]      0.26      1.08      0.27     -1.37      1.45      4.51      1.36\n",
            "             z[26]     -0.23      0.92     -0.51     -1.72      1.37     68.97      1.04\n",
            "             z[27]     -0.46      1.07     -0.54     -1.59      1.34      5.01      1.30\n",
            "             z[28]     -0.26      1.02     -0.33     -1.35      1.42      4.75      1.31\n",
            "             z[29]      0.13      0.86     -0.09     -1.13      1.70     10.25      1.14\n",
            "             z[30]      0.04      0.81      0.04     -1.21      1.52    227.35      1.02\n",
            "             z[31]     -0.16      0.86     -0.38     -1.39      1.36     12.51      1.15\n",
            "             z[32]      0.04      0.87     -0.11     -1.27      1.68    169.43      1.01\n",
            "             z[33]     -0.20      1.03     -0.35     -1.26      1.78      6.71      1.21\n",
            "             z[34]      0.05      0.89      0.28     -1.59      1.29     35.56      1.07\n",
            "             z[35]     -0.11      0.96     -0.26     -1.35      1.60      8.98      1.16\n",
            "             z[36]      0.50      1.08      0.63     -1.33      1.74      6.25      1.27\n",
            "             z[37]     -0.35      0.94     -0.54     -1.70      1.26     13.92      1.13\n",
            "             z[38]     -0.03      0.87     -0.33     -1.27      1.54     82.93      1.04\n",
            "             z[39]     -0.04      0.87     -0.35     -1.32      1.58     36.48      1.13\n",
            "\n",
            "Number of divergences: 297\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>2113.626</td>\n",
              "      <td>5.331</td>\n",
              "      <td>2103.990</td>\n",
              "      <td>2124.813</td>\n",
              "      <td>0.111</td>\n",
              "      <td>1.086</td>\n",
              "      <td>44.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>363.452</td>\n",
              "      <td>110.969</td>\n",
              "      <td>196.058</td>\n",
              "      <td>623.535</td>\n",
              "      <td>18.192</td>\n",
              "      <td>21.443</td>\n",
              "      <td>49.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>154.324</td>\n",
              "      <td>131.363</td>\n",
              "      <td>-11.087</td>\n",
              "      <td>406.882</td>\n",
              "      <td>34.856</td>\n",
              "      <td>18.604</td>\n",
              "      <td>22.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>1.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>447.922</td>\n",
              "      <td>118.240</td>\n",
              "      <td>268.871</td>\n",
              "      <td>721.431</td>\n",
              "      <td>19.506</td>\n",
              "      <td>22.522</td>\n",
              "      <td>41.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>611.770</td>\n",
              "      <td>112.949</td>\n",
              "      <td>437.286</td>\n",
              "      <td>876.374</td>\n",
              "      <td>14.949</td>\n",
              "      <td>22.362</td>\n",
              "      <td>57.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>1.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>575.378</td>\n",
              "      <td>103.024</td>\n",
              "      <td>385.401</td>\n",
              "      <td>779.605</td>\n",
              "      <td>17.044</td>\n",
              "      <td>16.267</td>\n",
              "      <td>28.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>1.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>2113.355</td>\n",
              "      <td>4.032</td>\n",
              "      <td>2104.802</td>\n",
              "      <td>2121.255</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.661</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>1.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>363.513</td>\n",
              "      <td>110.940</td>\n",
              "      <td>191.210</td>\n",
              "      <td>619.194</td>\n",
              "      <td>18.103</td>\n",
              "      <td>21.514</td>\n",
              "      <td>48.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>1.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>154.342</td>\n",
              "      <td>131.271</td>\n",
              "      <td>0.000</td>\n",
              "      <td>402.190</td>\n",
              "      <td>34.907</td>\n",
              "      <td>18.511</td>\n",
              "      <td>21.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>447.906</td>\n",
              "      <td>118.158</td>\n",
              "      <td>268.330</td>\n",
              "      <td>720.032</td>\n",
              "      <td>19.504</td>\n",
              "      <td>22.511</td>\n",
              "      <td>40.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>1.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>611.888</td>\n",
              "      <td>112.924</td>\n",
              "      <td>429.695</td>\n",
              "      <td>865.361</td>\n",
              "      <td>15.008</td>\n",
              "      <td>22.351</td>\n",
              "      <td>54.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>575.356</td>\n",
              "      <td>102.944</td>\n",
              "      <td>381.450</td>\n",
              "      <td>775.863</td>\n",
              "      <td>17.082</td>\n",
              "      <td>16.292</td>\n",
              "      <td>28.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>98.703</td>\n",
              "      <td>9.104</td>\n",
              "      <td>81.124</td>\n",
              "      <td>116.430</td>\n",
              "      <td>0.974</td>\n",
              "      <td>1.012</td>\n",
              "      <td>83.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>-0.226</td>\n",
              "      <td>0.930</td>\n",
              "      <td>-1.673</td>\n",
              "      <td>1.776</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.060</td>\n",
              "      <td>78.0</td>\n",
              "      <td>426.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>-0.056</td>\n",
              "      <td>0.833</td>\n",
              "      <td>-1.560</td>\n",
              "      <td>1.750</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.121</td>\n",
              "      <td>462.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-0.276</td>\n",
              "      <td>0.904</td>\n",
              "      <td>-1.997</td>\n",
              "      <td>1.495</td>\n",
              "      <td>0.178</td>\n",
              "      <td>0.127</td>\n",
              "      <td>24.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>2072.591</td>\n",
              "      <td>163.389</td>\n",
              "      <td>1739.127</td>\n",
              "      <td>2371.466</td>\n",
              "      <td>27.628</td>\n",
              "      <td>14.794</td>\n",
              "      <td>53.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>295.276</td>\n",
              "      <td>80.748</td>\n",
              "      <td>143.544</td>\n",
              "      <td>457.258</td>\n",
              "      <td>4.777</td>\n",
              "      <td>10.676</td>\n",
              "      <td>174.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>1.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>77.757</td>\n",
              "      <td>120.694</td>\n",
              "      <td>-116.142</td>\n",
              "      <td>304.162</td>\n",
              "      <td>20.622</td>\n",
              "      <td>10.662</td>\n",
              "      <td>24.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>380.570</td>\n",
              "      <td>93.747</td>\n",
              "      <td>224.293</td>\n",
              "      <td>582.583</td>\n",
              "      <td>8.187</td>\n",
              "      <td>10.481</td>\n",
              "      <td>51.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>543.592</td>\n",
              "      <td>100.860</td>\n",
              "      <td>349.361</td>\n",
              "      <td>742.128</td>\n",
              "      <td>6.636</td>\n",
              "      <td>13.101</td>\n",
              "      <td>169.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>1.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>504.712</td>\n",
              "      <td>87.126</td>\n",
              "      <td>354.943</td>\n",
              "      <td>671.782</td>\n",
              "      <td>8.020</td>\n",
              "      <td>9.472</td>\n",
              "      <td>48.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  2113.626    5.331  2103.990  2124.813      0.111    1.086   \n",
              "pred_cases_out[1]   363.452  110.969   196.058   623.535     18.192   21.443   \n",
              "pred_cases_out[2]   154.324  131.363   -11.087   406.882     34.856   18.604   \n",
              "pred_cases_out[3]   447.922  118.240   268.871   721.431     19.506   22.522   \n",
              "pred_cases_out[4]   611.770  112.949   437.286   876.374     14.949   22.362   \n",
              "pred_cases_out[5]   575.378  103.024   385.401   779.605     17.044   16.267   \n",
              "lp[0]              2113.355    4.032  2104.802  2121.255      0.062    0.661   \n",
              "lp[1]               363.513  110.940   191.210   619.194     18.103   21.514   \n",
              "lp[2]               154.342  131.271     0.000   402.190     34.907   18.511   \n",
              "lp[3]               447.906  118.158   268.330   720.032     19.504   22.511   \n",
              "lp[4]               611.888  112.924   429.695   865.361     15.008   22.351   \n",
              "lp[5]               575.356  102.944   381.450   775.863     17.082   16.292   \n",
              "b0                   98.703    9.104    81.124   116.430      0.974    1.012   \n",
              "b_pop_density        -0.226    0.930    -1.673     1.776      0.138    0.060   \n",
              "b_hdi                -0.056    0.833    -1.560     1.750      0.040    0.121   \n",
              "b_urban              -0.276    0.904    -1.997     1.495      0.178    0.127   \n",
              "vae[0]             2072.591  163.389  1739.127  2371.466     27.628   14.794   \n",
              "vae[1]              295.276   80.748   143.544   457.258      4.777   10.676   \n",
              "vae[2]               77.757  120.694  -116.142   304.162     20.622   10.662   \n",
              "vae[3]              380.570   93.747   224.293   582.583      8.187   10.481   \n",
              "vae[4]              543.592  100.860   349.361   742.128      6.636   13.101   \n",
              "vae[5]              504.712   87.126   354.943   671.782      8.020    9.472   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]      44.0     140.0   1.46  \n",
              "pred_cases_out[1]      49.0     103.0   1.79  \n",
              "pred_cases_out[2]      22.0     116.0   1.17  \n",
              "pred_cases_out[3]      41.0     101.0   1.27  \n",
              "pred_cases_out[4]      57.0     114.0   1.43  \n",
              "pred_cases_out[5]      28.0     154.0   1.52  \n",
              "lp[0]                1450.0     260.0   1.60  \n",
              "lp[1]                  48.0      97.0   1.78  \n",
              "lp[2]                  21.0     136.0   1.18  \n",
              "lp[3]                  40.0     113.0   1.28  \n",
              "lp[4]                  54.0     123.0   1.43  \n",
              "lp[5]                  28.0     126.0   1.53  \n",
              "b0                     83.0     130.0   1.23  \n",
              "b_pop_density          78.0     426.0   1.09  \n",
              "b_hdi                 462.0     682.0   1.54  \n",
              "b_urban                24.0     226.0   1.53  \n",
              "vae[0]                 53.0     146.0   1.18  \n",
              "vae[1]                174.0     292.0   1.27  \n",
              "vae[2]                 24.0     284.0   1.12  \n",
              "vae[3]                 51.0     374.0   1.07  \n",
              "vae[4]                169.0     284.0   1.35  \n",
              "vae[5]                 48.0     293.0   1.08  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_1.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 11\n",
            "Average ESS for all aggVAE-low effects : 11\n",
            "Max r_hat for all aggVAE-low : 1.1299999952316284\n",
            "Average ESS for all aggVAE-high effects : 11\n",
            "Max r_hat for all aggVAE-high : 1.1399999856948853\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_1.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.9, tree depth 18 (best) (Rhat, ESS for table 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_2.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_2,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     99.72      8.67     98.10     85.09    114.41       nan      1.01\n",
            "             b_hdi     -0.07      0.86     -0.28     -1.43      1.51    904.59      1.01\n",
            "     b_pop_density      0.47      1.16      0.48     -1.25      1.80      4.09      1.37\n",
            "           b_urban     -0.08      0.89     -0.39     -1.39      1.60     37.05      1.04\n",
            "full_pred_cases[0]   2112.72      6.29   2112.35   2103.26   2123.13   2145.95      1.00\n",
            "full_pred_cases[1]    376.25    138.00    348.80    198.18    612.92     22.35      1.09\n",
            "full_pred_cases[2]    177.32    152.57    151.07     -7.99    399.83      6.58      1.22\n",
            "full_pred_cases[3]    453.48    149.47    437.87    277.01    711.55     11.43      1.13\n",
            "full_pred_cases[4]    612.62    151.25    594.74    424.93    847.68     17.56      1.10\n",
            "full_pred_cases[5]    585.21    126.98    565.96    393.14    751.71    404.43      1.01\n",
            "             sigma      3.68      3.08      3.04      0.44      8.05      5.15      1.30\n",
            "            sigma1     96.24     67.30     97.89     12.05    175.11       nan      1.01\n",
            "              z[0]     -0.21      0.91     -0.50     -1.56      1.52     39.24      1.04\n",
            "              z[1]     -0.28      0.96     -0.47     -1.47      1.53     10.38      1.11\n",
            "              z[2]      0.19      0.97      0.31     -1.55      1.33      7.01      1.18\n",
            "              z[3]     -0.04      0.91     -0.36     -1.39      1.66     80.59      1.02\n",
            "              z[4]      0.27      1.07      0.38     -1.75      1.34      5.62      1.23\n",
            "              z[5]      0.19      0.86      0.50     -1.36      1.56     65.04      1.03\n",
            "              z[6]      0.13      0.88      0.26     -1.50      1.53   2239.65      1.00\n",
            "              z[7]     -0.51      1.12     -0.55     -1.71      1.27      4.59      1.31\n",
            "              z[8]     -0.61      1.26     -0.47     -2.25      1.07      3.22      1.57\n",
            "              z[9]      0.47      1.17      0.44     -1.33      1.83      4.08      1.37\n",
            "             z[10]      0.26      0.93      0.54     -1.31      1.66     17.05      1.07\n",
            "             z[11]      0.15      1.01      0.32     -1.56      1.55      8.65      1.14\n",
            "             z[12]     -0.16      0.95     -0.38     -1.58      1.40     11.93      1.10\n",
            "             z[13]     -0.25      1.02     -0.36     -1.30      1.65      5.88      1.22\n",
            "             z[14]      0.15      0.96      0.38     -1.50      1.56     10.90      1.11\n",
            "             z[15]      0.14      0.94      0.39     -1.66      1.36     13.96      1.08\n",
            "             z[16]      0.11      0.93      0.39     -1.61      1.39     18.97      1.07\n",
            "             z[17]     -0.16      0.97     -0.35     -1.36      1.68      8.56      1.13\n",
            "             z[18]      0.02      0.86     -0.08     -1.48      1.49   3124.07      1.00\n",
            "             z[19]      0.06      0.91     -0.15     -1.47      1.67   1787.13      1.01\n",
            "             z[20]      0.08      0.93      0.29     -1.55      1.40     12.03      1.10\n",
            "             z[21]      0.01      0.86     -0.06     -1.51      1.45   1820.95      1.00\n",
            "             z[22]     -0.28      0.85     -0.55     -1.60      1.21     28.39      1.05\n",
            "             z[23]      0.13      0.94      0.38     -1.65      1.42     14.38      1.08\n",
            "             z[24]     -0.02      0.88      0.11     -1.60      1.43   2792.68      1.00\n",
            "             z[25]     -0.31      0.87     -0.52     -1.44      1.35     13.52      1.09\n",
            "             z[26]     -0.10      0.88     -0.17     -1.58      1.45   2274.31      1.00\n",
            "             z[27]     -0.35      0.99     -0.47     -1.40      1.55      7.35      1.17\n",
            "             z[28]      0.14      0.84      0.31     -1.43      1.43   1874.26      1.01\n",
            "             z[29]      0.49      1.11      0.51     -1.27      1.71      4.41      1.33\n",
            "             z[30]     -0.48      1.24     -0.41     -2.03      1.22      3.49      1.49\n",
            "             z[31]     -0.41      1.21     -0.35     -1.88      1.33      3.67      1.45\n",
            "             z[32]      0.21      0.88      0.53     -1.31      1.66     54.80      1.03\n",
            "             z[33]     -0.12      0.91     -0.31     -1.37      1.48     10.90      1.11\n",
            "             z[34]     -0.01      0.85      0.15     -1.45      1.45   1987.57      1.01\n",
            "             z[35]     -0.06      0.90     -0.30     -1.36      1.58     17.54      1.07\n",
            "             z[36]      0.07      0.87      0.06     -1.44      1.56   2868.85      1.00\n",
            "             z[37]     -0.63      1.20     -0.56     -2.13      1.04      3.48      1.49\n",
            "             z[38]      0.44      1.05      0.53     -1.35      1.56      4.93      1.28\n",
            "             z[39]     -0.23      1.02     -0.34     -1.45      1.55      6.06      1.21\n",
            "\n",
            "Number of divergences: 601\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>2112.720</td>\n",
              "      <td>6.289</td>\n",
              "      <td>2100.305</td>\n",
              "      <td>2126.072</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.468</td>\n",
              "      <td>2397.0</td>\n",
              "      <td>1306.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>376.249</td>\n",
              "      <td>138.002</td>\n",
              "      <td>147.484</td>\n",
              "      <td>678.758</td>\n",
              "      <td>19.721</td>\n",
              "      <td>6.712</td>\n",
              "      <td>45.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>177.320</td>\n",
              "      <td>152.574</td>\n",
              "      <td>-9.871</td>\n",
              "      <td>437.506</td>\n",
              "      <td>39.749</td>\n",
              "      <td>3.751</td>\n",
              "      <td>21.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>453.479</td>\n",
              "      <td>149.471</td>\n",
              "      <td>190.497</td>\n",
              "      <td>748.053</td>\n",
              "      <td>29.805</td>\n",
              "      <td>5.989</td>\n",
              "      <td>22.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>612.623</td>\n",
              "      <td>151.249</td>\n",
              "      <td>377.967</td>\n",
              "      <td>923.387</td>\n",
              "      <td>24.903</td>\n",
              "      <td>8.871</td>\n",
              "      <td>26.0</td>\n",
              "      <td>365.0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>585.209</td>\n",
              "      <td>126.977</td>\n",
              "      <td>342.223</td>\n",
              "      <td>785.918</td>\n",
              "      <td>6.295</td>\n",
              "      <td>13.682</td>\n",
              "      <td>546.0</td>\n",
              "      <td>601.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>2112.906</td>\n",
              "      <td>4.584</td>\n",
              "      <td>2103.844</td>\n",
              "      <td>2122.495</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.348</td>\n",
              "      <td>3060.0</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>376.083</td>\n",
              "      <td>137.902</td>\n",
              "      <td>146.292</td>\n",
              "      <td>677.864</td>\n",
              "      <td>19.980</td>\n",
              "      <td>6.706</td>\n",
              "      <td>42.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>177.412</td>\n",
              "      <td>152.554</td>\n",
              "      <td>0.000</td>\n",
              "      <td>434.777</td>\n",
              "      <td>39.697</td>\n",
              "      <td>3.762</td>\n",
              "      <td>21.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>453.669</td>\n",
              "      <td>149.346</td>\n",
              "      <td>210.748</td>\n",
              "      <td>770.045</td>\n",
              "      <td>29.707</td>\n",
              "      <td>5.964</td>\n",
              "      <td>22.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>612.842</td>\n",
              "      <td>151.178</td>\n",
              "      <td>373.388</td>\n",
              "      <td>918.735</td>\n",
              "      <td>24.804</td>\n",
              "      <td>8.879</td>\n",
              "      <td>26.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>585.235</td>\n",
              "      <td>126.830</td>\n",
              "      <td>354.474</td>\n",
              "      <td>795.337</td>\n",
              "      <td>6.288</td>\n",
              "      <td>13.699</td>\n",
              "      <td>551.0</td>\n",
              "      <td>613.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>99.717</td>\n",
              "      <td>8.668</td>\n",
              "      <td>82.635</td>\n",
              "      <td>117.411</td>\n",
              "      <td>0.169</td>\n",
              "      <td>1.105</td>\n",
              "      <td>2715.0</td>\n",
              "      <td>1335.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.475</td>\n",
              "      <td>1.162</td>\n",
              "      <td>-1.667</td>\n",
              "      <td>1.804</td>\n",
              "      <td>0.388</td>\n",
              "      <td>0.017</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>1.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>-0.066</td>\n",
              "      <td>0.865</td>\n",
              "      <td>-1.762</td>\n",
              "      <td>1.658</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.111</td>\n",
              "      <td>1225.0</td>\n",
              "      <td>1540.0</td>\n",
              "      <td>1.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-0.078</td>\n",
              "      <td>0.890</td>\n",
              "      <td>-1.742</td>\n",
              "      <td>1.662</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.079</td>\n",
              "      <td>128.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>1.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1968.057</td>\n",
              "      <td>163.556</td>\n",
              "      <td>1705.287</td>\n",
              "      <td>2307.898</td>\n",
              "      <td>28.586</td>\n",
              "      <td>7.375</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1486.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>287.686</td>\n",
              "      <td>99.803</td>\n",
              "      <td>117.429</td>\n",
              "      <td>495.527</td>\n",
              "      <td>5.068</td>\n",
              "      <td>11.150</td>\n",
              "      <td>140.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>75.255</td>\n",
              "      <td>142.358</td>\n",
              "      <td>-162.586</td>\n",
              "      <td>332.828</td>\n",
              "      <td>15.590</td>\n",
              "      <td>13.800</td>\n",
              "      <td>27.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>365.804</td>\n",
              "      <td>113.566</td>\n",
              "      <td>189.759</td>\n",
              "      <td>610.975</td>\n",
              "      <td>8.365</td>\n",
              "      <td>11.486</td>\n",
              "      <td>37.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>525.317</td>\n",
              "      <td>123.346</td>\n",
              "      <td>314.436</td>\n",
              "      <td>771.001</td>\n",
              "      <td>6.898</td>\n",
              "      <td>12.994</td>\n",
              "      <td>73.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>497.390</td>\n",
              "      <td>103.189</td>\n",
              "      <td>305.575</td>\n",
              "      <td>643.962</td>\n",
              "      <td>5.614</td>\n",
              "      <td>14.786</td>\n",
              "      <td>52.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  2112.720    6.289  2100.305  2126.072      0.135    0.468   \n",
              "pred_cases_out[1]   376.249  138.002   147.484   678.758     19.721    6.712   \n",
              "pred_cases_out[2]   177.320  152.574    -9.871   437.506     39.749    3.751   \n",
              "pred_cases_out[3]   453.479  149.471   190.497   748.053     29.805    5.989   \n",
              "pred_cases_out[4]   612.623  151.249   377.967   923.387     24.903    8.871   \n",
              "pred_cases_out[5]   585.209  126.977   342.223   785.918      6.295   13.682   \n",
              "lp[0]              2112.906    4.584  2103.844  2122.495      0.085    0.348   \n",
              "lp[1]               376.083  137.902   146.292   677.864     19.980    6.706   \n",
              "lp[2]               177.412  152.554     0.000   434.777     39.697    3.762   \n",
              "lp[3]               453.669  149.346   210.748   770.045     29.707    5.964   \n",
              "lp[4]               612.842  151.178   373.388   918.735     24.804    8.879   \n",
              "lp[5]               585.235  126.830   354.474   795.337      6.288   13.699   \n",
              "b0                   99.717    8.668    82.635   117.411      0.169    1.105   \n",
              "b_pop_density         0.475    1.162    -1.667     1.804      0.388    0.017   \n",
              "b_hdi                -0.066    0.865    -1.762     1.658      0.025    0.111   \n",
              "b_urban              -0.078    0.890    -1.742     1.662      0.098    0.079   \n",
              "vae[0]             1968.057  163.556  1705.287  2307.898     28.586    7.375   \n",
              "vae[1]              287.686   99.803   117.429   495.527      5.068   11.150   \n",
              "vae[2]               75.255  142.358  -162.586   332.828     15.590   13.800   \n",
              "vae[3]              365.804  113.566   189.759   610.975      8.365   11.486   \n",
              "vae[4]              525.317  123.346   314.436   771.001      6.898   12.994   \n",
              "vae[5]              497.390  103.189   305.575   643.962      5.614   14.786   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    2397.0    1306.0   1.53  \n",
              "pred_cases_out[1]      45.0     407.0   1.09  \n",
              "pred_cases_out[2]      21.0     664.0   1.14  \n",
              "pred_cases_out[3]      22.0     374.0   1.15  \n",
              "pred_cases_out[4]      26.0     365.0   1.12  \n",
              "pred_cases_out[5]     546.0     601.0   1.53  \n",
              "lp[0]                3060.0    1123.0   1.53  \n",
              "lp[1]                  42.0     419.0   1.09  \n",
              "lp[2]                  21.0     377.0   1.15  \n",
              "lp[3]                  22.0     369.0   1.15  \n",
              "lp[4]                  26.0     371.0   1.13  \n",
              "lp[5]                 551.0     613.0   1.53  \n",
              "b0                   2715.0    1335.0   1.53  \n",
              "b_pop_density          10.0    2001.0   1.33  \n",
              "b_hdi                1225.0    1540.0   1.52  \n",
              "b_urban               128.0    1404.0   1.24  \n",
              "vae[0]                 43.0    1486.0   1.07  \n",
              "vae[1]                140.0     391.0   1.18  \n",
              "vae[2]                 27.0     385.0   1.11  \n",
              "vae[3]                 37.0     396.0   1.09  \n",
              "vae[4]                 73.0     398.0   1.10  \n",
              "vae[5]                 52.0     540.0   1.06  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_2.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 22\n",
            "Average ESS for all aggVAE-low effects : 23\n",
            "Max r_hat for all aggVAE-low : 1.0700000524520874\n",
            "Average ESS for all aggVAE-high effects : 22\n",
            "Max r_hat for all aggVAE-high : 1.100000023841858\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_2.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "#insert the inference into the dataset\n",
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the dfs for jkt dist and province dfs with predictions - change the year accordingly (do one by one from 2023 to 2020)\n",
        "#df_hi.to_csv(\"../data/processed/df_hi_jkt_2022_aggVAE_preds.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine the best target_accept_prob on the 2021 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load the mcmc data u want\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2021_155min_prob0.95_treedepth15.pkl\", \"rb\") as f_1:\n",
        "    mcmc_1 = pickle.load(f_1)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2021_78min_prob0.85_treedepth20.pkl\", \"rb\") as f_2:\n",
        "    mcmc_2 = pickle.load(f_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 'pol_pts_lo', 'pol_pts_hi', 'df_lo', 'df_hi'])\n",
            "Dengue incidence by province and year (low resolution):\n",
            "                  incidence\n",
            "Province    Year           \n",
            "DKI Jakarta 2020   0.001519\n",
            "            2021   0.001315\n",
            "            2022   0.002667\n",
            "            2023   0.001983 \n",
            "\n",
            "We are using data for the year 2021\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "spatial_data = load_data()\n",
        "print(spatial_data.keys())\n",
        "\n",
        "# Lets lok at the data and dissect it\n",
        "lo_prev = spatial_data[\"df_lo\"].copy()\n",
        "lo_prev['incidence'] = (lo_prev.Cases / lo_prev.Population)\n",
        "print(\"Dengue incidence by province and year (low resolution):\")\n",
        "print(lo_prev.groupby(['Province', 'Year'])[['incidence']].mean(), '\\n')\n",
        "\n",
        "# make sure we use only one year of data (change manually)\n",
        "year_data = 2021\n",
        "print(f'We are using data for the year {year_data}\\n')\n",
        "\n",
        "# let us filter the data for the years 2023, 2022, 2021, 2020 (must change the input manually for year_data)\n",
        "df_lo = spatial_data[\"df_lo\"][spatial_data[\"df_lo\"].Year == year_data]\n",
        "df_hi = spatial_data[\"df_hi\"][spatial_data[\"df_hi\"].Year == year_data]\n",
        "\n",
        "df_lo = df_lo.copy()\n",
        "df_hi = df_hi.copy()\n",
        "df_lo.loc[:, 'incidence'] = df_lo.Cases / df_lo.Population\n",
        "df_hi.loc[:, 'incidence'] = df_hi.Cases / df_hi.Population\n",
        "\n",
        "total_population = jnp.concatenate([df_lo.Population.values, df_hi.Population.values])\n",
        "count = jnp.concatenate([df_lo.Cases.values, jnp.full((df_hi.shape[0],), jnp.nan)])\n",
        "hdi_index = jnp.concatenate([df_lo.HDI.values, df_hi.HDI.values])*100\n",
        "pop_density = jnp.concatenate([df_lo.Pop_den.values*1e2, (df_hi.Pop_den.values)*1e-1])\n",
        "urban_frac = jnp.concatenate([df_lo.urbanicity.values, df_hi.urbanicity.values])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.95, max tree depth 15 (Rhat, ESS for table 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_1.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_1,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    109.15     10.82    108.02     96.27    124.28      2.00 1749037.75\n",
            "             b_hdi     -0.45      1.36     -0.22     -2.56      1.19      2.00   1474.12\n",
            "     b_pop_density     -0.24      0.68     -0.18     -1.21      0.63       nan    724.63\n",
            "           b_urban     -1.30      0.43     -1.24     -1.96     -0.76      2.00   3139.32\n",
            "full_pred_cases[0]    885.33    132.35    892.93    705.31   1050.18      2.00  78313.30\n",
            "full_pred_cases[1]     36.64     68.18      9.06    -22.06    150.48      2.00 1545141.00\n",
            "full_pred_cases[2]     23.72     34.00     26.39    -22.90     64.99      2.00 178617.44\n",
            "full_pred_cases[3]     69.41     75.83     42.03     -1.73    195.31      2.00  29146.09\n",
            "full_pred_cases[4]    114.08    106.74     84.78      1.12    285.63      2.00 445404.72\n",
            "full_pred_cases[5]     42.80    135.42     -5.34    -86.17    268.02      2.00 176646.77\n",
            "             sigma     24.82     13.70     25.75      6.57     41.21      2.00 6694040.50\n",
            "            sigma1    333.45    168.11    413.26     44.69    462.59       nan 5261466.50\n",
            "              z[0]     -0.14      0.41     -0.27     -0.55      0.51      2.00    254.80\n",
            "              z[1]      0.42      1.28      0.33     -1.30      2.30      2.00   1446.33\n",
            "              z[2]      0.01      0.95     -0.35     -0.87      1.60      2.00    675.99\n",
            "              z[3]     -0.18      0.49     -0.26     -0.77      0.59      2.00    338.31\n",
            "              z[4]      0.17      0.85      0.26     -1.10      1.24      2.00   1710.41\n",
            "              z[5]     -0.40      0.94     -0.50     -1.39      0.78      2.00    863.79\n",
            "              z[6]     -0.43      1.17     -0.35     -2.14      1.11      2.00   1613.19\n",
            "              z[7]      0.58      0.79      0.31     -0.19      1.90      2.00    353.27\n",
            "              z[8]      0.28      0.98      0.27     -1.05      1.64      2.00   4193.38\n",
            "              z[9]      0.45      1.08      0.57     -1.18      1.81      2.00   4383.46\n",
            "             z[10]      0.59      0.83      0.59     -0.58      1.77      2.00    951.12\n",
            "             z[11]      0.48      0.75      0.15     -0.12      1.76      2.00    598.92\n",
            "             z[12]     -0.10      0.99     -0.10     -1.40      1.20      2.00   1360.67\n",
            "             z[13]      0.70      1.26      0.38     -0.61      2.66      2.00   1223.29\n",
            "             z[14]      0.71      1.07      0.72     -0.61      2.01      2.00   1710.61\n",
            "             z[15]      1.53      0.35      1.72      0.93      1.77      2.00  70832.54\n",
            "             z[16]     -0.49      1.59     -1.09     -1.93      2.15      2.00 250388.84\n",
            "             z[17]     -0.43      0.97     -0.71     -1.45      1.14      2.00   5546.40\n",
            "             z[18]     -0.06      1.13      0.53     -2.00      0.71       nan   2294.25\n",
            "             z[19]      0.14      1.75     -0.57     -1.40      3.11      2.00   2353.47\n",
            "             z[20]      0.37      0.52      0.57     -0.50      0.82      2.00    754.01\n",
            "             z[21]     -0.79      0.99     -0.40     -2.45      0.10      2.00    618.99\n",
            "             z[22]     -0.77      0.50     -0.61     -1.60     -0.27      2.00    587.93\n",
            "             z[23]     -0.75      1.18     -0.54     -2.42      0.49      2.00   1304.43\n",
            "             z[24]     -0.62      1.02     -0.58     -1.92      0.59      2.00    879.51\n",
            "             z[25]     -0.54      0.98     -0.77     -1.57      0.93      2.00   2054.93\n",
            "             z[26]     -0.27      0.81     -0.20     -1.31      0.64      2.00    933.31\n",
            "             z[27]      0.70      0.59      0.68     -0.03      1.48      2.00    888.21\n",
            "             z[28]      1.19      0.50      1.18      0.50      1.91      2.00    388.54\n",
            "             z[29]     -0.92      1.00     -1.15     -2.07      0.67      2.00   1280.15\n",
            "             z[30]      0.28      0.65      0.28     -0.59      1.14      2.00    675.62\n",
            "             z[31]      1.05      1.02      1.05     -0.30      2.40      2.00    701.64\n",
            "             z[32]      0.59      0.60      0.76     -0.31      1.15      2.00    516.53\n",
            "             z[33]     -0.42      0.64     -0.69     -0.96      0.67      2.00   1506.65\n",
            "             z[34]      0.09      0.78     -0.18     -0.62      1.36      2.00    759.09\n",
            "             z[35]      0.24      0.71      0.16     -0.62      1.27      2.00   1061.13\n",
            "             z[36]      0.37      0.70      0.45     -0.61      1.18      2.00   1145.10\n",
            "             z[37]      0.19      0.53     -0.03     -0.27      1.07      2.00    347.91\n",
            "             z[38]     -0.83      0.58     -1.13     -1.22      0.18      2.00   1232.98\n",
            "             z[39]      0.40      1.28      0.26     -1.25      2.33      2.00   3050.83\n",
            "\n",
            "Number of divergences: 0\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
            "C:\\Users\\jessi\\AppData\\Roaming\\Python\\Python313\\site-packages\\arviz\\stats\\diagnostics.py:596: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>885.327</td>\n",
              "      <td>132.350</td>\n",
              "      <td>705.311</td>\n",
              "      <td>1050.179</td>\n",
              "      <td>65.910</td>\n",
              "      <td>23.410</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>36.639</td>\n",
              "      <td>68.182</td>\n",
              "      <td>-22.060</td>\n",
              "      <td>150.479</td>\n",
              "      <td>33.954</td>\n",
              "      <td>18.064</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>23.718</td>\n",
              "      <td>34.002</td>\n",
              "      <td>-22.901</td>\n",
              "      <td>64.992</td>\n",
              "      <td>16.933</td>\n",
              "      <td>5.883</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>69.409</td>\n",
              "      <td>75.832</td>\n",
              "      <td>-1.731</td>\n",
              "      <td>195.315</td>\n",
              "      <td>37.764</td>\n",
              "      <td>20.016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>114.079</td>\n",
              "      <td>106.744</td>\n",
              "      <td>1.116</td>\n",
              "      <td>285.631</td>\n",
              "      <td>53.159</td>\n",
              "      <td>26.632</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>42.797</td>\n",
              "      <td>135.417</td>\n",
              "      <td>-86.174</td>\n",
              "      <td>268.019</td>\n",
              "      <td>67.437</td>\n",
              "      <td>36.032</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>972.367</td>\n",
              "      <td>64.333</td>\n",
              "      <td>890.735</td>\n",
              "      <td>1048.884</td>\n",
              "      <td>31.493</td>\n",
              "      <td>3.190</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>38.761</td>\n",
              "      <td>67.142</td>\n",
              "      <td>0.000</td>\n",
              "      <td>155.412</td>\n",
              "      <td>33.437</td>\n",
              "      <td>19.303</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>15.206</td>\n",
              "      <td>26.341</td>\n",
              "      <td>0.000</td>\n",
              "      <td>61.114</td>\n",
              "      <td>13.117</td>\n",
              "      <td>7.573</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>50.269</td>\n",
              "      <td>87.085</td>\n",
              "      <td>0.000</td>\n",
              "      <td>201.556</td>\n",
              "      <td>43.366</td>\n",
              "      <td>25.034</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>71.578</td>\n",
              "      <td>123.994</td>\n",
              "      <td>0.000</td>\n",
              "      <td>286.956</td>\n",
              "      <td>61.748</td>\n",
              "      <td>35.646</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>75.450</td>\n",
              "      <td>107.786</td>\n",
              "      <td>0.000</td>\n",
              "      <td>260.203</td>\n",
              "      <td>53.665</td>\n",
              "      <td>30.094</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>109.146</td>\n",
              "      <td>10.822</td>\n",
              "      <td>96.267</td>\n",
              "      <td>124.277</td>\n",
              "      <td>5.389</td>\n",
              "      <td>1.931</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>-0.237</td>\n",
              "      <td>0.676</td>\n",
              "      <td>-1.208</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.337</td>\n",
              "      <td>0.145</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>-0.454</td>\n",
              "      <td>1.355</td>\n",
              "      <td>-2.562</td>\n",
              "      <td>1.188</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.339</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-1.301</td>\n",
              "      <td>0.429</td>\n",
              "      <td>-1.956</td>\n",
              "      <td>-0.759</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.107</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1050.587</td>\n",
              "      <td>109.594</td>\n",
              "      <td>874.914</td>\n",
              "      <td>1201.081</td>\n",
              "      <td>54.260</td>\n",
              "      <td>26.282</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>-180.065</td>\n",
              "      <td>191.880</td>\n",
              "      <td>-330.891</td>\n",
              "      <td>149.966</td>\n",
              "      <td>95.551</td>\n",
              "      <td>54.203</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>-464.460</td>\n",
              "      <td>304.699</td>\n",
              "      <td>-675.116</td>\n",
              "      <td>58.449</td>\n",
              "      <td>151.738</td>\n",
              "      <td>85.716</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>-180.166</td>\n",
              "      <td>219.301</td>\n",
              "      <td>-329.247</td>\n",
              "      <td>199.061</td>\n",
              "      <td>109.204</td>\n",
              "      <td>62.511</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>-119.841</td>\n",
              "      <td>234.200</td>\n",
              "      <td>-320.069</td>\n",
              "      <td>280.721</td>\n",
              "      <td>116.619</td>\n",
              "      <td>65.406</td>\n",
              "      <td>5.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>52.634</td>\n",
              "      <td>146.452</td>\n",
              "      <td>-157.736</td>\n",
              "      <td>246.636</td>\n",
              "      <td>72.920</td>\n",
              "      <td>32.419</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd   hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]   885.327  132.350  705.311  1050.179     65.910   23.410   \n",
              "pred_cases_out[1]    36.639   68.182  -22.060   150.479     33.954   18.064   \n",
              "pred_cases_out[2]    23.718   34.002  -22.901    64.992     16.933    5.883   \n",
              "pred_cases_out[3]    69.409   75.832   -1.731   195.315     37.764   20.016   \n",
              "pred_cases_out[4]   114.079  106.744    1.116   285.631     53.159   26.632   \n",
              "pred_cases_out[5]    42.797  135.417  -86.174   268.019     67.437   36.032   \n",
              "lp[0]               972.367   64.333  890.735  1048.884     31.493    3.190   \n",
              "lp[1]                38.761   67.142    0.000   155.412     33.437   19.303   \n",
              "lp[2]                15.206   26.341    0.000    61.114     13.117    7.573   \n",
              "lp[3]                50.269   87.085    0.000   201.556     43.366   25.034   \n",
              "lp[4]                71.578  123.994    0.000   286.956     61.748   35.646   \n",
              "lp[5]                75.450  107.786    0.000   260.203     53.665   30.094   \n",
              "b0                  109.146   10.822   96.267   124.277      5.389    1.931   \n",
              "b_pop_density        -0.237    0.676   -1.208     0.626      0.337    0.145   \n",
              "b_hdi                -0.454    1.355   -2.562     1.188      0.675    0.339   \n",
              "b_urban              -1.301    0.429   -1.956    -0.759      0.213    0.107   \n",
              "vae[0]             1050.587  109.594  874.914  1201.081     54.260   26.282   \n",
              "vae[1]             -180.065  191.880 -330.891   149.966     95.551   54.203   \n",
              "vae[2]             -464.460  304.699 -675.116    58.449    151.738   85.716   \n",
              "vae[3]             -180.166  219.301 -329.247   199.061    109.204   62.511   \n",
              "vae[4]             -119.841  234.200 -320.069   280.721    116.619   65.406   \n",
              "vae[5]               52.634  146.452 -157.736   246.636     72.920   32.419   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]       4.0       4.0    inf  \n",
              "pred_cases_out[1]       4.0       4.0    inf  \n",
              "pred_cases_out[2]       4.0       4.0    inf  \n",
              "pred_cases_out[3]       4.0      11.0  15.87  \n",
              "pred_cases_out[4]       4.0       4.0    inf  \n",
              "pred_cases_out[5]       4.0       4.0    inf  \n",
              "lp[0]                   5.0      32.0   2.13  \n",
              "lp[1]                   4.0       4.0   3.48  \n",
              "lp[2]                   4.0       4.0   3.61  \n",
              "lp[3]                   4.0       4.0   3.38  \n",
              "lp[4]                   4.0       4.0   3.27  \n",
              "lp[5]                   4.0       4.0   3.61  \n",
              "b0                      4.0       4.0    inf  \n",
              "b_pop_density           4.0       4.0   7.78  \n",
              "b_hdi                   4.0       4.0   9.59  \n",
              "b_urban                 4.0       4.0  17.12  \n",
              "vae[0]                  5.0      12.0   3.18  \n",
              "vae[1]                  5.0      20.0   3.07  \n",
              "vae[2]                  5.0      19.0   2.82  \n",
              "vae[3]                  5.0      13.0   3.09  \n",
              "vae[4]                  5.0      21.0   3.04  \n",
              "vae[5]                  5.0      20.0   3.04  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_1.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 2\n",
            "Average ESS for all aggVAE-low effects : 2\n",
            "Max r_hat for all aggVAE-low : 249.27000427246094\n",
            "Average ESS for all aggVAE-high effects : 2\n",
            "Max r_hat for all aggVAE-high : 346.5199890136719\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_1.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.85, max tree depth 20 (best) - Rhat, ESS for table 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_2.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_2,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     99.97      9.92     99.78     83.42    116.03   3134.41      1.00\n",
            "             b_hdi      0.10      1.01      0.11     -1.54      1.77   1149.65      1.00\n",
            "     b_pop_density      0.12      1.03      0.13     -1.66      1.75   2105.43      1.00\n",
            "           b_urban      0.11      1.03      0.08     -1.65      1.75    414.62      1.00\n",
            "full_pred_cases[0]   1047.92      8.08   1047.89   1035.29   1061.32   1560.81      1.00\n",
            "full_pred_cases[1]    254.39    125.29    257.48     68.67    497.88    306.74      1.01\n",
            "full_pred_cases[2]    165.45    126.63    156.37    -13.52    343.82    307.95      1.01\n",
            "full_pred_cases[3]    290.90    128.40    295.35     96.02    522.94    312.14      1.01\n",
            "full_pred_cases[4]    364.21    126.52    368.06    167.57    572.16    347.69      1.01\n",
            "full_pred_cases[5]    351.31    122.24    346.75    179.09    568.27    413.81      1.00\n",
            "             sigma      5.15      2.97      4.66      0.58      9.44    240.50      1.02\n",
            "            sigma1     64.88     64.74     40.88      4.62    151.94     56.19      1.05\n",
            "              z[0]      0.01      1.02     -0.00     -1.63      1.63   1533.64      1.00\n",
            "              z[1]     -0.06      0.98     -0.05     -1.64      1.54   2693.06      1.00\n",
            "              z[2]     -0.12      0.99     -0.10     -1.88      1.39   1012.82      1.00\n",
            "              z[3]      0.06      0.99      0.07     -1.46      1.77   3049.06      1.00\n",
            "              z[4]     -0.03      1.03     -0.03     -1.70      1.58   1413.31      1.00\n",
            "              z[5]      0.04      1.00      0.03     -1.41      1.79   1731.92      1.00\n",
            "              z[6]      0.09      1.03      0.09     -1.65      1.66   1634.91      1.00\n",
            "              z[7]     -0.08      1.01     -0.08     -1.67      1.62   2109.36      1.00\n",
            "              z[8]     -0.08      1.01     -0.10     -1.63      1.62   1376.51      1.00\n",
            "              z[9]     -0.03      1.03     -0.01     -1.78      1.62    588.88      1.01\n",
            "             z[10]      0.04      1.00      0.03     -1.64      1.67   2214.76      1.00\n",
            "             z[11]     -0.10      0.98     -0.10     -1.71      1.50   1995.32      1.00\n",
            "             z[12]      0.07      1.02      0.09     -1.48      1.86   1871.18      1.00\n",
            "             z[13]     -0.01      1.01     -0.01     -1.54      1.77   1735.88      1.00\n",
            "             z[14]     -0.03      0.98     -0.06     -1.59      1.63   1295.41      1.00\n",
            "             z[15]     -0.06      0.99     -0.08     -1.82      1.43   2818.61      1.00\n",
            "             z[16]     -0.09      1.06     -0.10     -1.76      1.66   1041.20      1.00\n",
            "             z[17]      0.13      1.02      0.11     -1.59      1.81    465.12      1.02\n",
            "             z[18]      0.02      1.00      0.01     -1.56      1.71   1994.50      1.00\n",
            "             z[19]      0.09      1.01      0.06     -1.58      1.75   2694.13      1.00\n",
            "             z[20]     -0.08      1.04     -0.13     -1.84      1.53   1709.84      1.00\n",
            "             z[21]      0.02      0.95      0.03     -1.47      1.64   2662.48      1.00\n",
            "             z[22]     -0.14      0.99     -0.16     -1.79      1.48   2073.85      1.00\n",
            "             z[23]     -0.07      1.01     -0.05     -1.86      1.42   2103.90      1.00\n",
            "             z[24]     -0.05      1.01     -0.02     -1.74      1.59   2625.80      1.00\n",
            "             z[25]     -0.08      0.99     -0.08     -1.74      1.46   2355.80      1.00\n",
            "             z[26]     -0.05      0.99     -0.05     -1.62      1.58   2178.18      1.00\n",
            "             z[27]     -0.06      1.01     -0.05     -1.71      1.56   2372.25      1.00\n",
            "             z[28]      0.07      0.98      0.08     -1.45      1.81   2103.06      1.00\n",
            "             z[29]      0.09      1.00      0.10     -1.62      1.63    979.87      1.01\n",
            "             z[30]      0.04      1.01      0.04     -1.52      1.77   1925.36      1.00\n",
            "             z[31]      0.01      1.01      0.01     -1.66      1.60   1084.64      1.00\n",
            "             z[32]      0.06      1.07      0.06     -1.72      1.87    670.38      1.00\n",
            "             z[33]      0.07      0.99      0.05     -1.54      1.66   2369.51      1.00\n",
            "             z[34]     -0.13      1.05     -0.11     -1.86      1.62    463.38      1.01\n",
            "             z[35]      0.04      0.99      0.05     -1.62      1.64   1707.20      1.00\n",
            "             z[36]      0.02      1.01      0.05     -1.66      1.61   1264.52      1.00\n",
            "             z[37]     -0.06      0.96     -0.06     -1.66      1.54   2356.02      1.00\n",
            "             z[38]      0.07      1.01      0.09     -1.43      1.84   2847.15      1.00\n",
            "             z[39]      0.06      0.98      0.04     -1.50      1.74   3019.11      1.00\n",
            "\n",
            "Number of divergences: 991\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1047.920</td>\n",
              "      <td>8.084</td>\n",
              "      <td>1032.853</td>\n",
              "      <td>1064.378</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.293</td>\n",
              "      <td>1563.0</td>\n",
              "      <td>1394.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>254.392</td>\n",
              "      <td>125.286</td>\n",
              "      <td>-10.243</td>\n",
              "      <td>465.543</td>\n",
              "      <td>7.141</td>\n",
              "      <td>3.626</td>\n",
              "      <td>314.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>165.454</td>\n",
              "      <td>126.631</td>\n",
              "      <td>-13.515</td>\n",
              "      <td>396.530</td>\n",
              "      <td>7.203</td>\n",
              "      <td>3.409</td>\n",
              "      <td>323.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>290.896</td>\n",
              "      <td>128.400</td>\n",
              "      <td>34.358</td>\n",
              "      <td>526.837</td>\n",
              "      <td>7.251</td>\n",
              "      <td>3.351</td>\n",
              "      <td>320.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>364.212</td>\n",
              "      <td>126.523</td>\n",
              "      <td>139.652</td>\n",
              "      <td>619.246</td>\n",
              "      <td>6.762</td>\n",
              "      <td>3.862</td>\n",
              "      <td>352.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>351.309</td>\n",
              "      <td>122.235</td>\n",
              "      <td>132.492</td>\n",
              "      <td>572.152</td>\n",
              "      <td>5.989</td>\n",
              "      <td>4.966</td>\n",
              "      <td>425.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1047.987</td>\n",
              "      <td>5.856</td>\n",
              "      <td>1035.599</td>\n",
              "      <td>1058.834</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.211</td>\n",
              "      <td>2516.0</td>\n",
              "      <td>1727.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>254.562</td>\n",
              "      <td>124.981</td>\n",
              "      <td>0.000</td>\n",
              "      <td>465.824</td>\n",
              "      <td>7.094</td>\n",
              "      <td>3.547</td>\n",
              "      <td>315.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>165.587</td>\n",
              "      <td>126.586</td>\n",
              "      <td>0.000</td>\n",
              "      <td>392.557</td>\n",
              "      <td>7.231</td>\n",
              "      <td>3.495</td>\n",
              "      <td>303.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>290.918</td>\n",
              "      <td>128.349</td>\n",
              "      <td>36.752</td>\n",
              "      <td>530.107</td>\n",
              "      <td>7.254</td>\n",
              "      <td>3.354</td>\n",
              "      <td>316.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>364.422</td>\n",
              "      <td>126.580</td>\n",
              "      <td>135.808</td>\n",
              "      <td>613.549</td>\n",
              "      <td>6.836</td>\n",
              "      <td>3.899</td>\n",
              "      <td>344.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>351.193</td>\n",
              "      <td>122.335</td>\n",
              "      <td>133.045</td>\n",
              "      <td>572.986</td>\n",
              "      <td>5.981</td>\n",
              "      <td>4.959</td>\n",
              "      <td>426.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>99.973</td>\n",
              "      <td>9.918</td>\n",
              "      <td>80.801</td>\n",
              "      <td>118.343</td>\n",
              "      <td>0.177</td>\n",
              "      <td>0.195</td>\n",
              "      <td>3153.0</td>\n",
              "      <td>2291.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.121</td>\n",
              "      <td>1.033</td>\n",
              "      <td>-1.837</td>\n",
              "      <td>2.054</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.024</td>\n",
              "      <td>2149.0</td>\n",
              "      <td>965.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.098</td>\n",
              "      <td>1.007</td>\n",
              "      <td>-1.894</td>\n",
              "      <td>1.954</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.020</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1816.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>0.109</td>\n",
              "      <td>1.028</td>\n",
              "      <td>-1.607</td>\n",
              "      <td>2.173</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.028</td>\n",
              "      <td>434.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>915.081</td>\n",
              "      <td>179.987</td>\n",
              "      <td>582.674</td>\n",
              "      <td>1239.598</td>\n",
              "      <td>6.518</td>\n",
              "      <td>3.198</td>\n",
              "      <td>755.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>133.772</td>\n",
              "      <td>78.431</td>\n",
              "      <td>-19.929</td>\n",
              "      <td>269.919</td>\n",
              "      <td>2.760</td>\n",
              "      <td>4.043</td>\n",
              "      <td>1131.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>29.363</td>\n",
              "      <td>105.672</td>\n",
              "      <td>-166.062</td>\n",
              "      <td>197.970</td>\n",
              "      <td>4.415</td>\n",
              "      <td>6.931</td>\n",
              "      <td>803.0</td>\n",
              "      <td>687.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>169.907</td>\n",
              "      <td>89.264</td>\n",
              "      <td>10.318</td>\n",
              "      <td>340.667</td>\n",
              "      <td>3.075</td>\n",
              "      <td>4.371</td>\n",
              "      <td>1131.0</td>\n",
              "      <td>798.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>245.328</td>\n",
              "      <td>100.286</td>\n",
              "      <td>63.658</td>\n",
              "      <td>433.633</td>\n",
              "      <td>3.230</td>\n",
              "      <td>4.545</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>234.034</td>\n",
              "      <td>89.132</td>\n",
              "      <td>87.227</td>\n",
              "      <td>400.539</td>\n",
              "      <td>2.892</td>\n",
              "      <td>5.701</td>\n",
              "      <td>1286.0</td>\n",
              "      <td>1035.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1047.920    8.084  1032.853  1064.378      0.200    0.293   \n",
              "pred_cases_out[1]   254.392  125.286   -10.243   465.543      7.141    3.626   \n",
              "pred_cases_out[2]   165.454  126.631   -13.515   396.530      7.203    3.409   \n",
              "pred_cases_out[3]   290.896  128.400    34.358   526.837      7.251    3.351   \n",
              "pred_cases_out[4]   364.212  126.523   139.652   619.246      6.762    3.862   \n",
              "pred_cases_out[5]   351.309  122.235   132.492   572.152      5.989    4.966   \n",
              "lp[0]              1047.987    5.856  1035.599  1058.834      0.119    0.211   \n",
              "lp[1]               254.562  124.981     0.000   465.824      7.094    3.547   \n",
              "lp[2]               165.587  126.586     0.000   392.557      7.231    3.495   \n",
              "lp[3]               290.918  128.349    36.752   530.107      7.254    3.354   \n",
              "lp[4]               364.422  126.580   135.808   613.549      6.836    3.899   \n",
              "lp[5]               351.193  122.335   133.045   572.986      5.981    4.959   \n",
              "b0                   99.973    9.918    80.801   118.343      0.177    0.195   \n",
              "b_pop_density         0.121    1.033    -1.837     2.054      0.022    0.024   \n",
              "b_hdi                 0.098    1.007    -1.894     1.954      0.030    0.020   \n",
              "b_urban               0.109    1.028    -1.607     2.173      0.050    0.028   \n",
              "vae[0]              915.081  179.987   582.674  1239.598      6.518    3.198   \n",
              "vae[1]              133.772   78.431   -19.929   269.919      2.760    4.043   \n",
              "vae[2]               29.363  105.672  -166.062   197.970      4.415    6.931   \n",
              "vae[3]              169.907   89.264    10.318   340.667      3.075    4.371   \n",
              "vae[4]              245.328  100.286    63.658   433.633      3.230    4.545   \n",
              "vae[5]              234.034   89.132    87.227   400.539      2.892    5.701   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    1563.0    1394.0   1.01  \n",
              "pred_cases_out[1]     314.0     148.0   1.01  \n",
              "pred_cases_out[2]     323.0     146.0   1.01  \n",
              "pred_cases_out[3]     320.0     158.0   1.01  \n",
              "pred_cases_out[4]     352.0     610.0   1.01  \n",
              "pred_cases_out[5]     425.0     324.0   1.00  \n",
              "lp[0]                2516.0    1727.0   1.01  \n",
              "lp[1]                 315.0     149.0   1.01  \n",
              "lp[2]                 303.0     146.0   1.01  \n",
              "lp[3]                 316.0     154.0   1.01  \n",
              "lp[4]                 344.0     290.0   1.01  \n",
              "lp[5]                 426.0     292.0   1.00  \n",
              "b0                   3153.0    2291.0   1.00  \n",
              "b_pop_density        2149.0     965.0   1.00  \n",
              "b_hdi                1149.0    1816.0   1.00  \n",
              "b_urban               434.0     142.0   1.00  \n",
              "vae[0]                755.0    2012.0   1.00  \n",
              "vae[1]               1131.0     849.0   1.01  \n",
              "vae[2]                803.0     687.0   1.02  \n",
              "vae[3]               1131.0     798.0   1.01  \n",
              "vae[4]               1241.0     876.0   1.01  \n",
              "vae[5]               1286.0    1035.0   1.02  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_2.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 505\n",
            "Average ESS for all aggVAE-low effects : 449\n",
            "Max r_hat for all aggVAE-low : 1.0199999809265137\n",
            "Average ESS for all aggVAE-high effects : 516\n",
            "Max r_hat for all aggVAE-high : 1.0199999809265137\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_2.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "#insert the inference into the dataset\n",
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#since i dont have sufficient computational resources to run target_accept_prob = 0.9 w tree depth = 20, the best results r the ones that converged\n",
        "#df_hi.to_csv(\"../data/processed/df_hi_jkt_2021_aggVAE_preds.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine the best target_accept_prob on the 2020 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load the mcmc data u want\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2020_54min_z40_prob0.95_treedepth15.pkl\", \"rb\") as f_1:\n",
        "    mcmc_1 = pickle.load(f_1)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2020_78min_prob0.85_treedepth20.pkl\", \"rb\") as f_2:\n",
        "    mcmc_2 = pickle.load(f_2)\n",
        "\n",
        "with open(\"../model weights/aggVAEPrev/mcmc_jkt_2020_35min_z40_prob0.9_treedepth20.pkl\", \"rb\") as f_3:\n",
        "    mcmc_3 = pickle.load(f_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 'pol_pts_lo', 'pol_pts_hi', 'df_lo', 'df_hi'])\n",
            "Dengue incidence by province and year (low resolution):\n",
            "                  incidence\n",
            "Province    Year           \n",
            "DKI Jakarta 2020   0.001519\n",
            "            2021   0.001315\n",
            "            2022   0.002667\n",
            "            2023   0.001983 \n",
            "\n",
            "We are using data for the year 2020\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "spatial_data = load_data()\n",
        "print(spatial_data.keys())\n",
        "\n",
        "# Lets lok at the data and dissect it\n",
        "lo_prev = spatial_data[\"df_lo\"].copy()\n",
        "lo_prev['incidence'] = (lo_prev.Cases / lo_prev.Population)\n",
        "print(\"Dengue incidence by province and year (low resolution):\")\n",
        "print(lo_prev.groupby(['Province', 'Year'])[['incidence']].mean(), '\\n')\n",
        "\n",
        "# make sure we use only one year of data (change manually)\n",
        "year_data = 2020\n",
        "print(f'We are using data for the year {year_data}\\n')\n",
        "\n",
        "# let us filter the data for the years 2023, 2022, 2021, 2020 (must change the input manually for year_data)\n",
        "df_lo = spatial_data[\"df_lo\"][spatial_data[\"df_lo\"].Year == year_data]\n",
        "df_hi = spatial_data[\"df_hi\"][spatial_data[\"df_hi\"].Year == year_data]\n",
        "\n",
        "df_lo = df_lo.copy()\n",
        "df_hi = df_hi.copy()\n",
        "df_lo.loc[:, 'incidence'] = df_lo.Cases / df_lo.Population\n",
        "df_hi.loc[:, 'incidence'] = df_hi.Cases / df_hi.Population\n",
        "\n",
        "total_population = jnp.concatenate([df_lo.Population.values, df_hi.Population.values])\n",
        "count = jnp.concatenate([df_lo.Cases.values, jnp.full((df_hi.shape[0],), jnp.nan)])\n",
        "hdi_index = jnp.concatenate([df_lo.HDI.values, df_hi.HDI.values])*100\n",
        "pop_density = jnp.concatenate([df_lo.Pop_den.values*1e2, (df_hi.Pop_den.values)*1e-1])\n",
        "urban_frac = jnp.concatenate([df_lo.urbanicity.values, df_hi.urbanicity.values])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_count = {\n",
        "    'x': spatial_data[\"x\"],\n",
        "    'gp_kernel': exp_sq_kernel,\n",
        "    'noise': 1e-2,\n",
        "    'jitter': 1e-2,\n",
        "    'M_lo': jnp.array(spatial_data[\"pol_pts_lo\"]),\n",
        "    'M_hi': jnp.array(spatial_data[\"pol_pts_hi\"]),\n",
        "    'kernel_length': dist.InverseGamma(5, 2),\n",
        "    'kernel_var': dist.LogNormal(-1, 0.05),\n",
        "    'pop_density': pop_density,\n",
        "    'hdi_index': hdi_index,\n",
        "    'urban_frac': urban_frac,\n",
        "    'count': count,\n",
        "    'prior_pred': False,\n",
        "    \"decoder_params\": decoder_params,\n",
        "    \"out_dims\": 6 # [lo + hi]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.95, max tree depth 15 (Rhat, ESS for table 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_1.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_1,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    100.65      8.87    102.54     84.92    115.58    471.32      1.02\n",
            "             b_hdi      0.21      0.89      0.47     -1.45      1.44     23.82      1.06\n",
            "     b_pop_density      0.20      0.88      0.47     -1.40      1.47     30.53      1.06\n",
            "           b_urban     -0.33      1.00     -0.42     -1.42      1.48      6.41      1.22\n",
            "full_pred_cases[0]   1217.20      6.13   1216.82   1208.30   1226.89    796.97      1.01\n",
            "full_pred_cases[1]    241.72    123.01    214.61     61.17    454.90     20.53      1.08\n",
            "full_pred_cases[2]    121.15    124.55     73.04    -13.29    305.85     10.28      1.14\n",
            "full_pred_cases[3]    281.57    128.26    257.31    116.14    524.56     20.88      1.08\n",
            "full_pred_cases[4]    375.16    130.38    352.76    198.63    596.29     27.22      1.07\n",
            "full_pred_cases[5]    375.21    126.88    333.74    189.57    573.65     85.66      1.04\n",
            "             sigma      3.18      3.11      2.47      0.11      7.54      5.22      1.31\n",
            "            sigma1     88.33     71.98     73.86      6.24    184.18       nan      1.02\n",
            "              z[0]      0.07      0.91      0.32     -1.53      1.58    547.91      1.03\n",
            "              z[1]     -0.15      0.86     -0.45     -1.47      1.41     76.37      1.04\n",
            "              z[2]     -0.28      0.97     -0.47     -1.59      1.47      9.93      1.12\n",
            "              z[3]      0.20      0.93      0.50     -1.54      1.45     20.37      1.06\n",
            "              z[4]      0.48      1.20      0.43     -1.29      1.90      3.83      1.43\n",
            "              z[5]      0.11      0.82      0.30     -1.23      1.60    936.60      1.01\n",
            "              z[6]     -0.22      0.95     -0.41     -1.37      1.55      9.14      1.14\n",
            "              z[7]      0.11      0.91      0.38     -1.60      1.27     20.58      1.08\n",
            "              z[8]      0.04      0.90      0.36     -1.53      1.57    304.73      1.03\n",
            "              z[9]      0.25      0.96      0.47     -1.60      1.37     10.45      1.12\n",
            "             z[10]     -0.46      1.17     -0.42     -1.77      1.42      4.26      1.36\n",
            "             z[11]      0.06      0.88      0.35     -1.50      1.46       nan      1.04\n",
            "             z[12]      0.16      0.93      0.40     -1.62      1.45     26.58      1.06\n",
            "             z[13]      0.49      1.15      0.52     -1.38      1.75      4.63      1.32\n",
            "             z[14]      0.40      1.13      0.38     -1.35      1.66      4.32      1.36\n",
            "             z[15]     -0.12      0.85     -0.41     -1.44      1.44    833.98      1.02\n",
            "             z[16]     -0.29      1.00     -0.48     -1.51      1.55      9.39      1.14\n",
            "             z[17]     -0.12      0.95     -0.41     -1.49      1.63     54.66      1.05\n",
            "             z[18]      0.07      0.87     -0.04     -1.49      1.47    726.47      1.00\n",
            "             z[19]      0.39      1.07      0.45     -1.44      1.51      5.01      1.29\n",
            "             z[20]     -0.12      0.90     -0.13     -1.82      1.35    487.76      1.00\n",
            "             z[21]      0.17      0.87      0.48     -1.34      1.61    101.13      1.03\n",
            "             z[22]     -0.25      0.93     -0.49     -1.50      1.49     18.67      1.08\n",
            "             z[23]      0.09      0.88      0.39     -1.47      1.44     38.88      1.06\n",
            "             z[24]     -0.00      0.86      0.07     -1.58      1.39   1081.74      1.00\n",
            "             z[25]      0.08      0.90      0.32     -1.56      1.36     21.48      1.08\n",
            "             z[26]     -0.36      1.00     -0.52     -1.62      1.42      8.09      1.16\n",
            "             z[27]     -0.02      0.88      0.13     -1.53      1.44    839.33      1.01\n",
            "             z[28]     -0.23      0.97     -0.35     -1.34      1.48      6.34      1.20\n",
            "             z[29]     -0.02      0.87     -0.25     -1.50      1.46    644.59      1.02\n",
            "             z[30]      0.16      0.90      0.44     -1.49      1.46     30.27      1.06\n",
            "             z[31]     -0.25      0.94     -0.39     -1.48      1.33      7.48      1.17\n",
            "             z[32]     -0.11      0.90     -0.39     -1.38      1.51     23.66      1.06\n",
            "             z[33]      0.19      0.90      0.42     -1.54      1.50    636.99      1.01\n",
            "             z[34]     -0.00      0.84      0.12     -1.29      1.69    860.71      1.01\n",
            "             z[35]      0.50      1.09      0.55     -1.35      1.65      4.87      1.30\n",
            "             z[36]      0.09      0.84     -0.00     -1.38      1.50    924.02      1.01\n",
            "             z[37]     -0.55      1.17     -0.48     -1.97      1.09      3.71      1.46\n",
            "             z[38]     -0.13      0.90     -0.34     -1.32      1.54     12.42      1.10\n",
            "             z[39]     -0.13      0.89     -0.39     -1.41      1.42     22.35      1.06\n",
            "\n",
            "Number of divergences: 341\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1217.202</td>\n",
              "      <td>6.129</td>\n",
              "      <td>1206.090</td>\n",
              "      <td>1230.135</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.746</td>\n",
              "      <td>1082.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>1.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>241.724</td>\n",
              "      <td>123.012</td>\n",
              "      <td>-8.118</td>\n",
              "      <td>441.554</td>\n",
              "      <td>18.371</td>\n",
              "      <td>10.605</td>\n",
              "      <td>53.0</td>\n",
              "      <td>483.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>121.151</td>\n",
              "      <td>124.555</td>\n",
              "      <td>-9.055</td>\n",
              "      <td>350.836</td>\n",
              "      <td>26.881</td>\n",
              "      <td>4.737</td>\n",
              "      <td>54.0</td>\n",
              "      <td>631.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>281.572</td>\n",
              "      <td>128.255</td>\n",
              "      <td>-4.639</td>\n",
              "      <td>488.993</td>\n",
              "      <td>20.304</td>\n",
              "      <td>8.324</td>\n",
              "      <td>43.0</td>\n",
              "      <td>439.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>375.163</td>\n",
              "      <td>130.384</td>\n",
              "      <td>140.247</td>\n",
              "      <td>637.265</td>\n",
              "      <td>18.135</td>\n",
              "      <td>11.483</td>\n",
              "      <td>46.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>375.211</td>\n",
              "      <td>126.884</td>\n",
              "      <td>160.778</td>\n",
              "      <td>634.078</td>\n",
              "      <td>8.053</td>\n",
              "      <td>11.514</td>\n",
              "      <td>319.0</td>\n",
              "      <td>659.0</td>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1217.083</td>\n",
              "      <td>4.409</td>\n",
              "      <td>1208.754</td>\n",
              "      <td>1226.663</td>\n",
              "      <td>0.117</td>\n",
              "      <td>0.507</td>\n",
              "      <td>1406.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>241.645</td>\n",
              "      <td>122.943</td>\n",
              "      <td>0.000</td>\n",
              "      <td>441.217</td>\n",
              "      <td>18.379</td>\n",
              "      <td>10.600</td>\n",
              "      <td>49.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>121.173</td>\n",
              "      <td>124.540</td>\n",
              "      <td>0.000</td>\n",
              "      <td>346.318</td>\n",
              "      <td>26.893</td>\n",
              "      <td>4.744</td>\n",
              "      <td>49.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>281.637</td>\n",
              "      <td>128.410</td>\n",
              "      <td>0.000</td>\n",
              "      <td>489.274</td>\n",
              "      <td>20.270</td>\n",
              "      <td>8.516</td>\n",
              "      <td>41.0</td>\n",
              "      <td>438.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>375.239</td>\n",
              "      <td>130.378</td>\n",
              "      <td>138.803</td>\n",
              "      <td>636.952</td>\n",
              "      <td>18.065</td>\n",
              "      <td>11.581</td>\n",
              "      <td>45.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>375.193</td>\n",
              "      <td>126.743</td>\n",
              "      <td>155.416</td>\n",
              "      <td>626.964</td>\n",
              "      <td>8.216</td>\n",
              "      <td>11.687</td>\n",
              "      <td>276.0</td>\n",
              "      <td>658.0</td>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>100.652</td>\n",
              "      <td>8.871</td>\n",
              "      <td>82.096</td>\n",
              "      <td>117.036</td>\n",
              "      <td>0.402</td>\n",
              "      <td>1.045</td>\n",
              "      <td>584.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.205</td>\n",
              "      <td>0.882</td>\n",
              "      <td>-1.606</td>\n",
              "      <td>1.738</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.076</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1573.0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.206</td>\n",
              "      <td>0.892</td>\n",
              "      <td>-1.592</td>\n",
              "      <td>1.778</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.084</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1227.0</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>-0.329</td>\n",
              "      <td>1.003</td>\n",
              "      <td>-1.718</td>\n",
              "      <td>1.668</td>\n",
              "      <td>0.267</td>\n",
              "      <td>0.023</td>\n",
              "      <td>17.0</td>\n",
              "      <td>733.0</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1105.127</td>\n",
              "      <td>144.942</td>\n",
              "      <td>821.974</td>\n",
              "      <td>1408.277</td>\n",
              "      <td>5.439</td>\n",
              "      <td>20.277</td>\n",
              "      <td>610.0</td>\n",
              "      <td>964.0</td>\n",
              "      <td>1.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>153.302</td>\n",
              "      <td>90.371</td>\n",
              "      <td>-20.217</td>\n",
              "      <td>334.425</td>\n",
              "      <td>5.231</td>\n",
              "      <td>6.131</td>\n",
              "      <td>90.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>18.399</td>\n",
              "      <td>118.402</td>\n",
              "      <td>-225.645</td>\n",
              "      <td>215.273</td>\n",
              "      <td>7.449</td>\n",
              "      <td>9.476</td>\n",
              "      <td>60.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>193.482</td>\n",
              "      <td>99.925</td>\n",
              "      <td>18.713</td>\n",
              "      <td>406.677</td>\n",
              "      <td>6.089</td>\n",
              "      <td>7.310</td>\n",
              "      <td>77.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>287.295</td>\n",
              "      <td>111.262</td>\n",
              "      <td>76.675</td>\n",
              "      <td>512.892</td>\n",
              "      <td>5.700</td>\n",
              "      <td>8.572</td>\n",
              "      <td>219.0</td>\n",
              "      <td>416.0</td>\n",
              "      <td>1.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>285.997</td>\n",
              "      <td>105.049</td>\n",
              "      <td>114.315</td>\n",
              "      <td>502.097</td>\n",
              "      <td>4.121</td>\n",
              "      <td>7.599</td>\n",
              "      <td>753.0</td>\n",
              "      <td>833.0</td>\n",
              "      <td>1.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1217.202    6.129  1206.090  1230.135      0.215    0.746   \n",
              "pred_cases_out[1]   241.724  123.012    -8.118   441.554     18.371   10.605   \n",
              "pred_cases_out[2]   121.151  124.555    -9.055   350.836     26.881    4.737   \n",
              "pred_cases_out[3]   281.572  128.255    -4.639   488.993     20.304    8.324   \n",
              "pred_cases_out[4]   375.163  130.384   140.247   637.265     18.135   11.483   \n",
              "pred_cases_out[5]   375.211  126.884   160.778   634.078      8.053   11.514   \n",
              "lp[0]              1217.083    4.409  1208.754  1226.663      0.117    0.507   \n",
              "lp[1]               241.645  122.943     0.000   441.217     18.379   10.600   \n",
              "lp[2]               121.173  124.540     0.000   346.318     26.893    4.744   \n",
              "lp[3]               281.637  128.410     0.000   489.274     20.270    8.516   \n",
              "lp[4]               375.239  130.378   138.803   636.952     18.065   11.581   \n",
              "lp[5]               375.193  126.743   155.416   626.964      8.216   11.687   \n",
              "b0                  100.652    8.871    82.096   117.036      0.402    1.045   \n",
              "b_pop_density         0.205    0.882    -1.606     1.738      0.113    0.076   \n",
              "b_hdi                 0.206    0.892    -1.592     1.778      0.116    0.084   \n",
              "b_urban              -0.329    1.003    -1.718     1.668      0.267    0.023   \n",
              "vae[0]             1105.127  144.942   821.974  1408.277      5.439   20.277   \n",
              "vae[1]              153.302   90.371   -20.217   334.425      5.231    6.131   \n",
              "vae[2]               18.399  118.402  -225.645   215.273      7.449    9.476   \n",
              "vae[3]              193.482   99.925    18.713   406.677      6.089    7.310   \n",
              "vae[4]              287.295  111.262    76.675   512.892      5.700    8.572   \n",
              "vae[5]              285.997  105.049   114.315   502.097      4.121    7.599   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    1082.0     167.0   1.57  \n",
              "pred_cases_out[1]      53.0     483.0   1.07  \n",
              "pred_cases_out[2]      54.0     631.0   1.08  \n",
              "pred_cases_out[3]      43.0     439.0   1.08  \n",
              "pred_cases_out[4]      46.0     406.0   1.07  \n",
              "pred_cases_out[5]     319.0     659.0   1.23  \n",
              "lp[0]                1406.0     256.0   1.56  \n",
              "lp[1]                  49.0     480.0   1.07  \n",
              "lp[2]                  49.0     270.0   1.08  \n",
              "lp[3]                  41.0     438.0   1.08  \n",
              "lp[4]                  45.0     417.0   1.08  \n",
              "lp[5]                 276.0     658.0   1.23  \n",
              "b0                    584.0     626.0   1.53  \n",
              "b_pop_density         102.0    1573.0   1.12  \n",
              "b_hdi                 103.0    1227.0   1.11  \n",
              "b_urban                17.0     733.0   1.18  \n",
              "vae[0]                610.0     964.0   1.55  \n",
              "vae[1]                 90.0     424.0   1.11  \n",
              "vae[2]                 60.0     383.0   1.06  \n",
              "vae[3]                 77.0     417.0   1.10  \n",
              "vae[4]                219.0     416.0   1.26  \n",
              "vae[5]                753.0     833.0   1.56  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_1.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 57\n",
            "Average ESS for all aggVAE-low effects : 112\n",
            "Max r_hat for all aggVAE-low : 1.0399999618530273\n",
            "Average ESS for all aggVAE-high effects : 46\n",
            "Max r_hat for all aggVAE-high : 1.0700000524520874\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_1.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.85, max tree depth 20 (best) - Rhat, ESS, RMSE, MAE for table 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_2.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_2,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0    100.20      9.68    100.50     85.43    117.30   2867.23      1.00\n",
            "             b_hdi      0.03      0.99      0.02     -1.58      1.66   1161.22      1.00\n",
            "     b_pop_density      0.14      0.98      0.13     -1.57      1.60    833.38      1.01\n",
            "           b_urban      0.11      1.02      0.12     -1.48      1.85    883.30      1.01\n",
            "full_pred_cases[0]   1217.31      8.32   1217.21   1203.62   1229.71   1908.75      1.00\n",
            "full_pred_cases[1]    267.76    132.47    267.42     36.46    467.38    377.31      1.02\n",
            "full_pred_cases[2]    162.08    132.34    152.04    -10.87    345.49    430.28      1.02\n",
            "full_pred_cases[3]    309.39    137.69    311.11     72.03    512.51    316.53      1.02\n",
            "full_pred_cases[4]    397.71    137.44    400.11    134.48    583.66    276.42      1.03\n",
            "full_pred_cases[5]    387.74    129.27    375.47    171.79    578.67    504.53      1.01\n",
            "             sigma      5.21      3.11      4.53      0.70     10.14     33.53      1.06\n",
            "            sigma1     77.66     73.04     51.20      4.70    190.87    247.43      1.02\n",
            "              z[0]     -0.06      1.03     -0.06     -1.72      1.58    736.68      1.01\n",
            "              z[1]     -0.01      0.98     -0.01     -1.69      1.46   1857.46      1.00\n",
            "              z[2]     -0.05      0.99     -0.04     -1.57      1.65   2310.53      1.00\n",
            "              z[3]      0.05      1.02      0.03     -1.64      1.62   1146.15      1.00\n",
            "              z[4]     -0.07      1.04     -0.10     -1.60      1.87   2281.20      1.00\n",
            "              z[5]      0.07      0.97      0.08     -1.56      1.58   1293.40      1.00\n",
            "              z[6]      0.10      1.04      0.09     -1.83      1.68    400.10      1.01\n",
            "              z[7]     -0.09      0.99     -0.08     -1.79      1.46   2553.60      1.00\n",
            "              z[8]     -0.02      0.97     -0.01     -1.51      1.72   1923.66      1.00\n",
            "              z[9]      0.05      1.01      0.07     -1.42      1.95   2481.19      1.00\n",
            "             z[10]      0.04      0.99      0.04     -1.52      1.65   2542.25      1.00\n",
            "             z[11]     -0.07      0.96     -0.09     -1.66      1.47   2195.87      1.00\n",
            "             z[12]      0.03      0.97     -0.01     -1.60      1.67   2234.32      1.00\n",
            "             z[13]      0.08      1.03      0.12     -1.77      1.62    874.04      1.00\n",
            "             z[14]     -0.09      0.99     -0.11     -1.59      1.59   1580.95      1.00\n",
            "             z[15]     -0.11      0.96     -0.13     -1.76      1.41   2379.84      1.00\n",
            "             z[16]     -0.08      1.00     -0.08     -1.68      1.56   1304.17      1.00\n",
            "             z[17]      0.10      0.96      0.13     -1.44      1.66   2543.22      1.00\n",
            "             z[18]      0.06      0.98      0.09     -1.60      1.63   2232.09      1.00\n",
            "             z[19]      0.06      1.05      0.11     -1.74      1.79    339.40      1.01\n",
            "             z[20]     -0.04      1.01     -0.04     -1.71      1.50   1335.91      1.01\n",
            "             z[21]      0.05      1.01      0.07     -1.50      1.80   1349.74      1.00\n",
            "             z[22]     -0.15      0.98     -0.13     -1.84      1.37   2104.51      1.00\n",
            "             z[23]     -0.03      0.98     -0.04     -1.58      1.63   2249.09      1.00\n",
            "             z[24]     -0.11      0.99     -0.10     -1.77      1.45   2513.89      1.00\n",
            "             z[25]     -0.12      1.00     -0.08     -1.78      1.50    299.40      1.01\n",
            "             z[26]     -0.06      0.98     -0.09     -1.72      1.54   1917.50      1.00\n",
            "             z[27]     -0.05      0.98     -0.07     -1.59      1.57   1545.90      1.00\n",
            "             z[28]      0.02      1.02      0.05     -1.85      1.49    470.86      1.01\n",
            "             z[29]      0.14      1.00      0.15     -1.47      1.78    744.69      1.01\n",
            "             z[30]      0.08      1.01      0.11     -1.67      1.69    814.33      1.01\n",
            "             z[31]      0.03      1.00      0.05     -1.59      1.71   1440.96      1.00\n",
            "             z[32]     -0.00      1.09      0.06     -1.73      1.74    198.74      1.02\n",
            "             z[33]      0.06      0.99      0.02     -1.46      1.72   1076.85      1.00\n",
            "             z[34]     -0.06      0.97     -0.09     -1.59      1.61   2350.22      1.00\n",
            "             z[35]      0.06      1.00      0.07     -1.43      1.76    809.60      1.01\n",
            "             z[36]      0.04      0.96      0.01     -1.57      1.60   2355.44      1.00\n",
            "             z[37]     -0.08      0.97     -0.12     -1.72      1.46   1202.83      1.00\n",
            "             z[38]      0.03      1.01      0.01     -1.51      1.75    825.23      1.00\n",
            "             z[39]      0.04      0.97      0.07     -1.56      1.60   2131.83      1.00\n",
            "\n",
            "Number of divergences: 1003\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1217.305</td>\n",
              "      <td>8.318</td>\n",
              "      <td>1200.243</td>\n",
              "      <td>1233.839</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.294</td>\n",
              "      <td>1697.0</td>\n",
              "      <td>1319.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>267.759</td>\n",
              "      <td>132.469</td>\n",
              "      <td>-8.339</td>\n",
              "      <td>482.310</td>\n",
              "      <td>6.845</td>\n",
              "      <td>3.877</td>\n",
              "      <td>370.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>162.083</td>\n",
              "      <td>132.345</td>\n",
              "      <td>-14.882</td>\n",
              "      <td>393.298</td>\n",
              "      <td>6.409</td>\n",
              "      <td>3.406</td>\n",
              "      <td>449.0</td>\n",
              "      <td>596.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>309.387</td>\n",
              "      <td>137.693</td>\n",
              "      <td>53.542</td>\n",
              "      <td>573.570</td>\n",
              "      <td>7.719</td>\n",
              "      <td>4.463</td>\n",
              "      <td>328.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>397.707</td>\n",
              "      <td>137.436</td>\n",
              "      <td>134.477</td>\n",
              "      <td>650.721</td>\n",
              "      <td>8.293</td>\n",
              "      <td>5.416</td>\n",
              "      <td>289.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>387.742</td>\n",
              "      <td>129.271</td>\n",
              "      <td>157.349</td>\n",
              "      <td>645.014</td>\n",
              "      <td>5.754</td>\n",
              "      <td>4.773</td>\n",
              "      <td>543.0</td>\n",
              "      <td>547.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1216.999</td>\n",
              "      <td>5.986</td>\n",
              "      <td>1204.915</td>\n",
              "      <td>1229.560</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.192</td>\n",
              "      <td>2906.0</td>\n",
              "      <td>1867.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>267.600</td>\n",
              "      <td>132.457</td>\n",
              "      <td>0.000</td>\n",
              "      <td>480.766</td>\n",
              "      <td>6.876</td>\n",
              "      <td>3.888</td>\n",
              "      <td>370.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>161.622</td>\n",
              "      <td>132.848</td>\n",
              "      <td>0.000</td>\n",
              "      <td>389.967</td>\n",
              "      <td>6.589</td>\n",
              "      <td>3.421</td>\n",
              "      <td>246.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>309.321</td>\n",
              "      <td>137.923</td>\n",
              "      <td>55.022</td>\n",
              "      <td>572.647</td>\n",
              "      <td>7.906</td>\n",
              "      <td>4.610</td>\n",
              "      <td>314.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>397.968</td>\n",
              "      <td>136.855</td>\n",
              "      <td>135.592</td>\n",
              "      <td>646.844</td>\n",
              "      <td>8.156</td>\n",
              "      <td>5.299</td>\n",
              "      <td>295.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>387.907</td>\n",
              "      <td>129.101</td>\n",
              "      <td>161.398</td>\n",
              "      <td>646.996</td>\n",
              "      <td>5.742</td>\n",
              "      <td>4.786</td>\n",
              "      <td>544.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>100.199</td>\n",
              "      <td>9.679</td>\n",
              "      <td>81.085</td>\n",
              "      <td>117.334</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.172</td>\n",
              "      <td>2868.0</td>\n",
              "      <td>2393.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.136</td>\n",
              "      <td>0.977</td>\n",
              "      <td>-1.701</td>\n",
              "      <td>1.889</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.016</td>\n",
              "      <td>935.0</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.027</td>\n",
              "      <td>0.991</td>\n",
              "      <td>-1.837</td>\n",
              "      <td>1.871</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.018</td>\n",
              "      <td>1204.0</td>\n",
              "      <td>1569.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>0.113</td>\n",
              "      <td>1.021</td>\n",
              "      <td>-1.697</td>\n",
              "      <td>2.111</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.017</td>\n",
              "      <td>880.0</td>\n",
              "      <td>879.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1087.447</td>\n",
              "      <td>172.900</td>\n",
              "      <td>778.119</td>\n",
              "      <td>1406.411</td>\n",
              "      <td>6.625</td>\n",
              "      <td>2.762</td>\n",
              "      <td>688.0</td>\n",
              "      <td>590.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>152.823</td>\n",
              "      <td>89.971</td>\n",
              "      <td>-77.144</td>\n",
              "      <td>273.848</td>\n",
              "      <td>6.883</td>\n",
              "      <td>6.610</td>\n",
              "      <td>276.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>26.302</td>\n",
              "      <td>129.417</td>\n",
              "      <td>-330.446</td>\n",
              "      <td>164.028</td>\n",
              "      <td>10.528</td>\n",
              "      <td>11.046</td>\n",
              "      <td>253.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>194.319</td>\n",
              "      <td>104.512</td>\n",
              "      <td>-89.058</td>\n",
              "      <td>327.306</td>\n",
              "      <td>8.236</td>\n",
              "      <td>8.586</td>\n",
              "      <td>301.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>284.242</td>\n",
              "      <td>112.844</td>\n",
              "      <td>-11.147</td>\n",
              "      <td>441.640</td>\n",
              "      <td>8.562</td>\n",
              "      <td>8.531</td>\n",
              "      <td>294.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>275.903</td>\n",
              "      <td>91.944</td>\n",
              "      <td>137.370</td>\n",
              "      <td>464.403</td>\n",
              "      <td>3.968</td>\n",
              "      <td>4.190</td>\n",
              "      <td>418.0</td>\n",
              "      <td>1201.0</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1217.305    8.318  1200.243  1233.839      0.191    0.294   \n",
              "pred_cases_out[1]   267.759  132.469    -8.339   482.310      6.845    3.877   \n",
              "pred_cases_out[2]   162.083  132.345   -14.882   393.298      6.409    3.406   \n",
              "pred_cases_out[3]   309.387  137.693    53.542   573.570      7.719    4.463   \n",
              "pred_cases_out[4]   397.707  137.436   134.477   650.721      8.293    5.416   \n",
              "pred_cases_out[5]   387.742  129.271   157.349   645.014      5.754    4.773   \n",
              "lp[0]              1216.999    5.986  1204.915  1229.560      0.113    0.192   \n",
              "lp[1]               267.600  132.457     0.000   480.766      6.876    3.888   \n",
              "lp[2]               161.622  132.848     0.000   389.967      6.589    3.421   \n",
              "lp[3]               309.321  137.923    55.022   572.647      7.906    4.610   \n",
              "lp[4]               397.968  136.855   135.592   646.844      8.156    5.299   \n",
              "lp[5]               387.907  129.101   161.398   646.996      5.742    4.786   \n",
              "b0                  100.199    9.679    81.085   117.334      0.181    0.172   \n",
              "b_pop_density         0.136    0.977    -1.701     1.889      0.033    0.016   \n",
              "b_hdi                 0.027    0.991    -1.837     1.871      0.029    0.018   \n",
              "b_urban               0.113    1.021    -1.697     2.111      0.035    0.017   \n",
              "vae[0]             1087.447  172.900   778.119  1406.411      6.625    2.762   \n",
              "vae[1]              152.823   89.971   -77.144   273.848      6.883    6.610   \n",
              "vae[2]               26.302  129.417  -330.446   164.028     10.528   11.046   \n",
              "vae[3]              194.319  104.512   -89.058   327.306      8.236    8.586   \n",
              "vae[4]              284.242  112.844   -11.147   441.640      8.562    8.531   \n",
              "vae[5]              275.903   91.944   137.370   464.403      3.968    4.190   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    1697.0    1319.0   1.01  \n",
              "pred_cases_out[1]     370.0     566.0   1.02  \n",
              "pred_cases_out[2]     449.0     596.0   1.02  \n",
              "pred_cases_out[3]     328.0     319.0   1.02  \n",
              "pred_cases_out[4]     289.0      73.0   1.03  \n",
              "pred_cases_out[5]     543.0     547.0   1.01  \n",
              "lp[0]                2906.0    1867.0   1.01  \n",
              "lp[1]                 370.0     565.0   1.02  \n",
              "lp[2]                 246.0     124.0   1.03  \n",
              "lp[3]                 314.0     167.0   1.02  \n",
              "lp[4]                 295.0      82.0   1.03  \n",
              "lp[5]                 544.0     542.0   1.01  \n",
              "b0                   2868.0    2393.0   1.00  \n",
              "b_pop_density         935.0    2200.0   1.01  \n",
              "b_hdi                1204.0    1569.0   1.00  \n",
              "b_urban               880.0     879.0   1.01  \n",
              "vae[0]                688.0     590.0   1.01  \n",
              "vae[1]                276.0      71.0   1.02  \n",
              "vae[2]                253.0      72.0   1.02  \n",
              "vae[3]                301.0      71.0   1.02  \n",
              "vae[4]                294.0      72.0   1.02  \n",
              "vae[5]                418.0    1201.0   1.02  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_2.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 741\n",
            "Average ESS for all aggVAE-low effects : 765\n",
            "Max r_hat for all aggVAE-low : 1.0099999904632568\n",
            "Average ESS for all aggVAE-high effects : 736\n",
            "Max r_hat for all aggVAE-high : 1.0099999904632568\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_2.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "#insert the inference into the dataset\n",
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 81.8094\n",
            "MAE as % of actual value (averaged over all observations): 32.01%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "#this is the best, save this data\n",
        "#df_hi.to_csv(\"../data/processed/df_hi_jkt_2020_aggVAE_preds.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prob 0.9, max tree depth 20 - Rhat, ESS, RMSE, MAE for table 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating  prior and posterior predictive\n",
        "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
        "posterior_samples = mcmc_3.get_samples()\n",
        "posterior_predictive = Predictive(model, posterior_samples)(\n",
        "    rng_key_po, config_count\n",
        ")\n",
        "prior = Predictive(model, num_samples=500)(\n",
        "    rng_key_pr, config_count\n",
        ")\n",
        "# transform prior and posterior predictive to arviz inference objects\n",
        "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
        "numpyro_data = az.from_numpyro(\n",
        "    mcmc_3,\n",
        "    prior=prior,\n",
        "    posterior_predictive=posterior_predictive,\n",
        "    coords={\"district\": np.arange(Total_districts)},\n",
        "    dims={\"lp\": [\"district\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "                b0     99.77      9.80     99.77     83.49    115.36   2482.36      1.00\n",
            "             b_hdi      0.07      1.01      0.05     -1.63      1.62   1425.00      1.00\n",
            "     b_pop_density      0.08      1.00      0.07     -1.67      1.66   2048.05      1.00\n",
            "           b_urban      0.06      1.00      0.05     -1.59      1.69   1120.81      1.00\n",
            "full_pred_cases[0]   1216.77      7.98   1216.88   1203.54   1229.52   1927.13      1.00\n",
            "full_pred_cases[1]    274.03    133.15    270.33     50.83    487.39    397.99      1.00\n",
            "full_pred_cases[2]    169.16    131.08    158.45    -11.09    347.88    484.94      1.00\n",
            "full_pred_cases[3]    317.93    138.55    317.93     90.07    536.97    390.66      1.00\n",
            "full_pred_cases[4]    405.41    139.81    405.22    186.72    616.64    373.36      1.00\n",
            "full_pred_cases[5]    388.67    133.75    380.11    177.67    568.62    429.71      1.01\n",
            "             sigma      5.02      2.77      4.64      0.83      9.19    339.66      1.03\n",
            "            sigma1     76.01     72.14     51.28      5.27    169.42    709.27      1.01\n",
            "              z[0]     -0.06      1.02     -0.04     -1.61      1.72   2730.50      1.00\n",
            "              z[1]     -0.04      0.98     -0.05     -1.63      1.58   2449.83      1.00\n",
            "              z[2]     -0.08      0.99     -0.09     -1.71      1.50   2450.25      1.00\n",
            "              z[3]      0.07      1.02      0.07     -1.60      1.69   2715.16      1.00\n",
            "              z[4]     -0.06      1.05     -0.07     -1.80      1.68   2034.55      1.00\n",
            "              z[5]      0.03      0.96      0.02     -1.55      1.61   2923.61      1.00\n",
            "              z[6]      0.07      1.01      0.09     -1.52      1.72   2791.58      1.00\n",
            "              z[7]     -0.06      0.98     -0.04     -1.67      1.48   3031.13      1.00\n",
            "              z[8]     -0.03      1.02     -0.02     -1.68      1.62   2997.32      1.00\n",
            "              z[9]      0.02      1.00     -0.02     -1.67      1.64   2844.17      1.00\n",
            "             z[10]      0.06      0.98      0.06     -1.60      1.63   2622.16      1.00\n",
            "             z[11]     -0.08      1.03     -0.08     -1.76      1.60   2014.23      1.00\n",
            "             z[12]      0.02      1.02      0.03     -1.72      1.62   2216.95      1.00\n",
            "             z[13]      0.04      1.02      0.04     -1.62      1.73   2549.42      1.00\n",
            "             z[14]     -0.08      0.99     -0.06     -1.70      1.54   2644.75      1.00\n",
            "             z[15]     -0.05      1.00     -0.06     -1.78      1.53   2684.57      1.00\n",
            "             z[16]     -0.03      1.01     -0.02     -1.67      1.59   1922.07      1.00\n",
            "             z[17]      0.07      1.00      0.06     -1.65      1.67   2685.79      1.00\n",
            "             z[18]      0.06      1.00      0.09     -1.51      1.72   3088.95      1.00\n",
            "             z[19]      0.10      1.01      0.11     -1.57      1.80   2735.44      1.00\n",
            "             z[20]     -0.10      1.03     -0.10     -1.78      1.61   1780.97      1.00\n",
            "             z[21]      0.00      0.96      0.01     -1.64      1.53   2308.31      1.00\n",
            "             z[22]     -0.11      0.99     -0.10     -1.65      1.59   1949.45      1.00\n",
            "             z[23]     -0.01      0.98     -0.04     -1.64      1.58   2181.14      1.00\n",
            "             z[24]     -0.07      1.01     -0.10     -1.75      1.57   2926.13      1.00\n",
            "             z[25]     -0.11      0.96     -0.11     -1.71      1.42   3168.13      1.00\n",
            "             z[26]     -0.09      0.98     -0.07     -1.75      1.52   2547.03      1.00\n",
            "             z[27]     -0.05      1.04     -0.03     -1.75      1.61   2570.54      1.00\n",
            "             z[28]      0.02      0.96      0.00     -1.57      1.60   2993.89      1.00\n",
            "             z[29]      0.07      1.00      0.09     -1.68      1.60   1988.51      1.00\n",
            "             z[30]      0.08      1.00      0.08     -1.44      1.80   2741.92      1.00\n",
            "             z[31]      0.01      0.96      0.02     -1.45      1.67   2206.75      1.00\n",
            "             z[32]      0.08      1.03      0.07     -1.62      1.71   2409.68      1.00\n",
            "             z[33]      0.06      0.99      0.04     -1.51      1.72   3046.40      1.00\n",
            "             z[34]     -0.08      1.00     -0.09     -1.79      1.54   2325.18      1.00\n",
            "             z[35]      0.08      0.98      0.08     -1.51      1.65   2296.04      1.00\n",
            "             z[36]      0.06      0.99      0.06     -1.66      1.58   2562.86      1.00\n",
            "             z[37]     -0.08      0.98     -0.07     -1.70      1.49   2709.29      1.00\n",
            "             z[38]      0.05      1.00      0.04     -1.49      1.81   2201.46      1.00\n",
            "             z[39]      0.03      1.00      0.03     -1.59      1.69   2628.36      1.00\n",
            "\n",
            "Number of divergences: 915\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[0]</th>\n",
              "      <td>1216.769</td>\n",
              "      <td>7.976</td>\n",
              "      <td>1199.842</td>\n",
              "      <td>1231.419</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.295</td>\n",
              "      <td>2215.0</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[1]</th>\n",
              "      <td>274.033</td>\n",
              "      <td>133.151</td>\n",
              "      <td>-7.207</td>\n",
              "      <td>478.273</td>\n",
              "      <td>6.522</td>\n",
              "      <td>5.152</td>\n",
              "      <td>416.0</td>\n",
              "      <td>590.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[2]</th>\n",
              "      <td>169.158</td>\n",
              "      <td>131.080</td>\n",
              "      <td>-13.369</td>\n",
              "      <td>384.459</td>\n",
              "      <td>5.866</td>\n",
              "      <td>3.284</td>\n",
              "      <td>480.0</td>\n",
              "      <td>1002.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[3]</th>\n",
              "      <td>317.935</td>\n",
              "      <td>138.554</td>\n",
              "      <td>-4.231</td>\n",
              "      <td>526.368</td>\n",
              "      <td>6.841</td>\n",
              "      <td>4.869</td>\n",
              "      <td>416.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[4]</th>\n",
              "      <td>405.412</td>\n",
              "      <td>139.808</td>\n",
              "      <td>163.292</td>\n",
              "      <td>683.346</td>\n",
              "      <td>7.058</td>\n",
              "      <td>6.835</td>\n",
              "      <td>414.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_cases_out[5]</th>\n",
              "      <td>388.666</td>\n",
              "      <td>133.754</td>\n",
              "      <td>139.504</td>\n",
              "      <td>603.278</td>\n",
              "      <td>6.376</td>\n",
              "      <td>10.644</td>\n",
              "      <td>512.0</td>\n",
              "      <td>643.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[0]</th>\n",
              "      <td>1216.793</td>\n",
              "      <td>5.732</td>\n",
              "      <td>1205.773</td>\n",
              "      <td>1228.997</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.176</td>\n",
              "      <td>2698.0</td>\n",
              "      <td>1912.0</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[1]</th>\n",
              "      <td>273.955</td>\n",
              "      <td>133.087</td>\n",
              "      <td>0.000</td>\n",
              "      <td>471.599</td>\n",
              "      <td>6.526</td>\n",
              "      <td>5.161</td>\n",
              "      <td>419.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[2]</th>\n",
              "      <td>169.105</td>\n",
              "      <td>130.981</td>\n",
              "      <td>0.000</td>\n",
              "      <td>383.309</td>\n",
              "      <td>5.864</td>\n",
              "      <td>3.282</td>\n",
              "      <td>456.0</td>\n",
              "      <td>643.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[3]</th>\n",
              "      <td>317.926</td>\n",
              "      <td>138.388</td>\n",
              "      <td>0.000</td>\n",
              "      <td>517.400</td>\n",
              "      <td>6.832</td>\n",
              "      <td>4.866</td>\n",
              "      <td>417.0</td>\n",
              "      <td>583.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[4]</th>\n",
              "      <td>405.496</td>\n",
              "      <td>139.640</td>\n",
              "      <td>165.811</td>\n",
              "      <td>687.059</td>\n",
              "      <td>7.048</td>\n",
              "      <td>6.838</td>\n",
              "      <td>414.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lp[5]</th>\n",
              "      <td>388.663</td>\n",
              "      <td>133.447</td>\n",
              "      <td>144.320</td>\n",
              "      <td>607.049</td>\n",
              "      <td>6.359</td>\n",
              "      <td>10.659</td>\n",
              "      <td>513.0</td>\n",
              "      <td>653.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b0</th>\n",
              "      <td>99.766</td>\n",
              "      <td>9.804</td>\n",
              "      <td>82.450</td>\n",
              "      <td>118.746</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.178</td>\n",
              "      <td>2493.0</td>\n",
              "      <td>2152.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_pop_density</th>\n",
              "      <td>0.078</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-1.782</td>\n",
              "      <td>2.025</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.017</td>\n",
              "      <td>2106.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_hdi</th>\n",
              "      <td>0.071</td>\n",
              "      <td>1.008</td>\n",
              "      <td>-1.775</td>\n",
              "      <td>1.927</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.020</td>\n",
              "      <td>1428.0</td>\n",
              "      <td>1929.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_urban</th>\n",
              "      <td>0.059</td>\n",
              "      <td>1.001</td>\n",
              "      <td>-1.792</td>\n",
              "      <td>1.950</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.015</td>\n",
              "      <td>1146.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[0]</th>\n",
              "      <td>1096.225</td>\n",
              "      <td>174.951</td>\n",
              "      <td>757.694</td>\n",
              "      <td>1405.058</td>\n",
              "      <td>4.303</td>\n",
              "      <td>2.913</td>\n",
              "      <td>1654.0</td>\n",
              "      <td>2252.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[1]</th>\n",
              "      <td>160.054</td>\n",
              "      <td>95.515</td>\n",
              "      <td>-12.077</td>\n",
              "      <td>332.819</td>\n",
              "      <td>3.929</td>\n",
              "      <td>6.289</td>\n",
              "      <td>831.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[2]</th>\n",
              "      <td>36.448</td>\n",
              "      <td>127.547</td>\n",
              "      <td>-213.418</td>\n",
              "      <td>225.246</td>\n",
              "      <td>5.307</td>\n",
              "      <td>8.062</td>\n",
              "      <td>738.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[3]</th>\n",
              "      <td>203.776</td>\n",
              "      <td>107.976</td>\n",
              "      <td>3.968</td>\n",
              "      <td>392.716</td>\n",
              "      <td>4.041</td>\n",
              "      <td>6.433</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>910.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[4]</th>\n",
              "      <td>293.158</td>\n",
              "      <td>118.899</td>\n",
              "      <td>63.718</td>\n",
              "      <td>488.501</td>\n",
              "      <td>4.416</td>\n",
              "      <td>7.294</td>\n",
              "      <td>1048.0</td>\n",
              "      <td>926.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vae[5]</th>\n",
              "      <td>278.182</td>\n",
              "      <td>104.585</td>\n",
              "      <td>111.724</td>\n",
              "      <td>461.572</td>\n",
              "      <td>4.445</td>\n",
              "      <td>11.517</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>727.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean       sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  \\\n",
              "pred_cases_out[0]  1216.769    7.976  1199.842  1231.419      0.181    0.295   \n",
              "pred_cases_out[1]   274.033  133.151    -7.207   478.273      6.522    5.152   \n",
              "pred_cases_out[2]   169.158  131.080   -13.369   384.459      5.866    3.284   \n",
              "pred_cases_out[3]   317.935  138.554    -4.231   526.368      6.841    4.869   \n",
              "pred_cases_out[4]   405.412  139.808   163.292   683.346      7.058    6.835   \n",
              "pred_cases_out[5]   388.666  133.754   139.504   603.278      6.376   10.644   \n",
              "lp[0]              1216.793    5.732  1205.773  1228.997      0.116    0.176   \n",
              "lp[1]               273.955  133.087     0.000   471.599      6.526    5.161   \n",
              "lp[2]               169.105  130.981     0.000   383.309      5.864    3.282   \n",
              "lp[3]               317.926  138.388     0.000   517.400      6.832    4.866   \n",
              "lp[4]               405.496  139.640   165.811   687.059      7.048    6.838   \n",
              "lp[5]               388.663  133.447   144.320   607.049      6.359   10.659   \n",
              "b0                   99.766    9.804    82.450   118.746      0.197    0.178   \n",
              "b_pop_density         0.078    1.000    -1.782     2.025      0.022    0.017   \n",
              "b_hdi                 0.071    1.008    -1.775     1.927      0.027    0.020   \n",
              "b_urban               0.059    1.001    -1.792     1.950      0.030    0.015   \n",
              "vae[0]             1096.225  174.951   757.694  1405.058      4.303    2.913   \n",
              "vae[1]              160.054   95.515   -12.077   332.819      3.929    6.289   \n",
              "vae[2]               36.448  127.547  -213.418   225.246      5.307    8.062   \n",
              "vae[3]              203.776  107.976     3.968   392.716      4.041    6.433   \n",
              "vae[4]              293.158  118.899    63.718   488.501      4.416    7.294   \n",
              "vae[5]              278.182  104.585   111.724   461.572      4.445   11.517   \n",
              "\n",
              "                   ess_bulk  ess_tail  r_hat  \n",
              "pred_cases_out[0]    2215.0    1422.0   1.01  \n",
              "pred_cases_out[1]     416.0     590.0   1.00  \n",
              "pred_cases_out[2]     480.0    1002.0   1.00  \n",
              "pred_cases_out[3]     416.0     594.0   1.00  \n",
              "pred_cases_out[4]     414.0     582.0   1.00  \n",
              "pred_cases_out[5]     512.0     643.0   1.00  \n",
              "lp[0]                2698.0    1912.0   1.01  \n",
              "lp[1]                 419.0     587.0   1.00  \n",
              "lp[2]                 456.0     643.0   1.00  \n",
              "lp[3]                 417.0     583.0   1.00  \n",
              "lp[4]                 414.0     575.0   1.00  \n",
              "lp[5]                 513.0     653.0   1.00  \n",
              "b0                   2493.0    2152.0   1.00  \n",
              "b_pop_density        2106.0    1920.0   1.00  \n",
              "b_hdi                1428.0    1929.0   1.00  \n",
              "b_urban              1146.0    1868.0   1.00  \n",
              "vae[0]               1654.0    2252.0   1.00  \n",
              "vae[1]                831.0     849.0   1.00  \n",
              "vae[2]                738.0     826.0   1.00  \n",
              "vae[3]               1005.0     910.0   1.00  \n",
              "vae[4]               1048.0     926.0   1.00  \n",
              "vae[5]               1044.0     727.0   1.00  "
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(mcmc_3.print_summary())\n",
        "az.summary(numpyro_data, var_names = [\"pred_cases_out\", \"lp\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\", \"vae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ESS for all aggVAE effects : 1195\n",
            "Average ESS for all aggVAE-low effects : 1209\n",
            "Max r_hat for all aggVAE-low : 1.0\n",
            "Average ESS for all aggVAE-high effects : 1192\n",
            "Max r_hat for all aggVAE-high : 1.0\n"
          ]
        }
      ],
      "source": [
        "#check ESS and rhat\n",
        "ss = numpyro.diagnostics.summary(mcmc_3.get_samples(group_by_chain=True))\n",
        "r = np.mean(ss['vae_aggr']['n_eff'])\n",
        "print(\"Average ESS for all aggVAE effects : \" + str(round(r)))\n",
        "\n",
        "ess_lo = np.mean(ss[\"vae_aggr\"][\"n_eff\"][0:1])\n",
        "r_hat_lo = np.max(ss[\"vae_aggr\"][\"r_hat\"][0:1])\n",
        "\n",
        "ess_hi = np.mean(ss[\"vae_aggr\"][\"n_eff\"][1:6])\n",
        "r_hat_hi = np.max(ss[\"vae_aggr\"][\"r_hat\"][1 : 6])\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-low effects : {round(ess_lo)}\")\n",
        "print(f\"Max r_hat for all aggVAE-low : {round(r_hat_lo,2)}\")\n",
        "\n",
        "print(f\"Average ESS for all aggVAE-high effects : {round(ess_hi)}\")\n",
        "print(f\"Max r_hat for all aggVAE-high : {round(r_hat_hi,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "#insert the inference into the dataset\n",
        "mean_pred_cases = numpyro_data.posterior.pred_cases_out.values.mean(axis=(0, 1))\n",
        "df_hi['pred_cases_num'] = mean_pred_cases[df_lo.shape[0]:]\n",
        "df_lo['pred_cases'] = mean_pred_cases[:df_lo.shape[0]] / df_lo.Population\n",
        "df_hi['pred_cases'] = mean_pred_cases[df_lo.shape[0]:] / df_hi.Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 85.0627\n",
            "MAE as % of actual value (averaged over all observations): 34.96%\n"
          ]
        }
      ],
      "source": [
        "# Extract the predicted and observed values\n",
        "y_pred = df_hi[\"pred_cases_num\"].values\n",
        "y_true = df_hi[\"Cases\"].values\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Calculate MAE as percentage of each observation, then average\n",
        "mae_pct_all = []\n",
        "\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    if true != 0:\n",
        "        abs_error = abs(true - pred)\n",
        "        pct_error = (abs_error / true) * 100\n",
        "        mae_pct_all.append(pct_error)\n",
        "\n",
        "mae_pct_avg_all_obs = np.mean(mae_pct_all)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE as % of actual value (averaged over all observations): {mae_pct_avg_all_obs:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
