{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "1wXMNry7Hkyp"
   },
   "outputs": [],
   "source": [
    "# generic imports\n",
    "import time\n",
    "#from pyprojroot2 import here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "# jax import \n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "# numpyro import \n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS, MCMC, Predictive\n",
    "# arviz import \n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using [CpuDevice(id=0)] under the hood.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "jax.config.update('jax_platform_name', 'cpu');\n",
    "print(f'We are using {jax.devices()} under the hood.')\n",
    "#print(f'The default path is {here()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Province', 'Year', 'Cases', 'Population', 'HDI', 'Area_sq_km',\n",
      "       'Pop_den', 'urbanicity', 'geometry'],\n",
      "      dtype='object')\n",
      "Index(['District', 'Year', 'Area_sq_km', 'HDI', 'Province', 'Cases',\n",
      "       'Population', 'Pop_den', 'urbanicity', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let us first read the data and then understand what we have\n",
    "#data_path = here() / \"simulation study\" / \"data\"\n",
    "df_lo = gpd.read_file(\"../data/jkt_prov.shp\")\n",
    "df_hi = gpd.read_file(\"../data/jkt_dist.shp\")\n",
    "# let us first understand what we have\n",
    "print(df_lo.columns)\n",
    "print(df_hi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dengue incidence by province and year (low resolution):\n",
      "                  incidence\n",
      "Province    Year           \n",
      "DKI Jakarta 2020   0.001519\n",
      "            2021   0.001315\n",
      "            2022   0.002667\n",
      "            2023   0.001983 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display dengue incidence by province and year for low resolution data\n",
    "lo_prev = df_lo.copy()\n",
    "lo_prev['incidence'] = (lo_prev.Cases / lo_prev.Population)\n",
    "print(\"Dengue incidence by province and year (low resolution):\")\n",
    "print(lo_prev.groupby(['Province', 'Year'])[['incidence']].mean(), '\\n')\n",
    "\n",
    "# Below is code for high prev data but I  won't look at it as we want't to \n",
    "# model it not bias our choice of priors\n",
    "# Calculate and display dengue incidence by district for high resolution data  \n",
    "# hi_prev = df_hi.copy()\n",
    "# hi_prev['incidence'] = hi_prev.Cases / hi_prev.Population\n",
    "# print(\"Dengue incidence by district and year (high resolution):\")\n",
    "# print(hi_prev.groupby(['District', 'Year'])[['incidence']].mean())\n",
    "\n",
    "# make sure we use only one year of data \n",
    "year_data = df_lo.Year.max()\n",
    "# print(f'We are using data for the year {year_data}\\n')\n",
    "# let us filter the data for the most recent year\n",
    "df_lo = df_lo[df_lo.Year == year_data]\n",
    "df_hi = df_hi[df_hi.Year == year_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZReN7eiHoiS"
   },
   "source": [
    "# GP Kernel Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "u-WVCaHGHru2"
   },
   "outputs": [],
   "source": [
    "def dist_euclid(x, z):\n",
    "    \"\"\"\n",
    "    Computes Eucledian Distance Between Regions. This function is used by\n",
    "    exp_sq_kernel function (kernel function for gaussian processes)\n",
    "    \"\"\"\n",
    "    x = jnp.array(x) # (ngrid_pts, lat/lon) <- i.e (7304,2)\n",
    "    z = jnp.array(z) # (ngrid_pts, lat/lon) <- i.e (7304,2)\n",
    "    if len(x.shape)==1:\n",
    "        x = x.reshape(x.shape[0], 1) #(2618,) -> (7304,1)\n",
    "    if len(z.shape)==1:\n",
    "        z = x.reshape(x.shape[0], 1) #(2618,) -> (7304,1)\n",
    "    n_x, m = x.shape # 7304 , 2\n",
    "    n_z, m_z = z.shape # 7304 , 2\n",
    "    assert m == m_z\n",
    "    delta = jnp.zeros((n_x,n_z)) #(ngrid_pts,ngrid_pts) <- i.e (7304,7304)\n",
    "    for d in jnp.arange(m):\n",
    "        x_d = x[:,d] #(ngrid_pts-lat/lon,) <- (7304,)\n",
    "        z_d = z[:,d] #(ngrid_pts-lat/lon,) <- (7304,)\n",
    "        delta += (x_d[:,jnp.newaxis] - z_d)**2 # (7304,7304)\n",
    "\n",
    "    return jnp.sqrt(delta) #(7304,7304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "gekmJsOwHumV"
   },
   "outputs": [],
   "source": [
    "def exp_sq_kernel(x, z, var, length, noise, jitter=1.0e-4):\n",
    "    dist = dist_euclid(x, z) #(7304, 7304)\n",
    "    deltaXsq = jnp.power(dist/ length, 2.0)\n",
    "    k = var * jnp.exp(-0.5 * deltaXsq)\n",
    "    k += (noise + jitter) * jnp.eye(x.shape[0])\n",
    "    return k # (ngrid_pts, ngrid_pts) <- (7304,7304)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iOiO_1NHwNz"
   },
   "source": [
    "# Aggregation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "xgPKoYAkHxrl"
   },
   "outputs": [],
   "source": [
    "def M_g(M, g):\n",
    "    '''\n",
    "    - $M$ is a matrix with binary entries $m_{ij},$ showing whether point $j$ is in polygon $i$\n",
    "    - $g$ is a vector of GP draws over grid\n",
    "    - $maltmul(M, g)$ gives a vector of sums over each polygon\n",
    "    '''\n",
    "    M = jnp.array(M)\n",
    "    g = jnp.array(g).T\n",
    "    return(jnp.matmul(M, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qNASOC3HzmW"
   },
   "source": [
    "# Aggregated Prevalence Model - must edit this to include HDI, population density\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "SQPuzilzH1ih"
   },
   "outputs": [],
   "source": [
    "def prev_model_gp_aggr(args):\n",
    "    \"\"\"Dengue prevalence model with a Gaussian Process\"\"\"\n",
    "\n",
    "    x = args[\"x\"]  # Spatial grid points: (num_grid_points, 2)\n",
    "    gp_kernel = args[\"gp_kernel\"]  # Gaussian Process kernel\n",
    "    noise = args[\"noise\"]\n",
    "    jitter = args[\"jitter\"]\n",
    "\n",
    "    pop_density_lo = args[\"pop_density_lo\"]  # (4,) one province (jkt) for 4 yrs' data\n",
    "    pop_density_hi = args[\"pop_density_hi\"]  # (24,)\n",
    "\n",
    "    #aggregate pop_density tgt\n",
    "    pop_density = jnp.concatenate([pop_density_lo,pop_density_hi], axis = 0)\n",
    "\n",
    "    #aggregate hdi tgt\n",
    "\n",
    "    hdi_lo = args[\"hdi_lo\"]  # (4,) 6 districts within jkt for 4 yrs' data\n",
    "    hdi_hi = args[\"hdi_hi\"]  # (24,)\n",
    "    hdi = jnp.concatenate([hdi_lo,hdi_hi], axis = 0)\n",
    "\n",
    "    urban_lo = args[\"urban_lo\"]  # (4,) 6 districts within jkt for 4 yrs' data\n",
    "    urban_hi = args[\"urban_hi\"]  # (24,)\n",
    "    urban = jnp.concatenate([urban_lo,urban_hi], axis = 0)\n",
    "\n",
    "    M_lo = args[\"M_lo\"]  # (4, num_grid_points) aggregation matrix\n",
    "    M_hi = args[\"M_hi\"]  # (24, num_grid_points) aggregation matrix\n",
    "\n",
    "    total_cases_lo = args[\"total_cases_lo\"] #cos we wanna predict total cases district-wise, so only feed total cases for low res data\n",
    "\n",
    "    total_population_lo = args[\"total_population_lo\"]\n",
    "    total_population_hi = args[\"total_population_hi\"]\n",
    "\n",
    "    #aggregate total populations low and high\n",
    "    total_population = jnp.concatenate([total_population_lo,total_population_hi], axis = 0)\n",
    "\n",
    "    #add NaN values to total_cases to accommodate for unavailable total cases data for high resolution (that we want to predict)\n",
    "    total_cases = jnp.pad(total_cases_lo, (0, M_hi.shape[0]),constant_values = 0.0) #[3762.  484. ... , 0,0,0]\n",
    "    total_cases = jnp.where(total_cases == 0, jnp.nan, total_cases)# [3762.  484. ... , nan,nan,nan]\n",
    "    total_cases_mask = ~jnp.isnan(total_cases) # [True, True, ...., False, False, False]\n",
    "\n",
    "    # GP hyperparameters\n",
    "    kernel_length = numpyro.sample(\"kernel_length\", args[\"kernel_length\"])\n",
    "    kernel_var = numpyro.sample(\"kernel_var\", args[\"kernel_var\"])\n",
    "\n",
    "    # GP Kernel and Sample\n",
    "    k = gp_kernel(x, x, kernel_var, kernel_length, noise, jitter)\n",
    "    f = numpyro.sample(\"f\", dist.MultivariateNormal(loc=jnp.zeros(x.shape[0]), covariance_matrix=k))  # (num_grid_points,)\n",
    "\n",
    "    # Aggregate GP values to district level\n",
    "    gp_aggr_lo = numpyro.deterministic(\"gp_aggr_lo\", M_g(M_lo, f))  # (4,)\n",
    "    gp_aggr_hi = numpyro.deterministic(\"gp_aggr_hi\", M_g(M_hi, f))  # (24,)\n",
    "\n",
    "    # Now we need to aggregate both. This step is important since even though we only\n",
    "    # show the model the low resolution data, to produce high resolution data it\n",
    "    # needs the GP realizations for those regions\n",
    "    gp_aggr = numpyro.deterministic(\"gp_aggr\", jnp.concatenate([gp_aggr_lo,gp_aggr_hi])) #(28,)\n",
    "\n",
    "    # Fixed effects\n",
    "    b0 = numpyro.sample(\"b0\", dist.Normal(-5.25, 0.5))  # Intercept\n",
    "    b_pop_density = numpyro.sample(\"b_pop_density\", dist.Normal(0, 0.33))  # Effect of population density normal (2, 0.25) previously\n",
    "    b_hdi = numpyro.sample(\"b_hdi\", dist.Normal(0, 0.33))  # Effect of HDI\n",
    "    b_urban = numpyro.sample(\"b_urban\", dist.Normal(0, 0.33))  # Effect of urbanicity\n",
    "\n",
    "    #standardise all before passing into lp\n",
    "    #pop_density = (pop_density - jnp.mean(pop_density)) / jnp.std(pop_density)\n",
    "    #hdi = (hdi-jnp.mean(hdi)) / jnp.std(hdi)\n",
    "    #urban = (urban - jnp.mean(urban)) / jnp.std(urban)\n",
    "\n",
    "    # Linear predictor\n",
    "    lp = numpyro.deterministic(\"lp\", b0 - gp_aggr - b_pop_density * pop_density + b_hdi * hdi - b_urban * urban)  # (num_districts,)\n",
    "    #lp = numpyro.deterministic(\"lp\", (b0 - gp_aggr - b_pop_density * pop_density))  # (num_districts,)\n",
    "    #lp = numpyro.deterministic(\"lp\", (b0 - gp_aggr))  # (num_districts,)\n",
    "\n",
    "    # Prevalence probability\n",
    "    theta = numpyro.deterministic(\"theta\", jax.nn.sigmoid(lp))  # (num_districts,)\n",
    "\n",
    "    # Binomial likelihood\n",
    "    with numpyro.handlers.mask(mask=total_cases_mask):\n",
    "        pred_cases = numpyro.sample(\n",
    "            \"pred_cases\",\n",
    "            dist.Binomial(total_count=total_population, probs=theta),\n",
    "            obs=total_cases)\n",
    "\n",
    "    return pred_cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbDDNakYIbYe"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "3_l-ejoAIc2h"
   },
   "outputs": [],
   "source": [
    "# Lat/Lon Values of artificial grid\n",
    "x = np.load(\"../data/lat_lon_x_jkt.npy\")\n",
    "# combined regional data\n",
    "pol_pts_jkt_lo = np.load(\"../data/pol_pts_jkt_lo.npy\")\n",
    "pt_which_pol_jkt_lo = np.load(\"../data/pt_which_pol_jkt_lo.npy\")\n",
    "pol_pts_jkt_hi = np.load(\"../data/pol_pts_jkt_hi.npy\")\n",
    "pt_which_pol_jkt_hi = np.load(\"../data/pt_which_pol_jkt_hi.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cE5BfS4I5oZ"
   },
   "source": [
    "# Vars needed to be changed (change according to the agg prevalence model parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ivFcMASHI8W8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1\n",
      "  1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1\n",
      "  1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1\n",
      "  1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#M_lo = jnp.array(pol_pts_jkt_lo)[0,:].reshape(1, -1)\n",
    "#M_hi = jnp.array(pol_pts_jkt_hi)[[0,4,9,14,19], :]\n",
    "M_lo = jnp.array(pol_pts_jkt_lo)\n",
    "M_hi = jnp.array(pol_pts_jkt_hi)\n",
    "print(M_lo)\n",
    "print(M_hi)\n",
    "pop_density_lo = jnp.array(df_lo[\"Pop_den\"])\n",
    "pop_density_hi = jnp.array(df_hi[\"Pop_den\"]) \n",
    "hdi_lo = jnp.array(df_lo[\"HDI\"])\n",
    "hdi_hi = jnp.array(df_hi[\"HDI\"])\n",
    "urban_lo = jnp.array(df_lo[\"urbanicity\"])\n",
    "urban_hi = jnp.array(df_hi[\"urbanicity\"])\n",
    "cases_lo = jnp.array(df_lo[\"Cases\"])\n",
    "pop_lo = jnp.array(df_lo[\"Population\"])\n",
    "pop_hi = jnp.array(df_hi[\"Population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1211.4202]\n"
     ]
    }
   ],
   "source": [
    "print(pop_density_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j79GvFnGGlol",
    "outputId": "b4b37b17-a256-49f0-e2b5-dc453c9232f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "(5, 100)\n",
      "(1,)\n",
      "(5,)\n",
      "(1,)\n",
      "(5,)\n",
      "(1,)\n",
      "(1,)\n",
      "(5,)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "#print the shape of all the vars above\n",
    "print(M_lo.shape)\n",
    "print(M_hi.shape)\n",
    "print(pop_density_lo.shape)\n",
    "print(pop_density_hi.shape)\n",
    "print(hdi_lo.shape)\n",
    "print(hdi_hi.shape)\n",
    "print(cases_lo.shape)\n",
    "print(pop_lo.shape)\n",
    "print(pop_hi.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "2S8IwtvDJF-K"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"x\" : jnp.array(x), # Lat/lon vals of grid points # Shape (num_districts, 2)\n",
    "        \"gp_kernel\" : exp_sq_kernel,\n",
    "        \"jitter\" : 1e-4,\n",
    "        \"noise\" : 1e-4,\n",
    "        \"M_lo\" : M_lo, # Aggregation matrix # Shape (num_districts, num_districts)\n",
    "        \"M_hi\" : M_hi, # Aggregation matrix # Shape (num_districts, num_districts)\n",
    "        # GP Kernel Hyperparams\n",
    "        \"kernel_length\" :  dist.InverseGamma(3, 3), #(,)\n",
    "        \"kernel_var\" : dist.LogNormal(0,0.5),\n",
    "        \"pop_density_lo\": pop_density_lo, # Shape (num_districts,)\n",
    "        \"pop_density_hi\": pop_density_hi, # Shape (num_districts,)\n",
    "        \"hdi_lo\": hdi_lo, # Shape (num_districts, 2)\n",
    "        \"hdi_hi\": hdi_hi, # Shape (num_districts, 2)\n",
    "        \"urban_lo\": urban_lo,\n",
    "        \"urban_hi\": urban_hi,\n",
    "        \"total_cases_lo\" : cases_lo,\n",
    "        \"total_population_lo\" : pop_lo,\n",
    "        \"total_population_hi\" : pop_hi,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Predictive Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior Predictive Check\n",
    "prior_samples = Predictive(prev_model_gp_aggr, num_samples=500)(\n",
    "    random.PRNGKey(6), args)\n",
    "\n",
    "# transform prior samples to arviz inference object\n",
    "prior_samples_arviz = az.from_numpyro(prior=prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 500), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median</th>\n",
       "      <th>mad</th>\n",
       "      <th>eti_3%</th>\n",
       "      <th>eti_97%</th>\n",
       "      <th>mcse_median</th>\n",
       "      <th>ess_median</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>theta[0]</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.478</td>\n",
       "      <td>450.902</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta[1]</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>416.989</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta[2]</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.002</td>\n",
       "      <td>446.318</td>\n",
       "      <td>472.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta[3]</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>500.016</td>\n",
       "      <td>526.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta[4]</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>456.061</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta[5]</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>458.526</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp[0]</th>\n",
       "      <td>9.551</td>\n",
       "      <td>263.442</td>\n",
       "      <td>-713.885</td>\n",
       "      <td>726.724</td>\n",
       "      <td>19.936</td>\n",
       "      <td>450.902</td>\n",
       "      <td>437.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp[1]</th>\n",
       "      <td>-5.654</td>\n",
       "      <td>6.606</td>\n",
       "      <td>-24.792</td>\n",
       "      <td>13.137</td>\n",
       "      <td>0.578</td>\n",
       "      <td>416.989</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp[2]</th>\n",
       "      <td>-5.384</td>\n",
       "      <td>3.344</td>\n",
       "      <td>-15.139</td>\n",
       "      <td>3.844</td>\n",
       "      <td>0.352</td>\n",
       "      <td>446.318</td>\n",
       "      <td>472.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp[3]</th>\n",
       "      <td>-5.576</td>\n",
       "      <td>7.947</td>\n",
       "      <td>-29.609</td>\n",
       "      <td>17.154</td>\n",
       "      <td>0.752</td>\n",
       "      <td>500.016</td>\n",
       "      <td>526.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp[4]</th>\n",
       "      <td>-6.252</td>\n",
       "      <td>10.256</td>\n",
       "      <td>-37.562</td>\n",
       "      <td>24.070</td>\n",
       "      <td>0.939</td>\n",
       "      <td>456.061</td>\n",
       "      <td>513.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp[5]</th>\n",
       "      <td>-6.016</td>\n",
       "      <td>9.272</td>\n",
       "      <td>-32.834</td>\n",
       "      <td>19.331</td>\n",
       "      <td>0.607</td>\n",
       "      <td>458.526</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_aggr[0]</th>\n",
       "      <td>3.610</td>\n",
       "      <td>36.531</td>\n",
       "      <td>-103.064</td>\n",
       "      <td>113.772</td>\n",
       "      <td>3.473</td>\n",
       "      <td>492.142</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_aggr[1]</th>\n",
       "      <td>0.382</td>\n",
       "      <td>6.711</td>\n",
       "      <td>-18.695</td>\n",
       "      <td>19.820</td>\n",
       "      <td>0.596</td>\n",
       "      <td>432.952</td>\n",
       "      <td>535.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_aggr[2]</th>\n",
       "      <td>0.330</td>\n",
       "      <td>3.237</td>\n",
       "      <td>-8.992</td>\n",
       "      <td>9.911</td>\n",
       "      <td>0.286</td>\n",
       "      <td>469.967</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_aggr[3]</th>\n",
       "      <td>0.632</td>\n",
       "      <td>7.956</td>\n",
       "      <td>-22.509</td>\n",
       "      <td>24.133</td>\n",
       "      <td>0.722</td>\n",
       "      <td>512.320</td>\n",
       "      <td>483.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_aggr[4]</th>\n",
       "      <td>1.241</td>\n",
       "      <td>10.944</td>\n",
       "      <td>-29.018</td>\n",
       "      <td>31.929</td>\n",
       "      <td>0.739</td>\n",
       "      <td>484.452</td>\n",
       "      <td>535.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_aggr[5]</th>\n",
       "      <td>0.849</td>\n",
       "      <td>9.133</td>\n",
       "      <td>-25.031</td>\n",
       "      <td>27.163</td>\n",
       "      <td>0.751</td>\n",
       "      <td>482.850</td>\n",
       "      <td>484.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0</th>\n",
       "      <td>-5.249</td>\n",
       "      <td>0.319</td>\n",
       "      <td>-6.218</td>\n",
       "      <td>-4.406</td>\n",
       "      <td>0.028</td>\n",
       "      <td>474.715</td>\n",
       "      <td>405.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_pop_density</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.018</td>\n",
       "      <td>434.040</td>\n",
       "      <td>437.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_hdi</th>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.018</td>\n",
       "      <td>455.762</td>\n",
       "      <td>415.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_urban</th>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.016</td>\n",
       "      <td>597.189</td>\n",
       "      <td>454.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               median      mad   eti_3%  eti_97%  mcse_median  ess_median  \\\n",
       "theta[0]        1.000    0.000    0.000    1.000        0.478     450.902   \n",
       "theta[1]        0.004    0.004    0.000    1.000        0.002     416.989   \n",
       "theta[2]        0.005    0.005    0.000    0.979        0.002     446.318   \n",
       "theta[3]        0.004    0.004    0.000    1.000        0.003     500.016   \n",
       "theta[4]        0.002    0.002    0.000    1.000        0.002     456.061   \n",
       "theta[5]        0.002    0.002    0.000    1.000        0.001     458.526   \n",
       "lp[0]           9.551  263.442 -713.885  726.724       19.936     450.902   \n",
       "lp[1]          -5.654    6.606  -24.792   13.137        0.578     416.989   \n",
       "lp[2]          -5.384    3.344  -15.139    3.844        0.352     446.318   \n",
       "lp[3]          -5.576    7.947  -29.609   17.154        0.752     500.016   \n",
       "lp[4]          -6.252   10.256  -37.562   24.070        0.939     456.061   \n",
       "lp[5]          -6.016    9.272  -32.834   19.331        0.607     458.526   \n",
       "gp_aggr[0]      3.610   36.531 -103.064  113.772        3.473     492.142   \n",
       "gp_aggr[1]      0.382    6.711  -18.695   19.820        0.596     432.952   \n",
       "gp_aggr[2]      0.330    3.237   -8.992    9.911        0.286     469.967   \n",
       "gp_aggr[3]      0.632    7.956  -22.509   24.133        0.722     512.320   \n",
       "gp_aggr[4]      1.241   10.944  -29.018   31.929        0.739     484.452   \n",
       "gp_aggr[5]      0.849    9.133  -25.031   27.163        0.751     482.850   \n",
       "b0             -5.249    0.319   -6.218   -4.406        0.028     474.715   \n",
       "b_pop_density  -0.016    0.224   -0.627    0.599        0.018     434.040   \n",
       "b_hdi          -0.019    0.205   -0.610    0.563        0.018     455.762   \n",
       "b_urban        -0.036    0.228   -0.582    0.654        0.016     597.189   \n",
       "\n",
       "               ess_tail  r_hat  \n",
       "theta[0]          500.0    NaN  \n",
       "theta[1]          514.0    NaN  \n",
       "theta[2]          472.0    NaN  \n",
       "theta[3]          526.0    NaN  \n",
       "theta[4]          500.0    NaN  \n",
       "theta[5]          500.0    NaN  \n",
       "lp[0]             437.0    NaN  \n",
       "lp[1]             514.0    NaN  \n",
       "lp[2]             472.0    NaN  \n",
       "lp[3]             526.0    NaN  \n",
       "lp[4]             513.0    NaN  \n",
       "lp[5]             514.0    NaN  \n",
       "gp_aggr[0]        514.0    NaN  \n",
       "gp_aggr[1]        535.0    NaN  \n",
       "gp_aggr[2]        514.0    NaN  \n",
       "gp_aggr[3]        483.0    NaN  \n",
       "gp_aggr[4]        535.0    NaN  \n",
       "gp_aggr[5]        484.0    NaN  \n",
       "b0                405.0    NaN  \n",
       "b_pop_density     437.0    NaN  \n",
       "b_hdi             415.0    NaN  \n",
       "b_urban           454.0    NaN  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(prior_samples_arviz, var_names = [\"theta\", \"lp\", \"gp_aggr\", \"b0\", \"b_pop_density\", \"b_hdi\", \"b_urban\"], stat_focus = \"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doOpZ-ltJTlb"
   },
   "source": [
    "# Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "0PVn1gP1JUhB"
   },
   "outputs": [],
   "source": [
    "# Base seed for reproducibility\n",
    "base_seed = 3  # Keep this fixed for full replicability\n",
    "# MCMC settings\n",
    "n_warm = 1000\n",
    "n_samples = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWUOUxUeJWMC"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup:   2%|▏         | 71/3000 [01:26<59:08,  1.21s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m mcmc \u001b[38;5;241m=\u001b[39m MCMC(NUTS(prev_model_gp_aggr, target_accept_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m, max_tree_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m), \u001b[38;5;66;03m# change for later run to 0.95 and 12\u001b[39;00m\n\u001b[0;32m      3\u001b[0m             num_warmup\u001b[38;5;241m=\u001b[39mn_warm,\n\u001b[0;32m      4\u001b[0m             num_samples\u001b[38;5;241m=\u001b[39mn_samples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      8\u001b[0m             )\n\u001b[0;32m      9\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     12\u001b[0m t_elapsed_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((end \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpyro\\infer\\mcmc.py:713\u001b[0m, in \u001b[0;36mMCMC.run\u001b[1;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchain_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 713\u001b[0m     states, last_state \u001b[38;5;241m=\u001b[39m \u001b[43mpartial_map_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;66;03m# swap num_samples x num_chains to num_chains x num_samples\u001b[39;00m\n\u001b[0;32m    715\u001b[0m     states \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp\u001b[38;5;241m.\u001b[39mswapaxes(x, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), states)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpyro\\infer\\mcmc.py:489\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[1;34m(self, init, args, kwargs, collect_fields, remove_sites)\u001b[0m\n\u001b[0;32m    483\u001b[0m collection_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    484\u001b[0m collection_size \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    485\u001b[0m     collection_size\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collection_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m collection_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthinning\n\u001b[0;32m    488\u001b[0m )\n\u001b[1;32m--> 489\u001b[0m collect_vals \u001b[38;5;241m=\u001b[39m \u001b[43mfori_collect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlower_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupper_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_collect_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpostprocess_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_fields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_sites\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_last_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthinning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthinning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogbar_desc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_get_progbar_desc_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiagnostics_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiagnostics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_chains\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m states, last_val \u001b[38;5;241m=\u001b[39m collect_vals\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Get first argument of type `HMCState`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpyro\\util.py:401\u001b[0m, in \u001b[0;36mfori_collect\u001b[1;34m(lower, upper, body_fun, init_val, transform, progbar, return_last_val, collection_size, thinning, **progbar_opts)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m    399\u001b[0m     vals \u001b[38;5;241m=\u001b[39m _body_fn(i, \u001b[38;5;241m*\u001b[39mvals)\n\u001b[1;32m--> 401\u001b[0m     t\u001b[38;5;241m.\u001b[39mset_description(\u001b[43mprogbar_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m, refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diagnostics_fn:\n\u001b[0;32m    403\u001b[0m         t\u001b[38;5;241m.\u001b[39mset_postfix_str(diagnostics_fn(vals[\u001b[38;5;241m0\u001b[39m]), refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpyro\\infer\\mcmc.py:161\u001b[0m, in \u001b[0;36m_get_progbar_desc_str\u001b[1;34m(num_warmup, phase, i)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m        Given the current `state`, returns the diagnostics string to\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m        be added to progress bar for diagnostics purpose.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_progbar_desc_str\u001b[39m(num_warmup, phase, i):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m phase\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(base_seed)\n",
    "mcmc = MCMC(NUTS(prev_model_gp_aggr, target_accept_prob = 0.8, max_tree_depth = 10), # change for later run to 0.95 and 12\n",
    "            num_warmup=n_warm,\n",
    "            num_samples=n_samples,\n",
    "            num_chains=4,\n",
    "            chain_method=\"vectorized\",\n",
    "            progress_bar=True\n",
    "            )\n",
    "start = time.time()\n",
    "mcmc.run(rng, args)\n",
    "end = time.time()\n",
    "t_elapsed_min = round((end - start) / 60)\n",
    "print(f\"Time taken to run MCMC: {t_elapsed_min} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating  prior and posterior predictive\n",
    "rng_key_pr, rng_key_po = random.split(random.PRNGKey(4))\n",
    "posterior_samples = mcmc.get_samples()\n",
    "posterior_predictive = Predictive(prev_model_gp_aggr, posterior_samples)(\n",
    "    rng_key_po, args\n",
    ")\n",
    "prior = Predictive(prev_model_gp_aggr, num_samples=500)(\n",
    "    rng_key_pr, args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Inference Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_districts = df_lo.shape[0] + df_hi.shape[0]\n",
    "numpyro_data = az.from_numpyro(\n",
    "    mcmc,\n",
    "    prior=prior,\n",
    "    posterior_predictive=posterior_predictive,\n",
    "    coords={\"district\": np.arange(Total_districts)},\n",
    "    dims={\"theta\": [\"district\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the inference object\n",
    "from pyprojroot2 import here\n",
    "save_path = here() / \"simulation study\" / \"model_runs\" / \"aggGP_inference_object.nc\"\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro_data.to_netcdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro_data = az.from_netcdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(numpyro_data, var_names = [\"kernel\"], filter_vars=\"like\", stat_focus = \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(numpyro_data, var_names = [\"theta\", \"lp\", \"gp_aggr\", \"b\"], filter_vars=\"like\", stat_focus = \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = numpyro_data.posterior.theta.values\n",
    "n_lo = df_lo.shape[0]\n",
    "n_hi = df_hi.shape[0]\n",
    "theta_mean_gp = np.median(theta_samples, axis = (0, 1))\n",
    "bci_gp_25 = np.quantile(theta_samples,0.25,axis = (0, 1))\n",
    "bci_gp_75 = np.quantile(theta_samples,0.75, axis = (0, 1))\n",
    "# Slice IQR values to match low-res and high-res\n",
    "bci_lo_25 = bci_gp_25[:n_lo]\n",
    "bci_lo_75 = bci_gp_75[:n_lo]\n",
    "\n",
    "bci_hi_25 = bci_gp_25[n_lo:n_lo + n_hi]\n",
    "bci_hi_75 = bci_gp_75[n_lo:n_lo + n_hi]\n",
    "\n",
    "\n",
    "df_lo[\"obs_prev\"] = df_lo[\"Cases\"] / df_lo[\"Population\"]\n",
    "df_hi[\"obs_prev\"] = df_hi[\"Cases\"] / df_hi[\"Population\"]\n",
    "\n",
    "df_lo[\"theta_gp\"] = theta_mean_gp[0:n_lo] \n",
    "df_hi[\"theta_gp\"] = theta_mean_gp[n_lo:n_lo + n_hi] * 1e-2\n",
    "\n",
    "theta_obs_lo = df_lo[\"obs_prev\"]\n",
    "theta_gp_est_lo = df_lo[\"theta_gp\"]\n",
    "theta_obs_hi = df_hi[\"obs_prev\"]\n",
    "theta_gp_est_hi = df_hi[\"theta_gp\"]\n",
    "\n",
    "max_val_lo = np.max([theta_obs_lo, theta_gp_est_lo])\n",
    "min_val_lo = np.min([theta_obs_lo, theta_gp_est_lo])\n",
    "\n",
    "max_val_hi = np.max([theta_obs_hi, theta_gp_est_hi])\n",
    "min_val_hi = np.min([theta_obs_hi, theta_gp_est_hi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the low resolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot observed prevalence on the map\n",
    "df_lo.plot(\n",
    "    column=\"obs_prev\",  # Column to use for color\n",
    "    cmap=\"viridis\",  # Colormap\n",
    "    vmin=0.001,  # Minimum value for color scale\n",
    "    vmax=0.01,  # Maximum value for color scale\n",
    "    legend=True,  # Show legend\n",
    "    ax=ax[0],  # Plot on the first subplot\n",
    ")\n",
    "ax[0].set_title(\"Low-Res Observed Prevalence\")\n",
    "\n",
    "# Plot estimated prevalence on the map\n",
    "df_lo.plot(\n",
    "    column=\"theta_gp\",  # Column to use for color\n",
    "    cmap=\"viridis\",  # Colormap\n",
    "    vmin=0.001,  # Minimum value for color scale\n",
    "    vmax=0.01,  # Maximum value for color scale\n",
    "    legend=True,  # Show legend\n",
    "    ax=ax[1],  # Plot on the second subplot\n",
    ")\n",
    "ax[1].set_title(\"Low-Res Estimated Prevalence (θ)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"observed_vs_estimated_prevalence_lo.png\")  # Save as PNG\n",
    "# Or save as PDF:\n",
    "# plt.savefig(\"observed_vs_estimated_prevalence_lo.pdf\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot high resolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot observed prevalence on the map\n",
    "df_hi.plot(\n",
    "    column=\"obs_prev\",  # Column to use for color\n",
    "    cmap=\"viridis\",  # Colormap\n",
    "    vmin=0.001,  # Minimum value for color scale\n",
    "    vmax=0.01,  # Maximum value for color scale\n",
    "    legend=True,  # Show legend\n",
    "    ax=ax[0],  # Plot on the first subplot\n",
    ")\n",
    "ax[0].set_title(\"High-Res Observed Prevalence\")\n",
    "\n",
    "# Plot estimated prevalence on the map\n",
    "df_hi.plot(\n",
    "    column=\"theta_gp\",  # Column to use for color\n",
    "    cmap=\"viridis\",  # Colormap\n",
    "    vmin=0.001,  # Minimum value for color scale\n",
    "    vmax=0.01,  # Maximum value for color scale\n",
    "    legend=True,  # Show legend\n",
    "    ax=ax[1],  # Plot on the second subplot\n",
    ")\n",
    "ax[1].set_title(\"High-Res Estimated Prevalence (θ)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"observed_vs_estimated_prevalence_hi.png\")  # Save as PNG\n",
    "# Or save as PDF:\n",
    "# plt.savefig(\"observed_vs_estimated_prevalence.pdf\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
